{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83a0b14-7a38-41dc-80cf-096a9f9503ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "assert device == \"cuda\", \"Need CUDA for TensorRT.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf318930-3bf0-4de0-9854-5c6c8687c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader_b1   = DataLoader(test_dataset, batch_size=1,   shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b64  = DataLoader(test_dataset, batch_size=64,  shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b128 = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb2e192-fdf1-4a59-bc49-6f83a36732ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[1]))\n",
    "\n",
    "from models.alexnet_model import AlexNetCIFAR10, AlexNetCIFAR10_QAT  # <-- IMPORTANT: FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a998b044-df23-4a9d-b1b6-355c22f10ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: 0 unexpected: 0\n",
      "bad_missing (should be empty): []\n",
      "Loaded FP32 AlexNet from preconvert checkpoint ✅\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "CKPT_PATH = \"../../pth/alexnet_qat_preconvert.pth\"\n",
    "\n",
    "def strip_preconvert_state_generic(ckpt: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in ckpt.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            k = k[len(\"module.\"):]\n",
    "        if (\"activation_post_process\" in k) or (\"fake_quant\" in k) or (\"weight_fake_quant\" in k):\n",
    "            continue\n",
    "        if k.startswith(\"activation_post_process_\"):\n",
    "            continue\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "def remap_by_shape_and_order(ckpt_state: dict, model_state: dict):\n",
    "    \"\"\"\n",
    "    Greedy match ckpt tensors to model tensors by (suffix, shape) in model key order.\n",
    "    Works when naming differs but layer order/structure is the same.\n",
    "    \"\"\"\n",
    "    def suffix(k):\n",
    "        # keep BN stats vs weights separate\n",
    "        if k.endswith(\"running_mean\"): return \"running_mean\"\n",
    "        if k.endswith(\"running_var\"):  return \"running_var\"\n",
    "        if k.endswith(\"num_batches_tracked\"): return \"nbt\"\n",
    "        if k.endswith(\".weight\"): return \"weight\"\n",
    "        if k.endswith(\".bias\"):   return \"bias\"\n",
    "        return \"other\"\n",
    "\n",
    "    # group ckpt keys by (suffix, shape)\n",
    "    buckets = {}\n",
    "    for k, v in ckpt_state.items():\n",
    "        if not torch.is_tensor(v):\n",
    "            continue\n",
    "        key = (suffix(k), tuple(v.shape), str(v.dtype))\n",
    "        buckets.setdefault(key, []).append(k)\n",
    "\n",
    "    used = set()\n",
    "    new_state = {}\n",
    "\n",
    "    for mk, mv in model_state.items():\n",
    "        if not torch.is_tensor(mv):\n",
    "            continue\n",
    "        key = (suffix(mk), tuple(mv.shape), str(mv.dtype))\n",
    "        cands = buckets.get(key, [])\n",
    "        # pick first unused candidate\n",
    "        pick = None\n",
    "        for ck in cands:\n",
    "            if ck not in used:\n",
    "                pick = ck\n",
    "                break\n",
    "        if pick is not None:\n",
    "            new_state[mk] = ckpt_state[pick]\n",
    "            used.add(pick)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "# ---- load ckpt ----\n",
    "raw = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "ckpt_state = strip_preconvert_state_generic(raw)\n",
    "\n",
    "# IMPORTANT: use your FP32 AlexNet class here\n",
    "model = AlexNetCIFAR10(num_classes=10)\n",
    "\n",
    "model_state = model.state_dict()\n",
    "mapped = remap_by_shape_and_order(ckpt_state, model_state)\n",
    "\n",
    "missing, unexpected = model.load_state_dict(mapped, strict=False)\n",
    "\n",
    "bad_missing = [k for k in missing if k.endswith(\".weight\") or k.endswith(\".bias\") or k.endswith(\"running_mean\") or k.endswith(\"running_var\")]\n",
    "print(\"missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "print(\"bad_missing (should be empty):\", bad_missing[:50])\n",
    "\n",
    "assert len(bad_missing) == 0, \"Still missing real params => model definition doesn't match checkpoint structure.\"\n",
    "\n",
    "model.eval().to(device)\n",
    "print(\"Loaded FP32 AlexNet from preconvert checkpoint ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a405ef-b9ed-4c31-811f-adc9967aae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (full): 89.06\n",
      "Torch acc (first 50): 88.953125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_acc(model, loader, device=\"cuda\", max_batches=None):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if max_batches is not None and bi >= max_batches:\n",
    "            break\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Torch acc (full):\", torch_acc(model, test_loader, device=device))\n",
    "print(\"Torch acc (first 50):\", torch_acc(model, test_loader_b128, device=device, max_batches=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c861324f-ec23-4e3c-8746-15723a3d574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3530104/4137192131.py:15: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: alexnet_fp32_b1_op13.onnx\n",
      "Exported: alexnet_fp32_b64_op13.onnx\n",
      "Exported: alexnet_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval().to(device)\n",
    "\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32, device=device),\n",
    "    64:  torch.randn(64,  3, 32, 32, device=device),\n",
    "    128: torch.randn(128, 3, 32, 32, device=device),\n",
    "}\n",
    "\n",
    "onnx_map = {}\n",
    "with torch.no_grad():  # not required, but safe\n",
    "    for bs, dummy in dummy_map.items():\n",
    "        out_path = f\"alexnet_fp32_b{bs}_op13.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model, dummy, out_path,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"logits\"],\n",
    "            dynamic_axes=None,\n",
    "            dynamo=False\n",
    "        )\n",
    "        onnx_map[bs] = out_path\n",
    "        print(\"Exported:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a1cccf-4add-485f-a181-01738e8aa2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-13:48:31] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 701, GPU 3714 (MiB)\n",
      "[12/14/2025-13:48:31] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:48:31] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:48:31] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:48:31] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:48:31] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:48:31] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:48:31] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:48:31] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:48:31] [TRT] [I] ----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3530104/3635996445.py:77: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  config.int8_calibrator = EntropyCalibrator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-13:48:32] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +279, GPU +6, now: CPU 1178, GPU 3720 (MiB)\n",
      "[12/14/2025-13:48:32] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Total Host Persistent Memory: 38336 bytes\n",
      "[12/14/2025-13:48:32] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:48:32] [TRT] [I] Max Scratch Memory: 4608 bytes\n",
      "[12/14/2025-13:48:32] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 24 steps to complete.\n",
      "[12/14/2025-13:48:32] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.202061ms to assign 3 blocks to 24 nodes requiring 266752 bytes.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Total Activation Memory: 266752 bytes\n",
      "[12/14/2025-13:48:32] [TRT] [I] Total Weights Memory: 7242792 bytes\n",
      "[12/14/2025-13:48:32] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:48:32] [TRT] [I] Engine generation completed in 0.44926 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 7 (MiB)\n",
      "[12/14/2025-13:48:32] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 0 in 0.0029917 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 1 in 0.00281443 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 2 in 0.00269794 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 3 in 0.00270321 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 4 in 0.00274729 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 5 in 0.00272045 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 6 in 0.00273165 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 7 in 0.00274354 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 8 in 0.00270482 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 9 in 0.00266637 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 10 in 0.00271728 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 11 in 0.00270871 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 12 in 0.00268977 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 13 in 0.00269741 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 14 in 0.00267472 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 15 in 0.00267743 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 16 in 0.00267153 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 17 in 0.00268069 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 18 in 0.00267477 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 19 in 0.00270719 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 20 in 0.0026702 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 21 in 0.00272369 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 22 in 0.00271414 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 23 in 0.00266398 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 24 in 0.00267738 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 25 in 0.00268086 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 26 in 0.00269551 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 27 in 0.00269503 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 28 in 0.0026949 seconds.\n",
      "[12/14/2025-13:48:32] [TRT] [I]   Calibrated batch 29 in 0.00269503 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 30 in 0.00268832 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 31 in 0.00267896 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 32 in 0.00269891 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 33 in 0.00269464 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 34 in 0.00266786 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 35 in 0.00268585 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 36 in 0.00268285 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 37 in 0.00268408 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 38 in 0.00267726 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 39 in 0.00268782 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 40 in 0.00266932 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 41 in 0.00267774 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 42 in 0.00269795 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 43 in 0.0027014 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 44 in 0.00268246 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 45 in 0.00265788 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 46 in 0.00267829 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 47 in 0.0026802 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 48 in 0.00269398 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 49 in 0.00272402 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 50 in 0.00267459 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 51 in 0.00268557 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 52 in 0.00268627 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 53 in 0.0027008 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 54 in 0.00267944 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 55 in 0.00269084 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 56 in 0.00268383 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 57 in 0.00271738 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 58 in 0.00269655 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 59 in 0.00268905 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 60 in 0.00266735 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 61 in 0.0026874 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 62 in 0.002703 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 63 in 0.00267018 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 64 in 0.0026844 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 65 in 0.00271773 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 66 in 0.00266653 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 67 in 0.00272742 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 68 in 0.00268028 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 69 in 0.00268552 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 70 in 0.0023682 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 71 in 0.00228525 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 72 in 0.00229946 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 73 in 0.00229163 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 74 in 0.0022608 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 75 in 0.0022935 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 76 in 0.00228244 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 77 in 0.002273 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 78 in 0.00225647 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 79 in 0.00228756 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 80 in 0.00229781 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 81 in 0.00228676 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 82 in 0.00225502 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 83 in 0.00227079 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 84 in 0.00225891 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 85 in 0.00228539 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 86 in 0.00227179 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 87 in 0.00228257 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 88 in 0.00228069 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 89 in 0.00232052 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 90 in 0.00226758 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 91 in 0.00226837 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 92 in 0.00226282 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 93 in 0.00228252 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 94 in 0.00226552 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 95 in 0.00229212 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 96 in 0.00229589 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 97 in 0.00230757 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 98 in 0.00230432 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 99 in 0.00228373 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 100 in 0.00226363 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 101 in 0.00228052 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 102 in 0.00228362 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 103 in 0.00227687 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 104 in 0.00227869 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 105 in 0.00233494 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 106 in 0.00227838 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 107 in 0.00229198 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 108 in 0.00229305 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 109 in 0.00227886 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 110 in 0.00229691 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 111 in 0.00227952 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 112 in 0.00229047 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 113 in 0.00229443 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 114 in 0.00231063 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 115 in 0.00226891 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 116 in 0.00227904 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 117 in 0.00225276 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 118 in 0.00227492 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 119 in 0.00227989 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 120 in 0.002284 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 121 in 0.00229147 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 122 in 0.00228652 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 123 in 0.0022648 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 124 in 0.00225672 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 125 in 0.00227601 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 126 in 0.00227836 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 127 in 0.0022857 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 128 in 0.00226618 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 129 in 0.00225389 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 130 in 0.00229171 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 131 in 0.00225213 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 132 in 0.00226506 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 133 in 0.00227988 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 134 in 0.00226881 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 135 in 0.00225646 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 136 in 0.00225245 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 137 in 0.00229002 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 138 in 0.0023022 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 139 in 0.00226928 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 140 in 0.00227679 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 141 in 0.00226809 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 142 in 0.00228588 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 143 in 0.00228278 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 144 in 0.00229511 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 145 in 0.0022834 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 146 in 0.002299 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 147 in 0.00227287 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 148 in 0.00228091 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 149 in 0.00225654 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 150 in 0.00226521 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 151 in 0.00227357 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 152 in 0.00229548 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 153 in 0.00205868 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 154 in 0.00204045 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 155 in 0.00204893 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 156 in 0.0020313 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 157 in 0.0020207 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 158 in 0.00206816 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 159 in 0.00204635 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 160 in 0.00207644 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 161 in 0.00205353 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 162 in 0.00203465 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 163 in 0.0020354 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 164 in 0.00205372 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 165 in 0.00207336 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 166 in 0.00206721 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 167 in 0.00204249 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 168 in 0.00207838 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 169 in 0.00205526 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 170 in 0.00204082 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 171 in 0.00204053 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 172 in 0.0020509 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 173 in 0.0020474 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 174 in 0.00206456 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 175 in 0.00205082 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 176 in 0.00207052 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 177 in 0.00204255 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 178 in 0.00201555 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 179 in 0.00203555 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 180 in 0.00206069 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 181 in 0.00204355 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 182 in 0.00206183 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 183 in 0.0020446 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 184 in 0.00205564 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 185 in 0.00206727 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 186 in 0.00204482 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 187 in 0.00204287 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 188 in 0.00204641 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 189 in 0.00206589 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 190 in 0.00206158 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 191 in 0.00207169 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 192 in 0.00205231 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 193 in 0.00206643 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 194 in 0.00206585 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 195 in 0.00205732 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 196 in 0.00205184 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 197 in 0.00209262 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 198 in 0.0020637 seconds.\n",
      "[12/14/2025-13:48:33] [TRT] [I]   Calibrated batch 199 in 0.00207941 seconds.\n",
      "[12/14/2025-13:48:35] [TRT] [I]   Post Processing Calibration data in 1.7231 seconds.\n",
      "[12/14/2025-13:48:35] [TRT] [I] Calibration completed in 2.68101 seconds.\n",
      "[12/14/2025-13:48:35] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:48:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:48:46] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:48:46] [TRT] [I] Total Host Persistent Memory: 52544 bytes\n",
      "[12/14/2025-13:48:46] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:48:46] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:48:46] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 13 steps to complete.\n",
      "[12/14/2025-13:48:46] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.04257ms to assign 3 blocks to 13 nodes requiring 49664 bytes.\n",
      "[12/14/2025-13:48:46] [TRT] [I] Total Activation Memory: 49664 bytes\n",
      "[12/14/2025-13:48:46] [TRT] [I] Total Weights Memory: 1078788 bytes\n",
      "[12/14/2025-13:48:46] [TRT] [I] Engine generation completed in 11.5399 seconds.\n",
      "[12/14/2025-13:48:46] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 11 MiB\n",
      "Saved: alexnet_int8_b1.engine\n",
      "[12/14/2025-13:48:46] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:48:46] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:48:46] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:48:46] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:48:46] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:48:46] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:48:46] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:48:46] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:48:46] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:48:47] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 1838, GPU 3976 (MiB)\n",
      "[12/14/2025-13:48:47] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Total Host Persistent Memory: 36480 bytes\n",
      "[12/14/2025-13:48:47] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:48:47] [TRT] [I] Max Scratch Memory: 512 bytes\n",
      "[12/14/2025-13:48:47] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 23 steps to complete.\n",
      "[12/14/2025-13:48:47] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.38251ms to assign 3 blocks to 23 nodes requiring 16778240 bytes.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Total Activation Memory: 16778240 bytes\n",
      "[12/14/2025-13:48:47] [TRT] [I] Total Weights Memory: 7242792 bytes\n",
      "[12/14/2025-13:48:47] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:48:47] [TRT] [I] Engine generation completed in 0.247007 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +16, now: CPU 0, GPU 23 (MiB)\n",
      "[12/14/2025-13:48:47] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 0 in 0.00388951 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 1 in 0.00389894 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 2 in 0.00376727 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 3 in 0.00376676 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 4 in 0.00369973 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 5 in 0.00370772 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 6 in 0.00380751 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 7 in 0.00373568 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 8 in 0.00382325 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 9 in 0.00372001 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 10 in 0.00370884 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 11 in 0.00370737 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 12 in 0.00373644 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 13 in 0.00368993 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 14 in 0.00371028 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 15 in 0.00370532 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 16 in 0.00370859 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 17 in 0.00370057 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 18 in 0.00371674 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 19 in 0.00371477 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 20 in 0.00375623 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 21 in 0.00371013 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 22 in 0.00375222 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 23 in 0.0036873 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 24 in 0.00371032 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 25 in 0.00369051 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 26 in 0.00371755 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 27 in 0.00369738 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 28 in 0.00374014 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 29 in 0.00367932 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 30 in 0.00381618 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 31 in 0.00377403 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 32 in 0.00371332 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 33 in 0.00369135 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 34 in 0.0037362 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 35 in 0.00368857 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 36 in 0.00368453 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 37 in 0.00373111 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 38 in 0.0037397 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 39 in 0.00370706 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 40 in 0.00370584 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 41 in 0.00369318 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 42 in 0.00367851 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 43 in 0.00369136 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 44 in 0.00382608 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 45 in 0.00373304 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 46 in 0.00372308 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 47 in 0.00371669 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 48 in 0.00376882 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 49 in 0.00375021 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 50 in 0.00374122 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 51 in 0.00373026 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 52 in 0.00369676 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 53 in 0.00372983 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 54 in 0.00372983 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 55 in 0.00370683 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 56 in 0.00368865 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 57 in 0.00370321 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 58 in 0.0036889 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 59 in 0.00369475 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 60 in 0.00370095 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 61 in 0.003709 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 62 in 0.00384587 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 63 in 0.00371892 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 64 in 0.00371135 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 65 in 0.00372045 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 66 in 0.00385776 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 67 in 0.00376007 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 68 in 0.00373028 seconds.\n",
      "[12/14/2025-13:48:47] [TRT] [I]   Calibrated batch 69 in 0.00373384 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 70 in 0.00372876 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 71 in 0.0037391 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 72 in 0.00374533 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 73 in 0.00367933 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 74 in 0.00368953 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 75 in 0.00397128 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 76 in 0.00368326 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 77 in 0.00369097 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 78 in 0.0036861 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 79 in 0.00373133 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 80 in 0.00377971 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 81 in 0.00373566 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 82 in 0.00373683 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 83 in 0.00377242 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 84 in 0.00377554 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 85 in 0.00374321 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 86 in 0.00372191 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 87 in 0.00369682 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 88 in 0.00369212 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 89 in 0.00369249 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 90 in 0.00367463 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 91 in 0.00369419 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 92 in 0.00370823 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 93 in 0.00369334 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 94 in 0.00388144 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 95 in 0.00368968 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 96 in 0.00372369 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 97 in 0.00370529 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 98 in 0.0038055 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 99 in 0.00373531 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 100 in 0.00374894 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 101 in 0.00376273 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 102 in 0.00378732 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 103 in 0.00372873 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 104 in 0.00373173 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 105 in 0.00369527 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 106 in 0.00373289 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 107 in 0.00372433 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 108 in 0.00374337 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 109 in 0.00368784 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 110 in 0.00369957 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 111 in 0.00398385 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 112 in 0.00371958 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 113 in 0.0036978 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 114 in 0.00376778 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 115 in 0.00374321 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 116 in 0.00371717 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 117 in 0.00369133 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 118 in 0.00383039 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 119 in 0.00375623 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 120 in 0.00372061 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 121 in 0.00372017 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 122 in 0.00372718 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 123 in 0.00372171 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 124 in 0.00367584 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 125 in 0.00365636 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 126 in 0.00372281 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 127 in 0.00367466 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 128 in 0.00366081 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 129 in 0.00369179 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 130 in 0.00387576 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 131 in 0.00369365 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 132 in 0.00379958 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 133 in 0.00375612 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 134 in 0.00371362 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 135 in 0.00372264 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 136 in 0.00376248 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 137 in 0.00373084 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 138 in 0.00372891 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 139 in 0.0037218 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 140 in 0.00377374 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 141 in 0.00373857 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 142 in 0.00368446 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 143 in 0.0036853 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 144 in 0.00367383 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 145 in 0.00366958 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 146 in 0.00367568 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 147 in 0.0036742 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 148 in 0.00402882 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 149 in 0.00367948 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 150 in 0.00374388 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 151 in 0.00370071 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 152 in 0.00375652 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 153 in 0.00372588 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 154 in 0.00384551 seconds.\n",
      "[12/14/2025-13:48:48] [TRT] [I]   Calibrated batch 155 in 0.00368393 seconds.\n",
      "[12/14/2025-13:48:50] [TRT] [I]   Post Processing Calibration data in 1.74984 seconds.\n",
      "[12/14/2025-13:48:50] [TRT] [I] Calibration completed in 2.94708 seconds.\n",
      "[12/14/2025-13:48:50] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:48:50] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:49:00] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:49:00] [TRT] [I] Total Host Persistent Memory: 51680 bytes\n",
      "[12/14/2025-13:49:00] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:49:00] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:49:00] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 12 steps to complete.\n",
      "[12/14/2025-13:49:00] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.03226ms to assign 2 blocks to 12 nodes requiring 3145728 bytes.\n",
      "[12/14/2025-13:49:00] [TRT] [I] Total Activation Memory: 3145728 bytes\n",
      "[12/14/2025-13:49:00] [TRT] [I] Total Weights Memory: 1071620 bytes\n",
      "[12/14/2025-13:49:00] [TRT] [I] Engine generation completed in 10.618 seconds.\n",
      "[12/14/2025-13:49:00] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 23 MiB\n",
      "Saved: alexnet_int8_b64.engine\n",
      "[12/14/2025-13:49:01] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:49:01] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:49:01] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:49:01] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:49:01] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:49:01] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:49:01] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:49:01] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:49:01] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:49:01] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 1841, GPU 3980 (MiB)\n",
      "[12/14/2025-13:49:01] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Total Host Persistent Memory: 36480 bytes\n",
      "[12/14/2025-13:49:01] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:49:01] [TRT] [I] Max Scratch Memory: 512 bytes\n",
      "[12/14/2025-13:49:01] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 22 steps to complete.\n",
      "[12/14/2025-13:49:01] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.177504ms to assign 3 blocks to 22 nodes requiring 33555456 bytes.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Total Activation Memory: 33555456 bytes\n",
      "[12/14/2025-13:49:01] [TRT] [I] Total Weights Memory: 7242792 bytes\n",
      "[12/14/2025-13:49:01] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:49:01] [TRT] [I] Engine generation completed in 0.238299 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +32, now: CPU 0, GPU 39 (MiB)\n",
      "[12/14/2025-13:49:01] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 0 in 0.00550818 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 1 in 0.00542992 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 2 in 0.00538485 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 3 in 0.00539968 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 4 in 0.00540744 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 5 in 0.00538627 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 6 in 0.00541812 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 7 in 0.00540457 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 8 in 0.00541685 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 9 in 0.00535286 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 10 in 0.00539526 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 11 in 0.00537834 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 12 in 0.00535328 seconds.\n",
      "[12/14/2025-13:49:01] [TRT] [I]   Calibrated batch 13 in 0.00534998 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 14 in 0.00545369 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 15 in 0.00538732 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 16 in 0.00539501 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 17 in 0.00537587 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 18 in 0.00541719 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 19 in 0.00540897 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 20 in 0.00542897 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 21 in 0.00537082 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 22 in 0.0053886 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 23 in 0.00537919 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 24 in 0.00538288 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 25 in 0.00537785 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 26 in 0.00543179 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 27 in 0.00537289 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 28 in 0.00534775 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 29 in 0.0053733 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 30 in 0.00542866 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 31 in 0.00539127 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 32 in 0.00544528 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 33 in 0.00538216 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 34 in 0.00542687 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 35 in 0.0053637 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 36 in 0.00542016 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 37 in 0.00541673 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 38 in 0.00536947 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 39 in 0.00539465 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 40 in 0.00539424 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 41 in 0.0053728 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 42 in 0.00536925 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 43 in 0.00555988 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 44 in 0.00539416 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 45 in 0.00534808 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 46 in 0.00542809 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 47 in 0.00547563 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 48 in 0.0053802 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 49 in 0.00533974 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 50 in 0.00538203 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 51 in 0.00536184 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 52 in 0.0053998 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 53 in 0.00537031 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 54 in 0.00536835 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 55 in 0.0053836 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 56 in 0.00559551 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 57 in 0.00538047 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 58 in 0.00572221 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 59 in 0.00540172 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 60 in 0.00541604 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 61 in 0.00547368 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 62 in 0.00540436 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 63 in 0.00538666 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 64 in 0.00539577 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 65 in 0.00536582 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 66 in 0.00544676 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 67 in 0.00541452 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 68 in 0.00538596 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 69 in 0.00544077 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 70 in 0.00543579 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 71 in 0.00533994 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 72 in 0.00543524 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 73 in 0.00549248 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 74 in 0.00538912 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 75 in 0.00541219 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 76 in 0.00540227 seconds.\n",
      "[12/14/2025-13:49:02] [TRT] [I]   Calibrated batch 77 in 0.00533987 seconds.\n",
      "[12/14/2025-13:49:04] [TRT] [I]   Post Processing Calibration data in 1.7121 seconds.\n",
      "[12/14/2025-13:49:04] [TRT] [I] Calibration completed in 2.80132 seconds.\n",
      "[12/14/2025-13:49:04] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:49:04] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:49:14] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:49:15] [TRT] [I] Total Host Persistent Memory: 51680 bytes\n",
      "[12/14/2025-13:49:15] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:49:15] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:49:15] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 12 steps to complete.\n",
      "[12/14/2025-13:49:15] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.03192ms to assign 2 blocks to 12 nodes requiring 6291456 bytes.\n",
      "[12/14/2025-13:49:15] [TRT] [I] Total Activation Memory: 6291456 bytes\n",
      "[12/14/2025-13:49:15] [TRT] [I] Total Weights Memory: 1071620 bytes\n",
      "[12/14/2025-13:49:15] [TRT] [I] Engine generation completed in 10.6875 seconds.\n",
      "[12/14/2025-13:49:15] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 39 MiB\n",
      "Saved: alexnet_int8_b128.engine\n",
      "INT8 engines built: {1: 'alexnet_int8_b1.engine', 64: 'alexnet_int8_b64.engine', 128: 'alexnet_int8_b128.engine'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# ----------------------------\n",
    "# INT8 Entropy Calibrator\n",
    "# ----------------------------\n",
    "class EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calib_loader, max_batches=200, cache_file=\"calib.cache\"):\n",
    "        super().__init__()\n",
    "        self.data_iter = iter(calib_loader)\n",
    "        self.max_batches = max_batches\n",
    "        self.batch_count = 0\n",
    "        self.cache_file = cache_file\n",
    "\n",
    "        # initial shape (just to allocate something)\n",
    "        x0, _ = next(iter(calib_loader))\n",
    "        self.batch_size = x0.shape[0]\n",
    "        self.device_input = torch.empty_like(x0, device=\"cuda\")\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_batch(self, names):\n",
    "        if self.batch_count >= self.max_batches:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            x, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        self.batch_count += 1\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        # ✅ IMPORTANT: ensure buffer matches incoming shape\n",
    "        if self.device_input.numel() != x.numel():\n",
    "            self.device_input = torch.empty_like(x, device=\"cuda\")\n",
    "        else:\n",
    "            self.device_input = self.device_input.view_as(x)\n",
    "\n",
    "        self.device_input.copy_(x)\n",
    "        return [int(self.device_input.data_ptr())]\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        return None  # ✅ force fresh calibration\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "# ----------------------------\n",
    "# Build static INT8 engine\n",
    "# ----------------------------\n",
    "def build_int8_engine_static(onnx_path, engine_path, calib_loader, max_calib_batches=200):\n",
    "    # ✅ IMPORTANT: delete old cache so TRT can't reuse stale scales\n",
    "    cache_path = engine_path.replace(\".engine\", \".cache\")\n",
    "    if os.path.exists(cache_path):\n",
    "        os.remove(cache_path)\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed: {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        config.int8_calibrator = EntropyCalibrator(\n",
    "            calib_loader,\n",
    "            max_batches=max_calib_batches,\n",
    "            cache_file=cache_path\n",
    "        )\n",
    "\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"INT8 engine build failed: {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Build engines for each batch size\n",
    "# ----------------------------\n",
    "calib_loader_map = {\n",
    "    1:   test_loader_b1,\n",
    "    64:  test_loader_b64,\n",
    "    128: test_loader_b128,\n",
    "}\n",
    "\n",
    "engine_map = {}\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"alexnet_int8_b{bs}.engine\"\n",
    "    build_int8_engine_static(\n",
    "        onnx_path=onnx_path,\n",
    "        engine_path=engine_path,\n",
    "        calib_loader=calib_loader_map[bs],\n",
    "        max_calib_batches=200\n",
    "    )\n",
    "    engine_map[bs] = engine_path\n",
    "\n",
    "print(\"INT8 engines built:\", engine_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c18192-c88b-4817-b3be-f83ed04b4bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_int8_b128.engine\n",
      "  IN : input (128, 3, 32, 32) DataType.FLOAT\n",
      "  OUT: logits (128, 10) DataType.FLOAT\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "def inspect_engine(engine_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as rt:\n",
    "        eng = rt.deserialize_cuda_engine(f.read())\n",
    "    names = [eng.get_tensor_name(i) for i in range(eng.num_io_tensors)]\n",
    "    inp = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    print(engine_path)\n",
    "    print(\"  IN :\", inp, eng.get_tensor_shape(inp), eng.get_tensor_dtype(inp))\n",
    "    print(\"  OUT:\", out, eng.get_tensor_shape(out), eng.get_tensor_dtype(out))\n",
    "\n",
    "inspect_engine(\"alexnet_int8_b128.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c530db-5ed2-43f9-820a-8d75f4f55177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alexnet_int8_b1.engine\n",
      "  batch: 1\n",
      "  acc: 96.00% (first 50 batches)\n",
      "  latency ms: mean=0.135, p50=0.128, p90=0.136, p99=0.161\n",
      "  throughput: 7384.2 img/s\n",
      "\n",
      "alexnet_int8_b64.engine\n",
      "  batch: 64\n",
      "  acc: 88.66% (first 50 batches)\n",
      "  latency ms: mean=0.197, p50=0.197, p90=0.199, p99=0.206\n",
      "  throughput: 324801.9 img/s\n",
      "\n",
      "alexnet_int8_b128.engine\n",
      "  batch: 128\n",
      "  acc: 86.84% (first 50 batches)\n",
      "  latency ms: mean=0.243, p50=0.242, p90=0.245, p99=0.252\n",
      "  throughput: 527815.9 img/s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER_EVAL = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def load_engine(engine_path):\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER_EVAL) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    if engine is None:\n",
    "        raise RuntimeError(f\"Failed to load engine: {engine_path}\")\n",
    "    return engine, engine.create_execution_context()\n",
    "\n",
    "def get_io_names(engine):\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    return inp, out\n",
    "\n",
    "def trt_dtype_to_torch(dt):\n",
    "    return {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "        trt.DataType.BOOL:  torch.bool,\n",
    "    }[dt]\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_eval(engine_path, loader, warmup=50, iters=200, acc_batches=50):\n",
    "    engine, context = load_engine(engine_path)\n",
    "    inp_name, out_name = get_io_names(engine)\n",
    "\n",
    "    in_shape  = tuple(engine.get_tensor_shape(inp_name))\n",
    "    out_shape = tuple(engine.get_tensor_shape(out_name))\n",
    "    bsz = in_shape[0]\n",
    "\n",
    "    out_torch_dtype = trt_dtype_to_torch(engine.get_tensor_dtype(out_name))\n",
    "\n",
    "    # non-default stream (avoids TRT warning + better perf)\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # --------------- Accuracy (first acc_batches) ---------------\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(loader):\n",
    "        if bi >= acc_batches:\n",
    "            break\n",
    "        if x_cpu.shape[0] != bsz:\n",
    "            raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        stream.synchronize()\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += bsz\n",
    "\n",
    "    acc = 100.0 * correct / max(1, total)\n",
    "\n",
    "    # --------------- Latency / Throughput microbench ---------------\n",
    "    # Use one batch from loader\n",
    "    x_cpu, _ = next(iter(loader))\n",
    "    if x_cpu.shape[0] != bsz:\n",
    "        raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "    x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "    yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed runs (use CUDA events for accurate GPU timing)\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    times_ms = []\n",
    "    for _ in range(iters):\n",
    "        starter.record(stream)\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        ender.record(stream)\n",
    "        stream.synchronize()\n",
    "        times_ms.append(starter.elapsed_time(ender))\n",
    "\n",
    "    times_ms = np.array(times_ms, dtype=np.float64)\n",
    "    p50 = float(np.percentile(times_ms, 50))\n",
    "    p90 = float(np.percentile(times_ms, 90))\n",
    "    p99 = float(np.percentile(times_ms, 99))\n",
    "    mean = float(times_ms.mean())\n",
    "\n",
    "    # throughput (images/sec)\n",
    "    ips = (1000.0 / mean) * bsz\n",
    "\n",
    "    return {\n",
    "        \"engine\": engine_path,\n",
    "        \"batch\": bsz,\n",
    "        \"acc_%\": acc,\n",
    "        \"lat_mean_ms\": mean,\n",
    "        \"lat_p50_ms\": p50,\n",
    "        \"lat_p90_ms\": p90,\n",
    "        \"lat_p99_ms\": p99,\n",
    "        \"throughput_img_s\": ips,\n",
    "    }\n",
    "\n",
    "# ---- Run for b1/b64/b128 ----\n",
    "results = []\n",
    "results.append(trt_eval(engine_map[1],   test_loader_b1,   warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[64],  test_loader_b64,  warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[128], test_loader_b128, warmup=50, iters=200, acc_batches=50))\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n{r['engine']}\")\n",
    "    print(f\"  batch: {r['batch']}\")\n",
    "    print(f\"  acc: {r['acc_%']:.2f}% (first 50 batches)\")\n",
    "    print(f\"  latency ms: mean={r['lat_mean_ms']:.3f}, p50={r['lat_p50_ms']:.3f}, p90={r['lat_p90_ms']:.3f}, p99={r['lat_p99_ms']:.3f}\")\n",
    "    print(f\"  throughput: {r['throughput_img_s']:.1f} img/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb50c10-6590-42f1-8579-d031c3412d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (model used for export): 89.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch acc (model used for export):\", torch_acc(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35712b3c-8c6a-4641-bbdf-70a51fea4ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
