{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83a0b14-7a38-41dc-80cf-096a9f9503ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "assert device == \"cuda\", \"Need CUDA for TensorRT.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf318930-3bf0-4de0-9854-5c6c8687c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader_b1   = DataLoader(test_dataset, batch_size=1,   shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b64  = DataLoader(test_dataset, batch_size=64,  shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b128 = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb2e192-fdf1-4a59-bc49-6f83a36732ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[1]))\n",
    "\n",
    "from models.squeezenet_model import SqueezeNetCIFAR10, SqueezeNetCIFAR10_QAT  # <-- IMPORTANT: FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a998b044-df23-4a9d-b1b6-355c22f10ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: 0 unexpected: 0\n",
      "bad_missing (should be empty): []\n",
      "Loaded FP32 SqueezeNet from preconvert checkpoint âœ…\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "CKPT_PATH = \"../../pth/squeezenet_qat_preconvert.pth\"   # <-- your file\n",
    "\n",
    "def strip_preconvert_state_generic(ckpt: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in ckpt.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            k = k[len(\"module.\"):]\n",
    "\n",
    "        # drop QAT/observer/fake-quant bookkeeping keys\n",
    "        if (\"activation_post_process\" in k) or (\"fake_quant\" in k) or (\"weight_fake_quant\" in k):\n",
    "            continue\n",
    "        if k.startswith(\"activation_post_process_\"):\n",
    "            continue\n",
    "\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "def remap_by_shape_and_order(ckpt_state: dict, model_state: dict):\n",
    "    \"\"\"\n",
    "    Greedy match ckpt tensors to model tensors by (suffix, shape, dtype) in model key order.\n",
    "    Works when naming differs but the layer order/structure is the same.\n",
    "    \"\"\"\n",
    "    def suffix(k):\n",
    "        if k.endswith(\"running_mean\"): return \"running_mean\"\n",
    "        if k.endswith(\"running_var\"):  return \"running_var\"\n",
    "        if k.endswith(\"num_batches_tracked\"): return \"nbt\"\n",
    "        if k.endswith(\".weight\"): return \"weight\"\n",
    "        if k.endswith(\".bias\"):   return \"bias\"\n",
    "        return \"other\"\n",
    "\n",
    "    # buckets of ckpt keys by (suffix, shape, dtype)\n",
    "    buckets = {}\n",
    "    for k, v in ckpt_state.items():\n",
    "        if not torch.is_tensor(v):\n",
    "            continue\n",
    "        key = (suffix(k), tuple(v.shape), str(v.dtype))\n",
    "        buckets.setdefault(key, []).append(k)\n",
    "\n",
    "    used = set()\n",
    "    new_state = {}\n",
    "\n",
    "    for mk, mv in model_state.items():\n",
    "        if not torch.is_tensor(mv):\n",
    "            continue\n",
    "        key = (suffix(mk), tuple(mv.shape), str(mv.dtype))\n",
    "        cands = buckets.get(key, [])\n",
    "        pick = None\n",
    "        for ck in cands:\n",
    "            if ck not in used:\n",
    "                pick = ck\n",
    "                break\n",
    "        if pick is not None:\n",
    "            new_state[mk] = ckpt_state[pick]\n",
    "            used.add(pick)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "# ---- load ckpt (strip QAT junk) ----\n",
    "raw = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "ckpt_state = strip_preconvert_state_generic(raw)\n",
    "\n",
    "# ---- IMPORTANT: FP32 SqueezeNet class here (NOT QAT) ----\n",
    "model = SqueezeNetCIFAR10(num_classes=10)   \n",
    "\n",
    "model_state = model.state_dict()\n",
    "mapped = remap_by_shape_and_order(ckpt_state, model_state)\n",
    "\n",
    "missing, unexpected = model.load_state_dict(mapped, strict=False)\n",
    "\n",
    "bad_missing = [\n",
    "    k for k in missing\n",
    "    if k.endswith(\".weight\") or k.endswith(\".bias\")\n",
    "    or k.endswith(\"running_mean\") or k.endswith(\"running_var\")\n",
    "]\n",
    "\n",
    "print(\"missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "print(\"bad_missing (should be empty):\", bad_missing[:50])\n",
    "\n",
    "assert len(bad_missing) == 0, \n",
    "\n",
    "model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a405ef-b9ed-4c31-811f-adc9967aae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (full): 88.68\n",
      "Torch acc (first 50): 88.578125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_acc(model, loader, device=\"cuda\", max_batches=None):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if max_batches is not None and bi >= max_batches:\n",
    "            break\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Torch acc (full):\", torch_acc(model, test_loader, device=device))\n",
    "print(\"Torch acc (first 50):\", torch_acc(model, test_loader_b128, device=device, max_batches=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c861324f-ec23-4e3c-8746-15723a3d574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3531126/1230409203.py:15: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: squeezenet_fp32_b1_op13.onnx\n",
      "Exported: squeezenet_fp32_b64_op13.onnx\n",
      "Exported: squeezenet_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval().to(device)\n",
    "\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32, device=device),\n",
    "    64:  torch.randn(64,  3, 32, 32, device=device),\n",
    "    128: torch.randn(128, 3, 32, 32, device=device),\n",
    "}\n",
    "\n",
    "onnx_map = {}\n",
    "with torch.no_grad():  # not required, but safe\n",
    "    for bs, dummy in dummy_map.items():\n",
    "        out_path = f\"squeezenet_fp32_b{bs}_op13.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model, dummy, out_path,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"logits\"],\n",
    "            dynamic_axes=None,\n",
    "            dynamo=False\n",
    "        )\n",
    "        onnx_map[bs] = out_path\n",
    "        print(\"Exported:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a1cccf-4add-485f-a181-01738e8aa2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-14:03:43] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 717, GPU 4623 (MiB)\n",
      "[12/14/2025-14:03:43] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-14:03:43] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-14:03:43] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-14:03:43] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-14:03:43] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-14:03:43] [TRT] [I] Domain:           \n",
      "[12/14/2025-14:03:43] [TRT] [I] Model version:    0\n",
      "[12/14/2025-14:03:43] [TRT] [I] Doc string:       \n",
      "[12/14/2025-14:03:43] [TRT] [I] ----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3531126/530169322.py:77: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  config.int8_calibrator = EntropyCalibrator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-14:03:43] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +280, GPU +6, now: CPU 1199, GPU 4629 (MiB)\n",
      "[12/14/2025-14:03:43] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-14:03:43] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:03:44] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:03:44] [TRT] [I] Total Host Persistent Memory: 138336 bytes\n",
      "[12/14/2025-14:03:44] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:03:44] [TRT] [I] Max Scratch Memory: 4608 bytes\n",
      "[12/14/2025-14:03:44] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 59 steps to complete.\n",
      "[12/14/2025-14:03:44] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.574132ms to assign 4 blocks to 59 nodes requiring 933888 bytes.\n",
      "[12/14/2025-14:03:44] [TRT] [I] Total Activation Memory: 933888 bytes\n",
      "[12/14/2025-14:03:44] [TRT] [I] Total Weights Memory: 4685864 bytes\n",
      "[12/14/2025-14:03:44] [TRT] [I] Engine generation completed in 0.598904 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 5 (MiB)\n",
      "[12/14/2025-14:03:44] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 0 in 0.00752889 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 1 in 0.00688225 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 2 in 0.00645246 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 3 in 0.0067544 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 4 in 0.00640992 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 5 in 0.00641394 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 6 in 0.00639303 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 7 in 0.00640541 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 8 in 0.0064542 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 9 in 0.00642159 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 10 in 0.0064011 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 11 in 0.00643713 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 12 in 0.00640396 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 13 in 0.00643383 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 14 in 0.00641848 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 15 in 0.00641375 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 16 in 0.00651531 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 17 in 0.00643145 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 18 in 0.00642176 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 19 in 0.00652954 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 20 in 0.00633356 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 21 in 0.00637063 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 22 in 0.0063188 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 23 in 0.00635694 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 24 in 0.00636197 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 25 in 0.00625736 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 26 in 0.00629107 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 27 in 0.00625546 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 28 in 0.00636199 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 29 in 0.00636929 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 30 in 0.00638542 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 31 in 0.00632746 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 32 in 0.00630116 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 33 in 0.00633502 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 34 in 0.00652402 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 35 in 0.00629712 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 36 in 0.00635841 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 37 in 0.00651948 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 38 in 0.0062738 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 39 in 0.00630099 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 40 in 0.00630077 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 41 in 0.00630483 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 42 in 0.0062508 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 43 in 0.00630872 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 44 in 0.00628748 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 45 in 0.00628753 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 46 in 0.00630569 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 47 in 0.00628327 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 48 in 0.006286 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 49 in 0.00629217 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 50 in 0.00627084 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 51 in 0.0063008 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 52 in 0.00627646 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 53 in 0.00648906 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 54 in 0.00632388 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 55 in 0.00631433 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 56 in 0.00631896 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 57 in 0.00632357 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 58 in 0.00629466 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 59 in 0.00628995 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 60 in 0.0063021 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 61 in 0.00632999 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 62 in 0.00630718 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 63 in 0.00633411 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 64 in 0.00628999 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 65 in 0.00636098 seconds.\n",
      "[12/14/2025-14:03:44] [TRT] [I]   Calibrated batch 66 in 0.00629602 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 67 in 0.00628781 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 68 in 0.0062831 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 69 in 0.00630727 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 70 in 0.00632822 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 71 in 0.00633508 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 72 in 0.00632437 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 73 in 0.00648071 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 74 in 0.00628078 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 75 in 0.00628639 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 76 in 0.00631972 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 77 in 0.0062745 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 78 in 0.00627212 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 79 in 0.00630735 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 80 in 0.00629544 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 81 in 0.00626973 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 82 in 0.00628973 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 83 in 0.00627329 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 84 in 0.00628578 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 85 in 0.00628057 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 86 in 0.00626527 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 87 in 0.00627165 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 88 in 0.00622963 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 89 in 0.00650441 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 90 in 0.00630583 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 91 in 0.00629795 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 92 in 0.00629908 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 93 in 0.0065081 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 94 in 0.00629877 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 95 in 0.00629687 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 96 in 0.00630933 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 97 in 0.00631771 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 98 in 0.00632643 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 99 in 0.0062998 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 100 in 0.00629203 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 101 in 0.0062905 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 102 in 0.00629658 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 103 in 0.00629685 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 104 in 0.00632368 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 105 in 0.00630978 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 106 in 0.00628849 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 107 in 0.00627156 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 108 in 0.0065013 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 109 in 0.00630551 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 110 in 0.00632649 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 111 in 0.00631265 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 112 in 0.00630717 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 113 in 0.00630722 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 114 in 0.0064628 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 115 in 0.00628027 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 116 in 0.00629774 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 117 in 0.00628575 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 118 in 0.00627672 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 119 in 0.0062958 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 120 in 0.00627879 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 121 in 0.00632562 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 122 in 0.00627743 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 123 in 0.00630753 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 124 in 0.00631909 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 125 in 0.0062648 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 126 in 0.00628952 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 127 in 0.00631601 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 128 in 0.00628834 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 129 in 0.00647877 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 130 in 0.00631502 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 131 in 0.00647254 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 132 in 0.00627963 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 133 in 0.00630415 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 134 in 0.0062555 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 135 in 0.0063148 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 136 in 0.00630093 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 137 in 0.00630396 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 138 in 0.0063059 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 139 in 0.00629028 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 140 in 0.0062536 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 141 in 0.0062617 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 142 in 0.00636041 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 143 in 0.00629638 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 144 in 0.00631683 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 145 in 0.00630514 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 146 in 0.00650048 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 147 in 0.00631477 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 148 in 0.00634936 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 149 in 0.00629782 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 150 in 0.00633125 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 151 in 0.00632281 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 152 in 0.00632742 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 153 in 0.0063134 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 154 in 0.00633781 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 155 in 0.00632254 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 156 in 0.00630837 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 157 in 0.00629105 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 158 in 0.00629325 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 159 in 0.00630907 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 160 in 0.00630072 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 161 in 0.006299 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 162 in 0.00631753 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 163 in 0.00632877 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 164 in 0.00630723 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 165 in 0.00630006 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 166 in 0.00634341 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 167 in 0.00635368 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 168 in 0.00631568 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 169 in 0.00630859 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 170 in 0.00631206 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 171 in 0.00633766 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 172 in 0.00629338 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 173 in 0.00633158 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 174 in 0.0063214 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 175 in 0.00628869 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 176 in 0.00633243 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 177 in 0.00649989 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 178 in 0.00629208 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 179 in 0.00631509 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 180 in 0.00632728 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 181 in 0.00632414 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 182 in 0.00628453 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 183 in 0.00638566 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 184 in 0.00641557 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 185 in 0.00658459 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 186 in 0.00646719 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 187 in 0.0064035 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 188 in 0.00644567 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 189 in 0.00647502 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 190 in 0.00639237 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 191 in 0.00633177 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 192 in 0.0065492 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 193 in 0.00632671 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 194 in 0.00651314 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 195 in 0.00635163 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 196 in 0.00633682 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 197 in 0.00631171 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 198 in 0.00635032 seconds.\n",
      "[12/14/2025-14:03:45] [TRT] [I]   Calibrated batch 199 in 0.00630783 seconds.\n",
      "[12/14/2025-14:03:50] [TRT] [I]   Post Processing Calibration data in 4.95402 seconds.\n",
      "[12/14/2025-14:03:50] [TRT] [I] Calibration completed in 6.85969 seconds.\n",
      "[12/14/2025-14:03:50] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-14:03:50] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:05:11] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:05:12] [TRT] [I] Total Host Persistent Memory: 153280 bytes\n",
      "[12/14/2025-14:05:12] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:05:12] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-14:05:12] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 31 steps to complete.\n",
      "[12/14/2025-14:05:12] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.128282ms to assign 3 blocks to 31 nodes requiring 172032 bytes.\n",
      "[12/14/2025-14:05:12] [TRT] [I] Total Activation Memory: 172032 bytes\n",
      "[12/14/2025-14:05:12] [TRT] [I] Total Weights Memory: 904708 bytes\n",
      "[12/14/2025-14:05:12] [TRT] [I] Engine generation completed in 81.3037 seconds.\n",
      "[12/14/2025-14:05:12] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 9 MiB\n",
      "Saved: squeezenet_int8_b1.engine\n",
      "[12/14/2025-14:05:12] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-14:05:12] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-14:05:12] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-14:05:12] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-14:05:12] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-14:05:12] [TRT] [I] Domain:           \n",
      "[12/14/2025-14:05:12] [TRT] [I] Model version:    0\n",
      "[12/14/2025-14:05:12] [TRT] [I] Doc string:       \n",
      "[12/14/2025-14:05:12] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-14:05:13] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 1892, GPU 4891 (MiB)\n",
      "[12/14/2025-14:05:13] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-14:05:13] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:05:13] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:05:13] [TRT] [I] Total Host Persistent Memory: 133472 bytes\n",
      "[12/14/2025-14:05:13] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:05:13] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-14:05:13] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 55 steps to complete.\n",
      "[12/14/2025-14:05:13] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.479353ms to assign 4 blocks to 55 nodes requiring 59768832 bytes.\n",
      "[12/14/2025-14:05:13] [TRT] [I] Total Activation Memory: 59768832 bytes\n",
      "[12/14/2025-14:05:13] [TRT] [I] Total Weights Memory: 4685864 bytes\n",
      "[12/14/2025-14:05:13] [TRT] [I] Engine generation completed in 0.4002 seconds.\n",
      "[12/14/2025-14:05:13] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +57, now: CPU 0, GPU 62 (MiB)\n",
      "[12/14/2025-14:05:13] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-14:05:13] [TRT] [I]   Calibrated batch 0 in 0.132307 seconds.\n",
      "[12/14/2025-14:05:13] [TRT] [I]   Calibrated batch 1 in 0.0906364 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 2 in 0.0903317 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 3 in 0.0900815 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 4 in 0.0897749 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 5 in 0.0899289 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 6 in 0.0900996 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 7 in 0.0897458 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 8 in 0.0899501 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 9 in 0.0895552 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 10 in 0.0895326 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 11 in 0.0897874 seconds.\n",
      "[12/14/2025-14:05:14] [TRT] [I]   Calibrated batch 12 in 0.0899461 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 13 in 0.089967 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 14 in 0.090315 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 15 in 0.0896024 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 16 in 0.0900211 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 17 in 0.0902543 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 18 in 0.090067 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 19 in 0.094597 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 20 in 0.0988813 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 21 in 0.0987576 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 22 in 0.0987264 seconds.\n",
      "[12/14/2025-14:05:15] [TRT] [I]   Calibrated batch 23 in 0.0984126 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 24 in 0.0981437 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 25 in 0.101285 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 26 in 0.0984359 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 27 in 0.0982731 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 28 in 0.0979762 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 29 in 0.0981485 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 30 in 0.0981192 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 31 in 0.0983019 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 32 in 0.0981872 seconds.\n",
      "[12/14/2025-14:05:16] [TRT] [I]   Calibrated batch 33 in 0.098299 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 34 in 0.0981321 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 35 in 0.0984314 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 36 in 0.0986245 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 37 in 0.0984031 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 38 in 0.0986748 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 39 in 0.0985935 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 40 in 0.0986742 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 41 in 0.0987421 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 42 in 0.0990091 seconds.\n",
      "[12/14/2025-14:05:17] [TRT] [I]   Calibrated batch 43 in 0.0989428 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 44 in 0.0990052 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 45 in 0.0989935 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 46 in 0.0995048 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 47 in 0.0996969 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 48 in 0.0995575 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 49 in 0.0996345 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 50 in 0.0994734 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 51 in 0.0996503 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 52 in 0.0992756 seconds.\n",
      "[12/14/2025-14:05:18] [TRT] [I]   Calibrated batch 53 in 0.0991662 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 54 in 0.0989774 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 55 in 0.0987165 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 56 in 0.0983215 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 57 in 0.0987362 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 58 in 0.0985628 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 59 in 0.0985437 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 60 in 0.0984248 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 61 in 0.0985326 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 62 in 0.0980988 seconds.\n",
      "[12/14/2025-14:05:19] [TRT] [I]   Calibrated batch 63 in 0.0985997 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 64 in 0.0986897 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 65 in 0.0982934 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 66 in 0.098633 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 67 in 0.0987158 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 68 in 0.0987825 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 69 in 0.0981988 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 70 in 0.104013 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 71 in 0.0987584 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 72 in 0.0984962 seconds.\n",
      "[12/14/2025-14:05:20] [TRT] [I]   Calibrated batch 73 in 0.0983644 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 74 in 0.0983568 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 75 in 0.0986937 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 76 in 0.0984224 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 77 in 0.0984098 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 78 in 0.09824 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 79 in 0.098318 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 80 in 0.0987614 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 81 in 0.0985063 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 82 in 0.0984881 seconds.\n",
      "[12/14/2025-14:05:21] [TRT] [I]   Calibrated batch 83 in 0.0983116 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 84 in 0.0982658 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 85 in 0.098154 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 86 in 0.097968 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 87 in 0.0983209 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 88 in 0.0982826 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 89 in 0.0982081 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 90 in 0.0982438 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 91 in 0.097936 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 92 in 0.0980437 seconds.\n",
      "[12/14/2025-14:05:22] [TRT] [I]   Calibrated batch 93 in 0.0978189 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 94 in 0.0980687 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 95 in 0.0980566 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 96 in 0.0981816 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 97 in 0.0982859 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 98 in 0.0984188 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 99 in 0.0981781 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 100 in 0.0983134 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 101 in 0.0985587 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 102 in 0.0986119 seconds.\n",
      "[12/14/2025-14:05:23] [TRT] [I]   Calibrated batch 103 in 0.0983909 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 104 in 0.0987151 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 105 in 0.0980779 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 106 in 0.09808 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 107 in 0.09791 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 108 in 0.0980598 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 109 in 0.097875 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 110 in 0.0978951 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 111 in 0.0978709 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 112 in 0.0978608 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 113 in 0.0979187 seconds.\n",
      "[12/14/2025-14:05:24] [TRT] [I]   Calibrated batch 114 in 0.0978639 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 115 in 0.102298 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 116 in 0.100675 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 117 in 0.0978059 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 118 in 0.09745 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 119 in 0.0975875 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 120 in 0.0977523 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 121 in 0.0975929 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 122 in 0.0975641 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 123 in 0.0974429 seconds.\n",
      "[12/14/2025-14:05:25] [TRT] [I]   Calibrated batch 124 in 0.0976827 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 125 in 0.0974619 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 126 in 0.0974685 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 127 in 0.0974691 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 128 in 0.0977807 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 129 in 0.0975227 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 130 in 0.0975523 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 131 in 0.0973802 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 132 in 0.0973797 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 133 in 0.0975445 seconds.\n",
      "[12/14/2025-14:05:26] [TRT] [I]   Calibrated batch 134 in 0.0969786 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 135 in 0.0968947 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 136 in 0.0971605 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 137 in 0.0974591 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 138 in 0.0973799 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 139 in 0.0973805 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 140 in 0.0973513 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 141 in 0.097356 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 142 in 0.0972677 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 143 in 0.0970938 seconds.\n",
      "[12/14/2025-14:05:27] [TRT] [I]   Calibrated batch 144 in 0.0972972 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 145 in 0.0972131 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 146 in 0.097147 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 147 in 0.097279 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 148 in 0.097215 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 149 in 0.0973626 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 150 in 0.0972868 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 151 in 0.0971029 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 152 in 0.0970549 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 153 in 0.0972491 seconds.\n",
      "[12/14/2025-14:05:28] [TRT] [I]   Calibrated batch 154 in 0.0970453 seconds.\n",
      "[12/14/2025-14:05:29] [TRT] [I]   Calibrated batch 155 in 0.0973143 seconds.\n",
      "[12/14/2025-14:05:33] [TRT] [I]   Post Processing Calibration data in 4.755 seconds.\n",
      "[12/14/2025-14:05:33] [TRT] [I] Calibration completed in 20.4958 seconds.\n",
      "[12/14/2025-14:05:33] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-14:05:33] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:06:39] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:06:39] [TRT] [I] Total Host Persistent Memory: 153216 bytes\n",
      "[12/14/2025-14:06:39] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:06:39] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-14:06:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 31 steps to complete.\n",
      "[12/14/2025-14:06:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.132279ms to assign 3 blocks to 31 nodes requiring 11010048 bytes.\n",
      "[12/14/2025-14:06:39] [TRT] [I] Total Activation Memory: 11010048 bytes\n",
      "[12/14/2025-14:06:39] [TRT] [I] Total Weights Memory: 904708 bytes\n",
      "[12/14/2025-14:06:39] [TRT] [I] Engine generation completed in 65.7147 seconds.\n",
      "[12/14/2025-14:06:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 62 MiB\n",
      "Saved: squeezenet_int8_b64.engine\n",
      "[12/14/2025-14:06:39] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-14:06:39] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-14:06:39] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-14:06:39] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-14:06:39] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-14:06:39] [TRT] [I] Domain:           \n",
      "[12/14/2025-14:06:39] [TRT] [I] Model version:    0\n",
      "[12/14/2025-14:06:39] [TRT] [I] Doc string:       \n",
      "[12/14/2025-14:06:39] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-14:06:40] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 1892, GPU 4893 (MiB)\n",
      "[12/14/2025-14:06:40] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-14:06:40] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:06:40] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:06:40] [TRT] [I] Total Host Persistent Memory: 134752 bytes\n",
      "[12/14/2025-14:06:40] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:06:40] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-14:06:40] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 55 steps to complete.\n",
      "[12/14/2025-14:06:40] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.481928ms to assign 4 blocks to 55 nodes requiring 119537664 bytes.\n",
      "[12/14/2025-14:06:40] [TRT] [I] Total Activation Memory: 119537664 bytes\n",
      "[12/14/2025-14:06:40] [TRT] [I] Total Weights Memory: 4685864 bytes\n",
      "[12/14/2025-14:06:40] [TRT] [I] Engine generation completed in 0.38791 seconds.\n",
      "[12/14/2025-14:06:40] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +114, now: CPU 0, GPU 119 (MiB)\n",
      "[12/14/2025-14:06:40] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-14:06:41] [TRT] [I]   Calibrated batch 0 in 0.236397 seconds.\n",
      "[12/14/2025-14:06:41] [TRT] [I]   Calibrated batch 1 in 0.189338 seconds.\n",
      "[12/14/2025-14:06:41] [TRT] [I]   Calibrated batch 2 in 0.183477 seconds.\n",
      "[12/14/2025-14:06:41] [TRT] [I]   Calibrated batch 3 in 0.185595 seconds.\n",
      "[12/14/2025-14:06:41] [TRT] [I]   Calibrated batch 4 in 0.186634 seconds.\n",
      "[12/14/2025-14:06:42] [TRT] [I]   Calibrated batch 5 in 0.187102 seconds.\n",
      "[12/14/2025-14:06:42] [TRT] [I]   Calibrated batch 6 in 0.188358 seconds.\n",
      "[12/14/2025-14:06:42] [TRT] [I]   Calibrated batch 7 in 0.18969 seconds.\n",
      "[12/14/2025-14:06:42] [TRT] [I]   Calibrated batch 8 in 0.191005 seconds.\n",
      "[12/14/2025-14:06:42] [TRT] [I]   Calibrated batch 9 in 0.191194 seconds.\n",
      "[12/14/2025-14:06:43] [TRT] [I]   Calibrated batch 10 in 0.192736 seconds.\n",
      "[12/14/2025-14:06:43] [TRT] [I]   Calibrated batch 11 in 0.192673 seconds.\n",
      "[12/14/2025-14:06:43] [TRT] [I]   Calibrated batch 12 in 0.192626 seconds.\n",
      "[12/14/2025-14:06:43] [TRT] [I]   Calibrated batch 13 in 0.19254 seconds.\n",
      "[12/14/2025-14:06:43] [TRT] [I]   Calibrated batch 14 in 0.192986 seconds.\n",
      "[12/14/2025-14:06:44] [TRT] [I]   Calibrated batch 15 in 0.191836 seconds.\n",
      "[12/14/2025-14:06:44] [TRT] [I]   Calibrated batch 16 in 0.192711 seconds.\n",
      "[12/14/2025-14:06:44] [TRT] [I]   Calibrated batch 17 in 0.192488 seconds.\n",
      "[12/14/2025-14:06:44] [TRT] [I]   Calibrated batch 18 in 0.191217 seconds.\n",
      "[12/14/2025-14:06:44] [TRT] [I]   Calibrated batch 19 in 0.19157 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 20 in 0.191542 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 21 in 0.191265 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 22 in 0.191832 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 23 in 0.1927 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 24 in 0.193386 seconds.\n",
      "[12/14/2025-14:06:45] [TRT] [I]   Calibrated batch 25 in 0.1933 seconds.\n",
      "[12/14/2025-14:06:46] [TRT] [I]   Calibrated batch 26 in 0.196745 seconds.\n",
      "[12/14/2025-14:06:46] [TRT] [I]   Calibrated batch 27 in 0.193681 seconds.\n",
      "[12/14/2025-14:06:46] [TRT] [I]   Calibrated batch 28 in 0.195087 seconds.\n",
      "[12/14/2025-14:06:46] [TRT] [I]   Calibrated batch 29 in 0.194833 seconds.\n",
      "[12/14/2025-14:06:46] [TRT] [I]   Calibrated batch 30 in 0.193569 seconds.\n",
      "[12/14/2025-14:06:47] [TRT] [I]   Calibrated batch 31 in 0.194414 seconds.\n",
      "[12/14/2025-14:06:47] [TRT] [I]   Calibrated batch 32 in 0.193942 seconds.\n",
      "[12/14/2025-14:06:47] [TRT] [I]   Calibrated batch 33 in 0.192405 seconds.\n",
      "[12/14/2025-14:06:47] [TRT] [I]   Calibrated batch 34 in 0.192766 seconds.\n",
      "[12/14/2025-14:06:47] [TRT] [I]   Calibrated batch 35 in 0.192748 seconds.\n",
      "[12/14/2025-14:06:48] [TRT] [I]   Calibrated batch 36 in 0.192007 seconds.\n",
      "[12/14/2025-14:06:48] [TRT] [I]   Calibrated batch 37 in 0.192724 seconds.\n",
      "[12/14/2025-14:06:48] [TRT] [I]   Calibrated batch 38 in 0.19345 seconds.\n",
      "[12/14/2025-14:06:48] [TRT] [I]   Calibrated batch 39 in 0.191886 seconds.\n",
      "[12/14/2025-14:06:48] [TRT] [I]   Calibrated batch 40 in 0.192703 seconds.\n",
      "[12/14/2025-14:06:49] [TRT] [I]   Calibrated batch 41 in 0.192442 seconds.\n",
      "[12/14/2025-14:06:49] [TRT] [I]   Calibrated batch 42 in 0.191673 seconds.\n",
      "[12/14/2025-14:06:49] [TRT] [I]   Calibrated batch 43 in 0.192586 seconds.\n",
      "[12/14/2025-14:06:49] [TRT] [I]   Calibrated batch 44 in 0.192654 seconds.\n",
      "[12/14/2025-14:06:49] [TRT] [I]   Calibrated batch 45 in 0.192519 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 46 in 0.192657 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 47 in 0.191977 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 48 in 0.191111 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 49 in 0.191735 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 50 in 0.192215 seconds.\n",
      "[12/14/2025-14:06:50] [TRT] [I]   Calibrated batch 51 in 0.190927 seconds.\n",
      "[12/14/2025-14:06:51] [TRT] [I]   Calibrated batch 52 in 0.191874 seconds.\n",
      "[12/14/2025-14:06:51] [TRT] [I]   Calibrated batch 53 in 0.192187 seconds.\n",
      "[12/14/2025-14:06:51] [TRT] [I]   Calibrated batch 54 in 0.191546 seconds.\n",
      "[12/14/2025-14:06:51] [TRT] [I]   Calibrated batch 55 in 0.197276 seconds.\n",
      "[12/14/2025-14:06:51] [TRT] [I]   Calibrated batch 56 in 0.193311 seconds.\n",
      "[12/14/2025-14:06:52] [TRT] [I]   Calibrated batch 57 in 0.192161 seconds.\n",
      "[12/14/2025-14:06:52] [TRT] [I]   Calibrated batch 58 in 0.191609 seconds.\n",
      "[12/14/2025-14:06:52] [TRT] [I]   Calibrated batch 59 in 0.191266 seconds.\n",
      "[12/14/2025-14:06:52] [TRT] [I]   Calibrated batch 60 in 0.191432 seconds.\n",
      "[12/14/2025-14:06:52] [TRT] [I]   Calibrated batch 61 in 0.19073 seconds.\n",
      "[12/14/2025-14:06:53] [TRT] [I]   Calibrated batch 62 in 0.191473 seconds.\n",
      "[12/14/2025-14:06:53] [TRT] [I]   Calibrated batch 63 in 0.191356 seconds.\n",
      "[12/14/2025-14:06:53] [TRT] [I]   Calibrated batch 64 in 0.190383 seconds.\n",
      "[12/14/2025-14:06:53] [TRT] [I]   Calibrated batch 65 in 0.190324 seconds.\n",
      "[12/14/2025-14:06:53] [TRT] [I]   Calibrated batch 66 in 0.190521 seconds.\n",
      "[12/14/2025-14:06:54] [TRT] [I]   Calibrated batch 67 in 0.190567 seconds.\n",
      "[12/14/2025-14:06:54] [TRT] [I]   Calibrated batch 68 in 0.190593 seconds.\n",
      "[12/14/2025-14:06:54] [TRT] [I]   Calibrated batch 69 in 0.190437 seconds.\n",
      "[12/14/2025-14:06:54] [TRT] [I]   Calibrated batch 70 in 0.189978 seconds.\n",
      "[12/14/2025-14:06:54] [TRT] [I]   Calibrated batch 71 in 0.189856 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 72 in 0.190037 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 73 in 0.189687 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 74 in 0.189751 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 75 in 0.189432 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 76 in 0.189819 seconds.\n",
      "[12/14/2025-14:06:55] [TRT] [I]   Calibrated batch 77 in 0.188989 seconds.\n",
      "[12/14/2025-14:07:00] [TRT] [I]   Post Processing Calibration data in 4.73952 seconds.\n",
      "[12/14/2025-14:07:00] [TRT] [I] Calibration completed in 20.2104 seconds.\n",
      "[12/14/2025-14:07:00] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-14:07:00] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-14:08:03] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-14:08:04] [TRT] [I] Total Host Persistent Memory: 153216 bytes\n",
      "[12/14/2025-14:08:04] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-14:08:04] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-14:08:04] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 31 steps to complete.\n",
      "[12/14/2025-14:08:04] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.129724ms to assign 3 blocks to 31 nodes requiring 22020096 bytes.\n",
      "[12/14/2025-14:08:04] [TRT] [I] Total Activation Memory: 22020096 bytes\n",
      "[12/14/2025-14:08:04] [TRT] [I] Total Weights Memory: 904708 bytes\n",
      "[12/14/2025-14:08:04] [TRT] [I] Engine generation completed in 63.645 seconds.\n",
      "[12/14/2025-14:08:04] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 48 MiB, GPU 119 MiB\n",
      "Saved: squeezenet_int8_b128.engine\n",
      "INT8 engines built: {1: 'squeezenet_int8_b1.engine', 64: 'squeezenet_int8_b64.engine', 128: 'squeezenet_int8_b128.engine'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# INT8 Entropy Calibrator\n",
    "class EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calib_loader, max_batches=200, cache_file=\"calib.cache\"):\n",
    "        super().__init__()\n",
    "        self.data_iter = iter(calib_loader)\n",
    "        self.max_batches = max_batches\n",
    "        self.batch_count = 0\n",
    "        self.cache_file = cache_file\n",
    "\n",
    "        # initial shape (just to allocate something)\n",
    "        x0, _ = next(iter(calib_loader))\n",
    "        self.batch_size = x0.shape[0]\n",
    "        self.device_input = torch.empty_like(x0, device=\"cuda\")\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_batch(self, names):\n",
    "        if self.batch_count >= self.max_batches:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            x, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        self.batch_count += 1\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        # âœ… IMPORTANT: ensure buffer matches incoming shape\n",
    "        if self.device_input.numel() != x.numel():\n",
    "            self.device_input = torch.empty_like(x, device=\"cuda\")\n",
    "        else:\n",
    "            self.device_input = self.device_input.view_as(x)\n",
    "\n",
    "        self.device_input.copy_(x)\n",
    "        return [int(self.device_input.data_ptr())]\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        return None  # âœ… force fresh calibration\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "# Build static INT8 engine\n",
    "def build_int8_engine_static(onnx_path, engine_path, calib_loader, max_calib_batches=200):\n",
    "    cache_path = engine_path.replace(\".engine\", \".cache\")\n",
    "    if os.path.exists(cache_path):\n",
    "        os.remove(cache_path)\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed: {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        config.int8_calibrator = EntropyCalibrator(\n",
    "            calib_loader,\n",
    "            max_batches=max_calib_batches,\n",
    "            cache_file=cache_path\n",
    "        )\n",
    "\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"INT8 engine build failed: {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "\n",
    "# Build engines for each batch size\n",
    "calib_loader_map = {\n",
    "    1:   test_loader_b1,\n",
    "    64:  test_loader_b64,\n",
    "    128: test_loader_b128,\n",
    "}\n",
    "\n",
    "engine_map = {}\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"squeezenet_int8_b{bs}.engine\"\n",
    "    build_int8_engine_static(\n",
    "        onnx_path=onnx_path,\n",
    "        engine_path=engine_path,\n",
    "        calib_loader=calib_loader_map[bs],\n",
    "        max_calib_batches=200\n",
    "    )\n",
    "    engine_map[bs] = engine_path\n",
    "\n",
    "print(\"INT8 engines built:\", engine_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c18192-c88b-4817-b3be-f83ed04b4bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet_int8_b128.engine\n",
      "  IN : input (128, 3, 32, 32) DataType.FLOAT\n",
      "  OUT: logits (128, 10) DataType.FLOAT\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "def inspect_engine(engine_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as rt:\n",
    "        eng = rt.deserialize_cuda_engine(f.read())\n",
    "    names = [eng.get_tensor_name(i) for i in range(eng.num_io_tensors)]\n",
    "    inp = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    print(engine_path)\n",
    "    print(\"  IN :\", inp, eng.get_tensor_shape(inp), eng.get_tensor_dtype(inp))\n",
    "    print(\"  OUT:\", out, eng.get_tensor_shape(out), eng.get_tensor_dtype(out))\n",
    "\n",
    "inspect_engine(\"squeezenet_int8_b128.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c530db-5ed2-43f9-820a-8d75f4f55177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "squeezenet_int8_b1.engine\n",
      "  batch: 1\n",
      "  acc: 96.00% (first 50 batches)\n",
      "  latency ms: mean=0.369, p50=0.368, p90=0.373, p99=0.379\n",
      "  throughput: 2711.8 img/s\n",
      "\n",
      "squeezenet_int8_b64.engine\n",
      "  batch: 64\n",
      "  acc: 88.59% (first 50 batches)\n",
      "  latency ms: mean=0.492, p50=0.492, p90=0.495, p99=0.504\n",
      "  throughput: 130063.4 img/s\n",
      "\n",
      "squeezenet_int8_b128.engine\n",
      "  batch: 128\n",
      "  acc: 88.42% (first 50 batches)\n",
      "  latency ms: mean=0.580, p50=0.618, p90=0.623, p99=0.629\n",
      "  throughput: 220532.5 img/s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER_EVAL = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def load_engine(engine_path):\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER_EVAL) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    if engine is None:\n",
    "        raise RuntimeError(f\"Failed to load engine: {engine_path}\")\n",
    "    return engine, engine.create_execution_context()\n",
    "\n",
    "def get_io_names(engine):\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    return inp, out\n",
    "\n",
    "def trt_dtype_to_torch(dt):\n",
    "    return {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "        trt.DataType.BOOL:  torch.bool,\n",
    "    }[dt]\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_eval(engine_path, loader, warmup=50, iters=200, acc_batches=50):\n",
    "    engine, context = load_engine(engine_path)\n",
    "    inp_name, out_name = get_io_names(engine)\n",
    "\n",
    "    in_shape  = tuple(engine.get_tensor_shape(inp_name))\n",
    "    out_shape = tuple(engine.get_tensor_shape(out_name))\n",
    "    bsz = in_shape[0]\n",
    "\n",
    "    out_torch_dtype = trt_dtype_to_torch(engine.get_tensor_dtype(out_name))\n",
    "\n",
    "    # non-default stream (avoids TRT warning + better perf)\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # --------------- Accuracy (first acc_batches) ---------------\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(loader):\n",
    "        if bi >= acc_batches:\n",
    "            break\n",
    "        if x_cpu.shape[0] != bsz:\n",
    "            raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        stream.synchronize()\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += bsz\n",
    "\n",
    "    acc = 100.0 * correct / max(1, total)\n",
    "\n",
    "    # --------------- Latency / Throughput microbench ---------------\n",
    "    # Use one batch from loader\n",
    "    x_cpu, _ = next(iter(loader))\n",
    "    if x_cpu.shape[0] != bsz:\n",
    "        raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "    x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "    yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed runs (use CUDA events for accurate GPU timing)\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    times_ms = []\n",
    "    for _ in range(iters):\n",
    "        starter.record(stream)\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        ender.record(stream)\n",
    "        stream.synchronize()\n",
    "        times_ms.append(starter.elapsed_time(ender))\n",
    "\n",
    "    times_ms = np.array(times_ms, dtype=np.float64)\n",
    "    p50 = float(np.percentile(times_ms, 50))\n",
    "    p90 = float(np.percentile(times_ms, 90))\n",
    "    p99 = float(np.percentile(times_ms, 99))\n",
    "    mean = float(times_ms.mean())\n",
    "\n",
    "    # throughput (images/sec)\n",
    "    ips = (1000.0 / mean) * bsz\n",
    "\n",
    "    return {\n",
    "        \"engine\": engine_path,\n",
    "        \"batch\": bsz,\n",
    "        \"acc_%\": acc,\n",
    "        \"lat_mean_ms\": mean,\n",
    "        \"lat_p50_ms\": p50,\n",
    "        \"lat_p90_ms\": p90,\n",
    "        \"lat_p99_ms\": p99,\n",
    "        \"throughput_img_s\": ips,\n",
    "    }\n",
    "\n",
    "# ---- Run for b1/b64/b128 ----\n",
    "results = []\n",
    "results.append(trt_eval(engine_map[1],   test_loader_b1,   warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[64],  test_loader_b64,  warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[128], test_loader_b128, warmup=50, iters=200, acc_batches=50))\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n{r['engine']}\")\n",
    "    print(f\"  batch: {r['batch']}\")\n",
    "    print(f\"  acc: {r['acc_%']:.2f}% (first 50 batches)\")\n",
    "    print(f\"  latency ms: mean={r['lat_mean_ms']:.3f}, p50={r['lat_p50_ms']:.3f}, p90={r['lat_p90_ms']:.3f}, p99={r['lat_p99_ms']:.3f}\")\n",
    "    print(f\"  throughput: {r['throughput_img_s']:.1f} img/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb50c10-6590-42f1-8579-d031c3412d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (model used for export): 89.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch acc (model used for export):\", torch_acc(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35712b3c-8c6a-4641-bbdf-70a51fea4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 1.2M Dec 14 14:05 squeezenet_int8_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.4M Dec 14 14:06 squeezenet_int8_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.3M Dec 14 14:08 squeezenet_int8_b128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh squeezenet_int8_b1.engine\n",
    "!ls -lh squeezenet_int8_b64.engine\n",
    "!ls -lh squeezenet_int8_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40748e2c-b1a2-44b7-a7d4-850a1472596d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
