{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb18d4-66d7-421d-bf00-63460b5c60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128 CUDA: True\n",
      "TensorRT: 10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"TensorRT:\", trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20c95b9-71ae-476f-9fe5-3997105ecf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[1]))\n",
    "\n",
    "from models.resnet32_model import ResNet, ResNetQAT\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4998521-d0a3-4741-aa94-55ae31ca8183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd93386-e7a2-4028-8377-27899c33347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: 676 unexpected: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5287623/ipykernel_2244149/1867164493.py:13: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  tq.prepare_qat(model, inplace=True)\n",
      "/home1/ihsiao/.conda/envs/ee599/lib/python3.12/site-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNetQAT(\n",
       "  (conv1): Conv2d(\n",
       "    3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0070, 0.0007, 0.0011, 0.0032, 0.0062, 0.0042, 0.0023, 0.0022, 0.0016,\n",
       "              0.0021, 0.0015, 0.0012, 0.0021, 0.0019, 0.0020, 0.0052],\n",
       "             device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "             dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "        min_val=tensor([-0.8860, -0.1091, -0.2391, -0.4209, -0.7691, -0.6686, -0.1984, -0.4251,\n",
       "                -0.3105, -0.2907, -0.3131, -0.2347, -0.2437, -0.3173, -0.2896, -0.6297],\n",
       "               device='cuda:0'), max_val=tensor([0.3645, 0.1739, 0.2435, 0.3543, 0.5848, 0.1540, 0.3887, 0.2516, 0.2885,\n",
       "                0.3192, 0.1393, 0.2392, 0.2758, 0.2680, 0.4089, 0.3612],\n",
       "               device='cuda:0')\n",
       "      )\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.036514282226562, max_val=8.38115119934082)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.850094318389893, max_val=7.926459789276123)\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0026, 0.0022, 0.0014, 0.0029, 0.0027, 0.0012, 0.0015, 0.0012, 0.0032,\n",
       "                  0.0047, 0.0031, 0.0016, 0.0024, 0.0024, 0.0025, 0.0009],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.4252, -0.3349, -0.2434, -0.2967, -0.4456, -0.2388, -0.2746, -0.1953,\n",
       "                    -0.5781, -0.4023, -0.3055, -0.2817, -0.4613, -0.3658, -0.2294, -0.1948],\n",
       "                   device='cuda:0'), max_val=tensor([0.3298, 0.2632, 0.2291, 0.4220, 0.3170, 0.2090, 0.1947, 0.2458, 0.1965,\n",
       "                    0.6668, 0.5638, 0.2110, 0.3002, 0.2931, 0.4001, 0.1990],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-19.737489700317383, max_val=12.42553997039795)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.571686744689941, max_val=6.9666619300842285)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0044, 0.0028, 0.0019, 0.0017, 0.0019, 0.0020, 0.0018, 0.0019, 0.0041,\n",
       "                  0.0016, 0.0033, 0.0016, 0.0022, 0.0038, 0.0018, 0.0034],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.5678, -0.3051, -0.2607, -0.2726, -0.3378, -0.3204, -0.3012, -0.2738,\n",
       "                    -0.5376, -0.2670, -0.3093, -0.2678, -0.3321, -0.2503, -0.2773, -0.3482],\n",
       "                   device='cuda:0'), max_val=tensor([0.5887, 0.3780, 0.2855, 0.2037, 0.2315, 0.2804, 0.3383, 0.3380, 0.3372,\n",
       "                    0.1756, 0.4455, 0.1903, 0.2691, 0.5489, 0.3022, 0.4914],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.281794548034668, max_val=13.764013290405273)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.035954475402832, max_val=9.845771789550781)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0012, 0.0008, 0.0012, 0.0012, 0.0010, 0.0008, 0.0009, 0.0019, 0.0015,\n",
       "                  0.0014, 0.0011, 0.0007, 0.0013, 0.0011, 0.0017, 0.0013],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2633, -0.1864, -0.2215, -0.3099, -0.2336, -0.1935, -0.2076, -0.1682,\n",
       "                    -0.1925, -0.3193, -0.2541, -0.1949, -0.2602, -0.2164, -0.3922, -0.2718],\n",
       "                   device='cuda:0'), max_val=tensor([0.2444, 0.1376, 0.2394, 0.1590, 0.1890, 0.1774, 0.2059, 0.3513, 0.3473,\n",
       "                    0.1665, 0.2485, 0.1155, 0.2477, 0.2458, 0.2033, 0.2204],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-29.91118812561035, max_val=15.979536056518555)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.186165809631348, max_val=6.598876953125)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0039, 0.0022, 0.0019, 0.0024, 0.0036, 0.0040, 0.0023, 0.0015, 0.0018,\n",
       "                  0.0029, 0.0030, 0.0024, 0.0032, 0.0027, 0.0013, 0.0034],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.4870, -0.2958, -0.2645, -0.2864, -0.4494, -0.2847, -0.3511, -0.2468,\n",
       "                    -0.2514, -0.2761, -0.3363, -0.2391, -0.2758, -0.3674, -0.1966, -0.3730],\n",
       "                   device='cuda:0'), max_val=tensor([0.4364, 0.2846, 0.2102, 0.3100, 0.3511, 0.5275, 0.2601, 0.2712, 0.2390,\n",
       "                    0.3849, 0.3797, 0.3302, 0.4312, 0.2895, 0.2209, 0.4413],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.181863784790039, max_val=8.663678169250488)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.73765230178833, max_val=6.732733726501465)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0005, 0.0008, 0.0008, 0.0011, 0.0006, 0.0008, 0.0008, 0.0008, 0.0006,\n",
       "                  0.0008, 0.0009, 0.0011, 0.0008, 0.0013, 0.0005, 0.0013],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1582, -0.2385, -0.1939, -0.2691, -0.1445, -0.1686, -0.2524, -0.1841,\n",
       "                    -0.1891, -0.2114, -0.2701, -0.1727, -0.2414, -0.2451, -0.1328, -0.2247],\n",
       "                   device='cuda:0'), max_val=tensor([0.1438, 0.2345, 0.1902, 0.1596, 0.1741, 0.1857, 0.1200, 0.2403, 0.1172,\n",
       "                    0.2129, 0.2370, 0.3175, 0.1435, 0.2366, 0.1086, 0.2667],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-26.142513275146484, max_val=14.469823837280273)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.56202507019043, max_val=6.370251178741455)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0029, 0.0034, 0.0023, 0.0035, 0.0027, 0.0040, 0.0032, 0.0026, 0.0022,\n",
       "                  0.0041, 0.0038, 0.0016, 0.0019, 0.0030, 0.0039, 0.0035],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.3457, -0.3997, -0.2306, -0.3506, -0.2756, -0.5124, -0.3379, -0.3586,\n",
       "                    -0.2818, -0.3750, -0.3026, -0.2194, -0.2174, -0.3742, -0.4385, -0.4456],\n",
       "                   device='cuda:0'), max_val=tensor([0.3152, 0.3605, 0.2922, 0.4313, 0.3511, 0.3373, 0.4006, 0.1921, 0.2732,\n",
       "                    0.4939, 0.4649, 0.2129, 0.2766, 0.2428, 0.4672, 0.3359],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.050167083740234, max_val=8.351380348205566)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.603993892669678, max_val=5.641645908355713)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0009, 0.0005, 0.0013, 0.0007, 0.0007, 0.0007, 0.0008, 0.0006, 0.0008,\n",
       "                  0.0005, 0.0006, 0.0006, 0.0005, 0.0005, 0.0009, 0.0006],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2274, -0.1674, -0.4106, -0.1896, -0.1934, -0.1708, -0.2572, -0.1991,\n",
       "                    -0.2212, -0.1640, -0.1643, -0.1722, -0.1359, -0.1770, -0.1823, -0.2075],\n",
       "                   device='cuda:0'), max_val=tensor([0.1890, 0.1191, 0.1775, 0.1358, 0.1763, 0.1843, 0.1189, 0.1481, 0.1896,\n",
       "                    0.1484, 0.2264, 0.1277, 0.1661, 0.1422, 0.2244, 0.1380],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-26.194744110107422, max_val=18.055036544799805)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.543061256408691, max_val=5.523547172546387)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0043, 0.0042, 0.0024, 0.0049, 0.0034, 0.0042, 0.0037, 0.0049, 0.0034,\n",
       "                  0.0039, 0.0031, 0.0032, 0.0018, 0.0028, 0.0049, 0.0062],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.3863, -0.4650, -0.3024, -0.4769, -0.4186, -0.4712, -0.4435, -0.5566,\n",
       "                    -0.3914, -0.3340, -0.3635, -0.3204, -0.2252, -0.3126, -0.5366, -0.6552],\n",
       "                   device='cuda:0'), max_val=tensor([0.4467, 0.3870, 0.2334, 0.5297, 0.3930, 0.3152, 0.3126, 0.3605, 0.3803,\n",
       "                    0.4406, 0.3082, 0.3962, 0.2362, 0.3385, 0.4607, 0.5310],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.47882604598999, max_val=7.107201099395752)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.839853763580322, max_val=6.1970295906066895)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0005, 0.0006, 0.0005, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0007,\n",
       "                  0.0008, 0.0006, 0.0010, 0.0011, 0.0005, 0.0007, 0.0008],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1990, -0.2310, -0.1641, -0.1458, -0.1364, -0.2332, -0.2577, -0.1805,\n",
       "                    -0.1598, -0.1486, -0.2461, -0.3762, -0.3997, -0.1801, -0.2483, -0.3011],\n",
       "                   device='cuda:0'), max_val=tensor([0.1203, 0.1834, 0.1783, 0.2063, 0.1783, 0.1779, 0.2028, 0.1445, 0.2058,\n",
       "                    0.2203, 0.1967, 0.2388, 0.2560, 0.1893, 0.2055, 0.2544],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-36.06580352783203, max_val=28.559335708618164)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.102209568023682, max_val=5.455790042877197)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0059, 0.0025, 0.0030, 0.0052, 0.0047, 0.0022, 0.0025, 0.0031, 0.0032,\n",
       "                  0.0035, 0.0024, 0.0037, 0.0026, 0.0041, 0.0039, 0.0098],\n",
       "                 device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.3895, -0.3220, -0.2669, -0.5762, -0.2733, -0.2688, -0.3071, -0.1998,\n",
       "                    -0.3373, -0.2363, -0.2048, -0.4518, -0.3073, -0.4642, -0.2617, -0.4086],\n",
       "                   device='cuda:0'), max_val=tensor([0.6607, 0.3060, 0.3823, 0.5213, 0.5465, 0.2820, 0.2912, 0.3919, 0.3977,\n",
       "                    0.4229, 0.3384, 0.2972, 0.3282, 0.3938, 0.4893, 1.0322],\n",
       "                   device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.1057209968566895, max_val=9.43590259552002)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.400178909301758, max_val=6.553081035614014)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0005, 0.0006, 0.0006, 0.0008, 0.0009, 0.0006,\n",
       "                  0.0009, 0.0005, 0.0006, 0.0009, 0.0007, 0.0005, 0.0006, 0.0006, 0.0008,\n",
       "                  0.0009, 0.0005, 0.0007, 0.0006, 0.0007, 0.0005, 0.0006, 0.0007, 0.0009,\n",
       "                  0.0005, 0.0007, 0.0006, 0.0007, 0.0009], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1497, -0.1841, -0.2333, -0.1683, -0.1636, -0.1945, -0.1090, -0.2022,\n",
       "                    -0.1715, -0.1856, -0.1291, -0.1531, -0.1665, -0.1354, -0.1755, -0.2000,\n",
       "                    -0.1231, -0.1490, -0.1468, -0.1542, -0.1926, -0.1816, -0.1353, -0.1065,\n",
       "                    -0.1781, -0.2416, -0.1467, -0.1309, -0.1838, -0.2079, -0.1394, -0.1505],\n",
       "                   device='cuda:0'), max_val=tensor([0.1987, 0.1139, 0.1943, 0.1457, 0.1131, 0.1464, 0.2350, 0.2669, 0.1454,\n",
       "                    0.2438, 0.1729, 0.1903, 0.2742, 0.2033, 0.1517, 0.1715, 0.2347, 0.2402,\n",
       "                    0.2623, 0.1474, 0.1690, 0.1989, 0.2161, 0.1665, 0.1395, 0.1174, 0.2648,\n",
       "                    0.1714, 0.2052, 0.1031, 0.2009, 0.2746], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.58955383300781, max_val=28.230388641357422)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.834209442138672, max_val=6.687244415283203)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0021, 0.0015, 0.0019, 0.0024, 0.0014, 0.0022, 0.0023, 0.0016, 0.0017,\n",
       "                  0.0016, 0.0023, 0.0018, 0.0016, 0.0018, 0.0028, 0.0022, 0.0020, 0.0018,\n",
       "                  0.0019, 0.0016, 0.0025, 0.0019, 0.0028, 0.0022, 0.0018, 0.0019, 0.0022,\n",
       "                  0.0020, 0.0018, 0.0040, 0.0016, 0.0017], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2237, -0.2621, -0.2052, -0.2650, -0.2490, -0.3039, -0.3434, -0.2251,\n",
       "                    -0.2752, -0.2724, -0.3236, -0.2403, -0.2006, -0.2637, -0.2648, -0.2791,\n",
       "                    -0.2393, -0.2151, -0.2796, -0.2584, -0.2563, -0.2138, -0.2526, -0.2481,\n",
       "                    -0.1896, -0.2874, -0.3395, -0.2937, -0.2544, -0.4303, -0.2489, -0.2465],\n",
       "                   device='cuda:0'), max_val=tensor([0.3198, 0.2477, 0.2855, 0.3522, 0.2634, 0.2995, 0.3099, 0.2488, 0.2942,\n",
       "                    0.2232, 0.3003, 0.2699, 0.2456, 0.2558, 0.4003, 0.2955, 0.2859, 0.2802,\n",
       "                    0.2693, 0.2551, 0.3439, 0.2877, 0.4038, 0.3179, 0.2641, 0.3037, 0.3313,\n",
       "                    0.2156, 0.2622, 0.5589, 0.2580, 0.2321], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.486109733581543, max_val=14.804455757141113)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.466700077056885, max_val=6.231925964355469)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(\n",
       "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0017, 0.0009, 0.0017, 0.0020, 0.0023, 0.0017, 0.0015, 0.0012, 0.0014,\n",
       "                    0.0023, 0.0018, 0.0011, 0.0018, 0.0012, 0.0018, 0.0013, 0.0018, 0.0012,\n",
       "                    0.0009, 0.0026, 0.0022, 0.0021, 0.0012, 0.0013, 0.0012, 0.0020, 0.0027,\n",
       "                    0.0016, 0.0038, 0.0023, 0.0033, 0.0020], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                    0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "            (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "              min_val=tensor([-0.2823, -0.1065, -0.1111, -0.2494, -0.3818, -0.1684, -0.1867, -0.2527,\n",
       "                      -0.2548, -0.2237, -0.0955, -0.1590, -0.2644, -0.2172, -0.2798, -0.2207,\n",
       "                      -0.1653, -0.1940, -0.1512, -0.2330, -0.1829, -0.1876, -0.2367, -0.2017,\n",
       "                      -0.2286, -0.1287, -0.2389, -0.2590, -0.3271, -0.2610, -0.1866, -0.3074],\n",
       "                     device='cuda:0'), max_val=tensor([0.1730, 0.1972, 0.2821, 0.3257, 0.2152, 0.2797, 0.2377, 0.0995, 0.1898,\n",
       "                      0.3756, 0.2911, 0.2195, 0.2208, 0.1862, 0.1435, 0.1576, 0.2897, 0.2412,\n",
       "                      0.1631, 0.3790, 0.3505, 0.3088, 0.1035, 0.2333, 0.1371, 0.3304, 0.4134,\n",
       "                      0.0805, 0.5223, 0.3180, 0.4679, 0.1535], device='cuda:0')\n",
       "            )\n",
       "          )\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.213207244873047, max_val=9.791633605957031)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.138122081756592, max_val=6.157686233520508)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0007, 0.0009, 0.0007, 0.0006, 0.0008, 0.0008, 0.0011, 0.0010, 0.0006,\n",
       "                  0.0009, 0.0006, 0.0014, 0.0004, 0.0005, 0.0007, 0.0005, 0.0008, 0.0009,\n",
       "                  0.0006, 0.0007, 0.0008, 0.0006, 0.0006, 0.0008, 0.0007, 0.0005, 0.0008,\n",
       "                  0.0006, 0.0008, 0.0004, 0.0008, 0.0006], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1923, -0.1700, -0.1704, -0.1588, -0.1781, -0.1555, -0.2402, -0.1533,\n",
       "                    -0.1817, -0.1719, -0.1795, -0.1911, -0.1445, -0.1517, -0.1421, -0.1293,\n",
       "                    -0.1748, -0.2470, -0.1358, -0.1583, -0.2135, -0.1220, -0.1690, -0.2021,\n",
       "                    -0.1503, -0.1452, -0.1731, -0.1462, -0.2066, -0.1312, -0.1985, -0.1549],\n",
       "                   device='cuda:0'), max_val=tensor([0.1405, 0.2310, 0.2089, 0.1705, 0.2006, 0.2252, 0.1826, 0.2605, 0.2117,\n",
       "                    0.2441, 0.1646, 0.3386, 0.1118, 0.1495, 0.1794, 0.1511, 0.2038, 0.1451,\n",
       "                    0.1784, 0.1816, 0.1332, 0.1728, 0.1604, 0.1732, 0.2099, 0.1226, 0.2029,\n",
       "                    0.1798, 0.2310, 0.1052, 0.1732, 0.1533], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.822160720825195, max_val=15.471019744873047)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.904541015625, max_val=6.07037353515625)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0026, 0.0016, 0.0032, 0.0021, 0.0017, 0.0030, 0.0027, 0.0018, 0.0022,\n",
       "                  0.0021, 0.0020, 0.0020, 0.0021, 0.0024, 0.0021, 0.0027, 0.0007, 0.0027,\n",
       "                  0.0028, 0.0023, 0.0024, 0.0023, 0.0019, 0.0014, 0.0024, 0.0017, 0.0018,\n",
       "                  0.0016, 0.0019, 0.0017, 0.0014, 0.0025], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2402, -0.2397, -0.3836, -0.2131, -0.2679, -0.3461, -0.2316, -0.2463,\n",
       "                    -0.3201, -0.2531, -0.2362, -0.2770, -0.1811, -0.3132, -0.2407, -0.3404,\n",
       "                    -0.1283, -0.2528, -0.2731, -0.2967, -0.2481, -0.2280, -0.2656, -0.2332,\n",
       "                    -0.3230, -0.2554, -0.2464, -0.2242, -0.2367, -0.2403, -0.2110, -0.2269],\n",
       "                   device='cuda:0'), max_val=tensor([0.3481, 0.2137, 0.2484, 0.2935, 0.2201, 0.3075, 0.3532, 0.2261, 0.2311,\n",
       "                    0.2789, 0.2532, 0.2578, 0.2775, 0.2025, 0.2654, 0.2956, 0.1294, 0.3559,\n",
       "                    0.3524, 0.2850, 0.3106, 0.3030, 0.2667, 0.1892, 0.2787, 0.2367, 0.2646,\n",
       "                    0.1859, 0.2642, 0.2199, 0.2117, 0.3128], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.472311973571777, max_val=11.33918285369873)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.6330695152282715, max_val=6.895839691162109)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0005, 0.0005, 0.0009, 0.0007, 0.0005, 0.0008, 0.0007, 0.0003, 0.0009,\n",
       "                  0.0004, 0.0006, 0.0005, 0.0006, 0.0007, 0.0004, 0.0007, 0.0008, 0.0006,\n",
       "                  0.0006, 0.0005, 0.0006, 0.0005, 0.0009, 0.0005, 0.0008, 0.0004, 0.0007,\n",
       "                  0.0003, 0.0005, 0.0005, 0.0005, 0.0005], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1683, -0.1591, -0.1399, -0.1601, -0.1592, -0.1818, -0.1698, -0.1080,\n",
       "                    -0.1603, -0.1356, -0.1315, -0.1571, -0.1745, -0.1390, -0.1340, -0.2175,\n",
       "                    -0.1491, -0.1495, -0.1881, -0.1816, -0.1896, -0.1595, -0.1700, -0.1318,\n",
       "                    -0.2307, -0.0967, -0.1788, -0.1334, -0.1564, -0.1737, -0.1330, -0.1637],\n",
       "                   device='cuda:0'), max_val=tensor([0.1412, 0.1645, 0.2402, 0.2035, 0.1660, 0.2001, 0.1849, 0.0963, 0.2059,\n",
       "                    0.1643, 0.2079, 0.1463, 0.1967, 0.2089, 0.1333, 0.1811, 0.2459, 0.1791,\n",
       "                    0.1589, 0.1414, 0.1149, 0.1151, 0.2272, 0.1785, 0.2122, 0.1646, 0.1920,\n",
       "                    0.1256, 0.1401, 0.1578, 0.1629, 0.1483], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-26.77366828918457, max_val=24.232688903808594)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.220459938049316, max_val=6.096107482910156)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0017, 0.0016, 0.0039, 0.0024, 0.0017, 0.0042, 0.0033, 0.0040, 0.0027,\n",
       "                  0.0028, 0.0025, 0.0013, 0.0024, 0.0031, 0.0035, 0.0044, 0.0027, 0.0031,\n",
       "                  0.0017, 0.0034, 0.0045, 0.0024, 0.0019, 0.0030, 0.0023, 0.0024, 0.0029,\n",
       "                  0.0020, 0.0018, 0.0028, 0.0021, 0.0020], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2368, -0.1815, -0.4177, -0.2683, -0.2368, -0.3164, -0.3247, -0.4112,\n",
       "                    -0.3504, -0.3388, -0.2670, -0.1731, -0.2260, -0.3703, -0.3856, -0.3419,\n",
       "                    -0.3159, -0.2610, -0.2078, -0.3883, -0.4952, -0.2715, -0.2397, -0.3595,\n",
       "                    -0.2280, -0.3077, -0.3366, -0.2514, -0.1945, -0.3086, -0.2609, -0.2183],\n",
       "                   device='cuda:0'), max_val=tensor([0.2427, 0.2449, 0.4374, 0.2954, 0.2466, 0.4594, 0.3744, 0.4343, 0.2307,\n",
       "                    0.3350, 0.3049, 0.1855, 0.3000, 0.2627, 0.3875, 0.4990, 0.2164, 0.3750,\n",
       "                    0.2339, 0.3065, 0.3689, 0.2776, 0.2251, 0.3118, 0.2790, 0.2736, 0.3020,\n",
       "                    0.2002, 0.2392, 0.3249, 0.2392, 0.2469], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.459467887878418, max_val=10.313056945800781)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.377049446105957, max_val=6.020021915435791)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0005, 0.0005, 0.0004, 0.0005, 0.0005, 0.0007, 0.0003, 0.0006, 0.0005,\n",
       "                  0.0006, 0.0005, 0.0006, 0.0004, 0.0006, 0.0007, 0.0005, 0.0006, 0.0005,\n",
       "                  0.0005, 0.0006, 0.0004, 0.0005, 0.0005, 0.0009, 0.0006, 0.0004, 0.0012,\n",
       "                  0.0004, 0.0004, 0.0005, 0.0005, 0.0005], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1673, -0.1241, -0.1458, -0.1280, -0.1599, -0.1210, -0.1196, -0.1093,\n",
       "                    -0.1408, -0.2230, -0.1299, -0.1344, -0.1140, -0.1601, -0.1700, -0.1570,\n",
       "                    -0.1887, -0.1147, -0.1401, -0.1299, -0.1575, -0.1687, -0.1372, -0.1784,\n",
       "                    -0.1742, -0.1438, -0.1611, -0.1418, -0.1317, -0.1563, -0.1503, -0.1424],\n",
       "                   device='cuda:0'), max_val=tensor([0.1517, 0.1888, 0.1089, 0.1788, 0.1717, 0.1960, 0.1196, 0.2023, 0.1793,\n",
       "                    0.1500, 0.1625, 0.1959, 0.1526, 0.1754, 0.1972, 0.1207, 0.1889, 0.1654,\n",
       "                    0.1819, 0.2249, 0.1657, 0.1305, 0.1590, 0.3089, 0.1727, 0.1237, 0.3190,\n",
       "                    0.1118, 0.1463, 0.1324, 0.1956, 0.1547], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-26.52031898498535, max_val=24.016599655151367)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.433145523071289, max_val=5.8060832023620605)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0024, 0.0028, 0.0033, 0.0019, 0.0010, 0.0046, 0.0034, 0.0044, 0.0027,\n",
       "                  0.0025, 0.0031, 0.0019, 0.0024, 0.0027, 0.0045, 0.0032, 0.0036, 0.0040,\n",
       "                  0.0026, 0.0050, 0.0053, 0.0033, 0.0039, 0.0039, 0.0016, 0.0044, 0.0020,\n",
       "                  0.0033, 0.0032, 0.0046, 0.0016, 0.0041], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1940, -0.3300, -0.3714, -0.2483, -0.1430, -0.3740, -0.3379, -0.4016,\n",
       "                    -0.2389, -0.3065, -0.2818, -0.2389, -0.2506, -0.3136, -0.4427, -0.2562,\n",
       "                    -0.3667, -0.2381, -0.2452, -0.3644, -0.4175, -0.3494, -0.3349, -0.4261,\n",
       "                    -0.2079, -0.2980, -0.2218, -0.3620, -0.3487, -0.3280, -0.1631, -0.2989],\n",
       "                   device='cuda:0'), max_val=tensor([0.3110, 0.2974, 0.3287, 0.2458, 0.1826, 0.4613, 0.3814, 0.4685, 0.3401,\n",
       "                    0.2685, 0.3629, 0.2234, 0.2789, 0.3009, 0.4542, 0.3779, 0.3850, 0.4671,\n",
       "                    0.3004, 0.5258, 0.5300, 0.2981, 0.4340, 0.3930, 0.1619, 0.4942, 0.2492,\n",
       "                    0.3396, 0.2624, 0.4889, 0.2237, 0.4271], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.704087257385254, max_val=9.7802152633667)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.775590896606445, max_val=7.57703971862793)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([2.8136e-04, 3.8011e-04, 3.7507e-04, 3.9035e-04, 7.1024e-04, 4.2385e-04,\n",
       "                  4.5809e-04, 3.1949e-04, 4.0371e-04, 3.9025e-04, 3.9782e-04, 5.0670e-04,\n",
       "                  1.2916e-04, 3.8368e-04, 7.5509e-04, 4.2146e-04, 3.8636e-04, 2.7086e-04,\n",
       "                  4.1397e-04, 3.6036e-04, 4.6194e-04, 3.5391e-04, 4.8790e-04, 3.3911e-04,\n",
       "                  5.5924e-05, 5.7661e-04, 4.4366e-04, 4.5335e-04, 4.6364e-04, 3.7773e-04,\n",
       "                  4.4285e-04, 3.9646e-04], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1324, -0.1168, -0.1065, -0.1027, -0.1304, -0.1157, -0.1260, -0.1165,\n",
       "                    -0.1071, -0.1109, -0.1281, -0.1378, -0.0574, -0.1083, -0.1440, -0.1423,\n",
       "                    -0.1388, -0.1164, -0.1453, -0.1224, -0.1423, -0.1342, -0.1638, -0.0863,\n",
       "                    -0.0321, -0.1129, -0.1332, -0.1467, -0.1252, -0.1325, -0.1631, -0.1297],\n",
       "                   device='cuda:0'), max_val=tensor([0.0967, 0.1411, 0.1468, 0.1574, 0.2192, 0.1619, 0.1726, 0.1027, 0.1672,\n",
       "                    0.1628, 0.1468, 0.1698, 0.0649, 0.1628, 0.2561, 0.1552, 0.1486, 0.1175,\n",
       "                    0.1550, 0.1402, 0.1553, 0.1259, 0.1729, 0.1265, 0.0418, 0.2291, 0.1976,\n",
       "                    0.1619, 0.1709, 0.1713, 0.1730, 0.1569], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-34.08927536010742, max_val=35.984336853027344)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.579314231872559, max_val=6.670157432556152)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0016, 0.0031, 0.0039, 0.0026, 0.0022, 0.0057, 0.0045, 0.0038, 0.0016,\n",
       "                  0.0031, 0.0030, 0.0018, 0.0038, 0.0022, 0.0038, 0.0012, 0.0025, 0.0024,\n",
       "                  0.0026, 0.0040, 0.0046, 0.0038, 0.0030, 0.0043, 0.0034, 0.0021, 0.0024,\n",
       "                  0.0043, 0.0038, 0.0024, 0.0018, 0.0045], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1943, -0.3401, -0.2507, -0.2339, -0.2618, -0.3299, -0.3911, -0.2777,\n",
       "                    -0.1831, -0.2287, -0.3243, -0.2297, -0.3296, -0.2434, -0.3800, -0.1590,\n",
       "                    -0.2661, -0.2227, -0.2412, -0.2362, -0.3639, -0.2929, -0.3043, -0.4225,\n",
       "                    -0.2621, -0.2002, -0.2851, -0.4431, -0.3686, -0.2277, -0.2390, -0.3799],\n",
       "                   device='cuda:0'), max_val=tensor([0.2175, 0.2782, 0.4279, 0.3044, 0.2247, 0.5515, 0.4553, 0.4272, 0.2100,\n",
       "                    0.3729, 0.2988, 0.2043, 0.3989, 0.2531, 0.3898, 0.1646, 0.2831, 0.3078,\n",
       "                    0.3024, 0.4285, 0.4668, 0.3985, 0.3258, 0.4389, 0.3723, 0.2672, 0.2718,\n",
       "                    0.3648, 0.3853, 0.2893, 0.2274, 0.4415], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.336091995239258, max_val=11.933639526367188)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.672248840332031, max_val=6.9482221603393555)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0006, 0.0005, 0.0004, 0.0005, 0.0004, 0.0004, 0.0005, 0.0005, 0.0005,\n",
       "                  0.0004, 0.0005, 0.0004, 0.0004, 0.0005, 0.0005, 0.0005, 0.0005, 0.0004,\n",
       "                  0.0005, 0.0004, 0.0005, 0.0004, 0.0004, 0.0005, 0.0004, 0.0004, 0.0004,\n",
       "                  0.0005, 0.0004, 0.0004, 0.0006, 0.0005, 0.0006, 0.0005, 0.0006, 0.0004,\n",
       "                  0.0005, 0.0004, 0.0004, 0.0005, 0.0004, 0.0005, 0.0005, 0.0003, 0.0004,\n",
       "                  0.0004, 0.0005, 0.0006, 0.0004, 0.0006, 0.0004, 0.0005, 0.0003, 0.0005,\n",
       "                  0.0004, 0.0004, 0.0007, 0.0005, 0.0006, 0.0005, 0.0004, 0.0004, 0.0005,\n",
       "                  0.0005], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1241, -0.1255, -0.1589, -0.1445, -0.1520, -0.1535, -0.1402, -0.1757,\n",
       "                    -0.1427, -0.1348, -0.1949, -0.1359, -0.1516, -0.1329, -0.1624, -0.1559,\n",
       "                    -0.1396, -0.1336, -0.1430, -0.1205, -0.1282, -0.1371, -0.1245, -0.1402,\n",
       "                    -0.1381, -0.1348, -0.1430, -0.1133, -0.1429, -0.1273, -0.1412, -0.1238,\n",
       "                    -0.1194, -0.1303, -0.1546, -0.1409, -0.1447, -0.1277, -0.1487, -0.1336,\n",
       "                    -0.1250, -0.1628, -0.1337, -0.1188, -0.1521, -0.1361, -0.1275, -0.1313,\n",
       "                    -0.1183, -0.1195, -0.1381, -0.0911, -0.1241, -0.1511, -0.1246, -0.1162,\n",
       "                    -0.1565, -0.1506, -0.1348, -0.1797, -0.1249, -0.1423, -0.1562, -0.1259],\n",
       "                   device='cuda:0'), max_val=tensor([0.1956, 0.1784, 0.1235, 0.1566, 0.1472, 0.1327, 0.1542, 0.1535, 0.1829,\n",
       "                    0.1472, 0.1015, 0.1439, 0.1310, 0.1778, 0.1927, 0.1701, 0.1877, 0.1514,\n",
       "                    0.1730, 0.1453, 0.1880, 0.1256, 0.1460, 0.1855, 0.1094, 0.1520, 0.1366,\n",
       "                    0.1634, 0.1680, 0.1548, 0.1998, 0.1711, 0.1851, 0.1487, 0.1823, 0.1042,\n",
       "                    0.1579, 0.1458, 0.1458, 0.1727, 0.1636, 0.1468, 0.1691, 0.1294, 0.1422,\n",
       "                    0.1246, 0.1747, 0.2022, 0.1439, 0.2036, 0.1122, 0.1862, 0.1394, 0.1760,\n",
       "                    0.1430, 0.1447, 0.2143, 0.1765, 0.2147, 0.1318, 0.1184, 0.1359, 0.1649,\n",
       "                    0.1626], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-38.850303649902344, max_val=37.19975280761719)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.165989875793457, max_val=6.592868328094482)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0025, 0.0020, 0.0031, 0.0030, 0.0023, 0.0027, 0.0033, 0.0026, 0.0025,\n",
       "                  0.0020, 0.0022, 0.0026, 0.0021, 0.0025, 0.0018, 0.0023, 0.0022, 0.0026,\n",
       "                  0.0023, 0.0024, 0.0025, 0.0018, 0.0018, 0.0031, 0.0024, 0.0023, 0.0024,\n",
       "                  0.0025, 0.0018, 0.0022, 0.0027, 0.0029, 0.0023, 0.0021, 0.0029, 0.0040,\n",
       "                  0.0019, 0.0018, 0.0019, 0.0024, 0.0018, 0.0022, 0.0021, 0.0019, 0.0027,\n",
       "                  0.0022, 0.0016, 0.0026, 0.0023, 0.0018, 0.0023, 0.0018, 0.0020, 0.0028,\n",
       "                  0.0026, 0.0026, 0.0020, 0.0026, 0.0020, 0.0023, 0.0021, 0.0022, 0.0021,\n",
       "                  0.0019], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.2350, -0.1985, -0.3020, -0.3840, -0.2155, -0.2207, -0.2781, -0.2514,\n",
       "                    -0.2340, -0.2652, -0.2604, -0.3339, -0.2056, -0.2646, -0.2138, -0.3116,\n",
       "                    -0.2921, -0.3058, -0.2326, -0.3084, -0.2232, -0.1952, -0.2379, -0.2592,\n",
       "                    -0.2594, -0.2462, -0.2648, -0.2226, -0.2291, -0.2791, -0.2471, -0.2238,\n",
       "                    -0.2302, -0.2336, -0.3076, -0.2783, -0.2333, -0.2152, -0.2620, -0.2364,\n",
       "                    -0.2170, -0.2483, -0.2004, -0.1961, -0.2452, -0.2972, -0.2197, -0.2882,\n",
       "                    -0.2940, -0.2511, -0.2230, -0.2350, -0.2523, -0.2601, -0.2432, -0.3346,\n",
       "                    -0.2621, -0.2617, -0.2047, -0.2016, -0.3012, -0.2997, -0.2784, -0.2680],\n",
       "                   device='cuda:0'), max_val=tensor([0.3345, 0.2876, 0.4147, 0.3545, 0.3047, 0.3407, 0.4410, 0.3677, 0.3297,\n",
       "                    0.2868, 0.2937, 0.2884, 0.2888, 0.3352, 0.2791, 0.3064, 0.2785, 0.3450,\n",
       "                    0.3406, 0.2982, 0.3526, 0.2764, 0.2444, 0.4056, 0.3276, 0.3066, 0.3300,\n",
       "                    0.3343, 0.2723, 0.2813, 0.3467, 0.3895, 0.3276, 0.2897, 0.3756, 0.5230,\n",
       "                    0.2538, 0.2544, 0.2343, 0.3372, 0.2587, 0.2955, 0.3037, 0.2684, 0.3470,\n",
       "                    0.2662, 0.2406, 0.3747, 0.2645, 0.2182, 0.3046, 0.2498, 0.2552, 0.3699,\n",
       "                    0.3635, 0.3067, 0.2889, 0.3503, 0.3067, 0.3219, 0.2668, 0.2590, 0.2254,\n",
       "                    0.2597], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.837808609008789, max_val=11.3966703414917)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.993860244750977, max_val=5.883262634277344)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(\n",
       "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0013, 0.0011, 0.0005, 0.0009, 0.0012, 0.0010, 0.0011, 0.0009, 0.0018,\n",
       "                    0.0010, 0.0016, 0.0004, 0.0020, 0.0010, 0.0015, 0.0008, 0.0010, 0.0004,\n",
       "                    0.0012, 0.0013, 0.0013, 0.0015, 0.0013, 0.0010, 0.0016, 0.0008, 0.0017,\n",
       "                    0.0017, 0.0009, 0.0007, 0.0012, 0.0009, 0.0015, 0.0011, 0.0008, 0.0014,\n",
       "                    0.0011, 0.0009, 0.0008, 0.0021, 0.0015, 0.0013, 0.0013, 0.0010, 0.0009,\n",
       "                    0.0017, 0.0012, 0.0013, 0.0005, 0.0013, 0.0015, 0.0010, 0.0012, 0.0010,\n",
       "                    0.0012, 0.0010, 0.0014, 0.0014, 0.0022, 0.0007, 0.0012, 0.0014, 0.0012,\n",
       "                    0.0008], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                   dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "            (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "              min_val=tensor([-0.1842, -0.1820, -0.1178, -0.1490, -0.2041, -0.1806, -0.1985, -0.1725,\n",
       "                      -0.1752, -0.1119, -0.1605, -0.1148, -0.2717, -0.1634, -0.2662, -0.1550,\n",
       "                      -0.1782, -0.1204, -0.1961, -0.2272, -0.1653, -0.1595, -0.2270, -0.1184,\n",
       "                      -0.2094, -0.1235, -0.2166, -0.1907, -0.1793, -0.1528, -0.2382, -0.0989,\n",
       "                      -0.2640, -0.2195, -0.1720, -0.1688, -0.1383, -0.1819, -0.1552, -0.1695,\n",
       "                      -0.1496, -0.1339, -0.1739, -0.1799, -0.1299, -0.2985, -0.2130, -0.2467,\n",
       "                      -0.0998, -0.2501, -0.1590, -0.2069, -0.1952, -0.1970, -0.2194, -0.1845,\n",
       "                      -0.1653, -0.2184, -0.2122, -0.1173, -0.1551, -0.1857, -0.2006, -0.1243],\n",
       "                     device='cuda:0'), max_val=tensor([0.2316, 0.2182, 0.1178, 0.1759, 0.1801, 0.1455, 0.2251, 0.0950, 0.2623,\n",
       "                      0.1901, 0.2636, 0.0983, 0.3007, 0.1993, 0.2438, 0.1727, 0.1923, 0.0603,\n",
       "                      0.2108, 0.1398, 0.2394, 0.2631, 0.1993, 0.2098, 0.2672, 0.1807, 0.3073,\n",
       "                      0.2699, 0.1522, 0.1406, 0.1748, 0.1723, 0.1811, 0.1890, 0.1487, 0.2445,\n",
       "                      0.2129, 0.1904, 0.1562, 0.3712, 0.2555, 0.2324, 0.2353, 0.1603, 0.1700,\n",
       "                      0.2348, 0.1527, 0.2173, 0.1258, 0.1415, 0.2510, 0.1002, 0.2056, 0.1805,\n",
       "                      0.2161, 0.1828, 0.2554, 0.1718, 0.3767, 0.1524, 0.2360, 0.2416, 0.1868,\n",
       "                      0.1744], device='cuda:0')\n",
       "            )\n",
       "          )\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.005568504333496, max_val=11.131071090698242)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.342874526977539, max_val=7.116767883300781)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0008, 0.0010, 0.0011, 0.0010, 0.0008, 0.0006, 0.0008, 0.0006, 0.0009,\n",
       "                  0.0009, 0.0005, 0.0010, 0.0007, 0.0006, 0.0008, 0.0008, 0.0006, 0.0010,\n",
       "                  0.0008, 0.0009, 0.0010, 0.0008, 0.0009, 0.0010, 0.0009, 0.0009, 0.0008,\n",
       "                  0.0008, 0.0012, 0.0011, 0.0006, 0.0009, 0.0008, 0.0006, 0.0009, 0.0010,\n",
       "                  0.0009, 0.0008, 0.0012, 0.0009, 0.0009, 0.0009, 0.0007, 0.0008, 0.0013,\n",
       "                  0.0006, 0.0009, 0.0009, 0.0008, 0.0008, 0.0008, 0.0008, 0.0006, 0.0007,\n",
       "                  0.0007, 0.0007, 0.0004, 0.0010, 0.0006, 0.0008, 0.0006, 0.0010, 0.0008,\n",
       "                  0.0009], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1491, -0.1936, -0.1685, -0.1656, -0.1815, -0.1530, -0.1379, -0.1427,\n",
       "                    -0.1744, -0.1556, -0.1248, -0.1377, -0.1597, -0.1352, -0.1851, -0.1637,\n",
       "                    -0.1457, -0.1631, -0.1499, -0.1605, -0.1470, -0.1583, -0.1706, -0.1637,\n",
       "                    -0.1764, -0.1611, -0.1765, -0.1767, -0.1807, -0.1665, -0.1489, -0.1411,\n",
       "                    -0.1772, -0.1676, -0.1820, -0.1813, -0.1833, -0.1897, -0.1617, -0.1657,\n",
       "                    -0.1615, -0.1476, -0.1574, -0.1494, -0.1715, -0.1660, -0.1617, -0.1954,\n",
       "                    -0.1978, -0.1532, -0.1902, -0.1350, -0.1427, -0.1609, -0.1825, -0.1385,\n",
       "                    -0.1481, -0.1788, -0.1296, -0.1358, -0.1674, -0.1824, -0.1605, -0.1943],\n",
       "                   device='cuda:0'), max_val=tensor([0.1982, 0.2508, 0.2693, 0.2425, 0.2074, 0.1586, 0.2127, 0.1580, 0.2158,\n",
       "                    0.2097, 0.1473, 0.2448, 0.1708, 0.1792, 0.1781, 0.1969, 0.1458, 0.2310,\n",
       "                    0.1832, 0.2255, 0.2451, 0.2637, 0.2416, 0.2134, 0.2153, 0.2069, 0.1854,\n",
       "                    0.1945, 0.2655, 0.2660, 0.1787, 0.2196, 0.1772, 0.1640, 0.2203, 0.2261,\n",
       "                    0.2044, 0.1844, 0.2921, 0.2316, 0.2186, 0.2147, 0.1800, 0.1867, 0.3014,\n",
       "                    0.1605, 0.2110, 0.1884, 0.1909, 0.1957, 0.1842, 0.1924, 0.1511, 0.1727,\n",
       "                    0.1675, 0.1893, 0.1418, 0.2217, 0.1626, 0.2059, 0.1307, 0.2280, 0.1908,\n",
       "                    0.1452], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-20.39500617980957, max_val=19.016555786132812)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.09722900390625, max_val=5.6438751220703125)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0029, 0.0039, 0.0039, 0.0022, 0.0028, 0.0032, 0.0030, 0.0035, 0.0018,\n",
       "                  0.0020, 0.0031, 0.0032, 0.0043, 0.0046, 0.0014, 0.0047, 0.0052, 0.0027,\n",
       "                  0.0030, 0.0069, 0.0020, 0.0029, 0.0040, 0.0033, 0.0029, 0.0032, 0.0026,\n",
       "                  0.0028, 0.0034, 0.0028, 0.0035, 0.0029, 0.0020, 0.0030, 0.0045, 0.0028,\n",
       "                  0.0029, 0.0028, 0.0041, 0.0038, 0.0044, 0.0026, 0.0029, 0.0026, 0.0031,\n",
       "                  0.0039, 0.0020, 0.0047, 0.0035, 0.0048, 0.0021, 0.0041, 0.0036, 0.0047,\n",
       "                  0.0026, 0.0027, 0.0023, 0.0028, 0.0020, 0.0046, 0.0019, 0.0026, 0.0026,\n",
       "                  0.0029], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.3035, -0.3590, -0.3185, -0.2449, -0.2936, -0.3538, -0.2686, -0.3277,\n",
       "                    -0.2294, -0.2284, -0.3246, -0.3298, -0.3940, -0.4052, -0.1768, -0.3898,\n",
       "                    -0.3876, -0.2541, -0.2717, -0.3825, -0.2602, -0.3104, -0.2910, -0.2805,\n",
       "                    -0.3318, -0.2664, -0.2335, -0.2540, -0.2644, -0.3165, -0.2991, -0.3267,\n",
       "                    -0.2447, -0.3377, -0.3683, -0.3244, -0.2409, -0.3245, -0.3433, -0.2998,\n",
       "                    -0.2754, -0.2514, -0.2757, -0.2563, -0.2545, -0.3072, -0.2513, -0.3348,\n",
       "                    -0.3617, -0.3263, -0.2300, -0.3252, -0.2578, -0.4688, -0.2360, -0.2489,\n",
       "                    -0.2830, -0.2819, -0.2321, -0.3893, -0.2203, -0.2546, -0.2987, -0.2946],\n",
       "                   device='cuda:0'), max_val=tensor([0.3289, 0.4246, 0.4361, 0.2578, 0.3262, 0.3505, 0.3453, 0.3902, 0.2242,\n",
       "                    0.2373, 0.3422, 0.3608, 0.4640, 0.4993, 0.2062, 0.5080, 0.5630, 0.3073,\n",
       "                    0.3430, 0.7211, 0.2263, 0.3501, 0.4269, 0.3750, 0.3178, 0.3590, 0.3153,\n",
       "                    0.3135, 0.3909, 0.3197, 0.3886, 0.3201, 0.2364, 0.3405, 0.4737, 0.2916,\n",
       "                    0.3362, 0.3216, 0.4416, 0.4198, 0.4956, 0.3056, 0.3575, 0.3181, 0.3491,\n",
       "                    0.4570, 0.2180, 0.4948, 0.3853, 0.5327, 0.2542, 0.4783, 0.4050, 0.4904,\n",
       "                    0.3236, 0.3228, 0.2428, 0.3309, 0.2572, 0.5013, 0.2378, 0.3003, 0.3000,\n",
       "                    0.3316], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.354573249816895, max_val=9.792410850524902)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.313591480255127, max_val=5.646236896514893)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0006, 0.0006, 0.0004, 0.0007, 0.0008, 0.0008, 0.0004, 0.0004, 0.1000,\n",
       "                  0.0006, 0.0007, 0.0007, 0.0008, 0.0009, 0.0007, 0.0007, 0.0005, 0.0005,\n",
       "                  0.0007, 0.0006, 0.0006, 0.0004, 0.0008, 0.0005, 0.0005, 0.0003, 0.0006,\n",
       "                  0.0011, 0.1000, 0.0004, 0.0007, 0.0007, 0.1000, 0.0005, 0.0010, 0.0006,\n",
       "                  0.0007, 0.0006, 0.0005, 0.0008, 0.0006, 0.0004, 0.0004, 0.0004, 0.0005,\n",
       "                  0.0007, 0.0005, 0.0007, 0.0004, 0.0003, 0.0006, 0.0004, 0.0006, 0.0008,\n",
       "                  0.0005, 0.0012, 0.0006, 0.0004, 0.1000, 0.0007, 0.0007, 0.0006, 0.0007,\n",
       "                  0.0006], device='cuda:0'), zero_point=tensor([  0,   0,   0,   0,   0,   0,   0,   0, 127,   0,   0,   0,   0,   0,\n",
       "                    0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "                  127,   0,   0,   0, 127,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "                    0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "                    0,   0, 127,   0,   0,   0,   0,   0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.1370, -0.1250, -0.1465, -0.1322, -0.1565, -0.1620, -0.1189, -0.1378,\n",
       "                     0.0000, -0.1268, -0.1465, -0.1849, -0.1440, -0.1328, -0.1144, -0.1143,\n",
       "                    -0.1378, -0.1498, -0.1519, -0.1744, -0.1411, -0.1325, -0.1415, -0.1307,\n",
       "                    -0.1371, -0.0926, -0.1430, -0.1803,  0.0000, -0.0674, -0.1783, -0.1505,\n",
       "                     0.0000, -0.1125, -0.1689, -0.1654, -0.1308, -0.1272, -0.1131, -0.1555,\n",
       "                    -0.1658, -0.1196, -0.1276, -0.1256, -0.1406, -0.1209, -0.1389, -0.1204,\n",
       "                    -0.1336, -0.1086, -0.1295, -0.1043, -0.1327, -0.1986, -0.1321, -0.1554,\n",
       "                    -0.1539, -0.1418,  0.0000, -0.1570, -0.1453, -0.1333, -0.1444, -0.1461],\n",
       "                   device='cuda:0'), max_val=tensor([0.1598, 0.2032, 0.1258, 0.1892, 0.2528, 0.2280, 0.1428, 0.1386, 0.0000,\n",
       "                    0.1710, 0.2015, 0.2064, 0.2554, 0.2500, 0.1864, 0.1789, 0.1462, 0.1233,\n",
       "                    0.2081, 0.1489, 0.1645, 0.1529, 0.2043, 0.1387, 0.1356, 0.1057, 0.1692,\n",
       "                    0.2853, 0.0000, 0.1401, 0.1756, 0.1819, 0.0000, 0.1489, 0.2657, 0.1805,\n",
       "                    0.1986, 0.1744, 0.1453, 0.1908, 0.1811, 0.0713, 0.1157, 0.1234, 0.1594,\n",
       "                    0.2124, 0.1491, 0.2034, 0.1084, 0.1016, 0.1718, 0.1296, 0.1683, 0.2128,\n",
       "                    0.1508, 0.3098, 0.1501, 0.1067, 0.0000, 0.1875, 0.1793, 0.1905, 0.2068,\n",
       "                    0.1758], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-30.635711669921875, max_val=22.581600189208984)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.858047008514404, max_val=6.290695667266846)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([3.8105e-03, 5.3051e-03, 3.0290e-03, 3.9259e-03, 3.2143e-03, 3.3674e-03,\n",
       "                  4.6068e-03, 4.8093e-03, 2.0562e-03, 2.4932e-03, 4.7940e-03, 4.1110e-04,\n",
       "                  3.9319e-03, 5.1647e-03, 3.1204e-03, 3.0289e-03, 4.2075e-03, 3.5831e-03,\n",
       "                  4.1235e-03, 3.1537e-03, 4.8704e-03, 4.7697e-03, 1.3769e-03, 3.2629e-03,\n",
       "                  4.0940e-03, 2.7591e-03, 4.0765e-03, 3.7390e-03, 4.6901e-03, 4.5529e-03,\n",
       "                  3.2053e-03, 4.7237e-03, 4.0975e-03, 5.7464e-03, 2.3362e-05, 5.1355e-03,\n",
       "                  1.2571e-05, 2.5548e-03, 4.2066e-03, 4.6336e-03, 2.0958e-05, 4.5598e-03,\n",
       "                  2.8897e-03, 4.7108e-03, 2.7833e-03, 4.4034e-03, 3.3069e-03, 5.1724e-03,\n",
       "                  9.3102e-06, 3.8973e-05, 5.1885e-03, 3.6985e-03, 2.1349e-03, 3.0285e-03,\n",
       "                  4.9656e-03, 3.8014e-03, 5.8026e-03, 6.1798e-03, 4.3136e-03, 3.7635e-03,\n",
       "                  2.4270e-03, 2.2464e-03, 1.6426e-03, 4.2766e-03], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.3365, -0.4809, -0.2700, -0.2927, -0.3238, -0.2543, -0.4432, -0.3268,\n",
       "                    -0.1897, -0.2497, -0.4594, -0.0329, -0.3130, -0.4985, -0.3309, -0.2524,\n",
       "                    -0.3478, -0.2154, -0.3953, -0.2817, -0.3190, -0.4685, -0.1329, -0.3263,\n",
       "                    -0.3808, -0.2502, -0.3532, -0.3583, -0.4514, -0.4033, -0.3100, -0.3102,\n",
       "                    -0.4024, -0.4210, -0.0098, -0.4216, -0.0062, -0.2384, -0.2974, -0.3856,\n",
       "                    -0.0070, -0.2419, -0.2722, -0.4426, -0.2527, -0.3719, -0.3085, -0.3171,\n",
       "                    -0.0092, -0.0118, -0.4142, -0.2604, -0.1997, -0.2993, -0.2664, -0.2148,\n",
       "                    -0.4502, -0.6048, -0.4278, -0.3676, -0.1532, -0.2201, -0.1661, -0.4066],\n",
       "                   device='cuda:0'), max_val=tensor([0.3684, 0.5037, 0.2968, 0.3850, 0.2605, 0.3221, 0.3099, 0.4655, 0.2178,\n",
       "                    0.2311, 0.3462, 0.0560, 0.3873, 0.4109, 0.2831, 0.3051, 0.3955, 0.3455,\n",
       "                    0.3869, 0.3040, 0.4814, 0.3687, 0.1505, 0.3045, 0.3922, 0.2762, 0.3871,\n",
       "                    0.3288, 0.3643, 0.4416, 0.2927, 0.4664, 0.3275, 0.5407, 0.0101, 0.4812,\n",
       "                    0.0052, 0.2624, 0.4075, 0.4316, 0.0080, 0.4416, 0.2878, 0.4383, 0.2832,\n",
       "                    0.4238, 0.3234, 0.4821, 0.0108, 0.0151, 0.4844, 0.3633, 0.2190, 0.2841,\n",
       "                    0.4954, 0.3659, 0.5386, 0.3468, 0.3233, 0.3193, 0.2482, 0.2349, 0.1754,\n",
       "                    0.4037], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.462432861328125, max_val=10.000746726989746)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.5026774406433105, max_val=6.377254009246826)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.4822e-04, 1.5703e-04,\n",
       "                  3.3458e-04, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 3.2669e-04, 2.4012e-04, 1.0000e-01,\n",
       "                  1.0000e-01, 6.0644e-19, 1.7546e-05, 1.8368e-04, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 2.0842e-04, 1.0000e-01, 2.5026e-04, 1.0000e-01, 1.0000e-01,\n",
       "                  3.0624e-04, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 5.8316e-05,\n",
       "                  1.0000e-01, 1.0000e-01, 2.1095e-04, 1.4827e-04, 2.6784e-04, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.4506e-04, 1.0000e-01, 1.0000e-01, 1.9395e-04,\n",
       "                  2.1299e-04, 3.5295e-04, 2.4587e-04, 1.0000e-01, 1.0000e-01, 1.6264e-04,\n",
       "                  1.0000e-01, 1.6747e-04, 1.8286e-04, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  2.3172e-04, 1.0000e-01, 2.1511e-04, 1.4419e-04], device='cuda:0'), zero_point=tensor([127, 127, 127, 127,   0,   0,   0, 127, 127, 127, 127, 127, 127, 127,\n",
       "                  127,   0,   0, 127, 127,   0,   0,   0, 127, 127, 127,   0, 127,   0,\n",
       "                  127, 127,   0, 127, 127, 127, 127,   0, 127, 127,   0,   0,   0, 127,\n",
       "                  127, 127,   0, 127, 127,   0,   0,   0,   0, 127, 127,   0, 127,   0,\n",
       "                    0, 127, 127, 127,   0, 127,   0,   0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.0505e-02,\n",
       "                    -5.8141e-02, -8.2884e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                    -9.7519e-02, -7.8958e-02,  0.0000e+00,  0.0000e+00, -1.1298e-17,\n",
       "                    -2.2716e-03, -6.0453e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                    -6.9159e-02,  0.0000e+00, -1.1440e-01,  0.0000e+00,  0.0000e+00,\n",
       "                    -1.1366e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                    -1.4111e-02,  0.0000e+00,  0.0000e+00, -7.9186e-02, -5.8532e-02,\n",
       "                    -8.1706e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.2689e-02,\n",
       "                     0.0000e+00,  0.0000e+00, -4.8585e-02, -1.0393e-01, -9.4531e-02,\n",
       "                    -1.2335e-01,  0.0000e+00,  0.0000e+00, -7.0086e-02,  0.0000e+00,\n",
       "                    -5.6356e-02, -9.5035e-02,  0.0000e+00,  0.0000e+00, -2.4545e-41,\n",
       "                    -9.3529e-02,  0.0000e+00, -1.1574e-01, -4.8605e-02], device='cuda:0'), max_val=tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0535e-02, 8.2686e-02,\n",
       "                    1.3171e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2789e-01, 1.3839e-01, 0.0000e+00,\n",
       "                    0.0000e+00, 4.6170e-17, 1.5929e-03, 1.1375e-01, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 1.1690e-01, 0.0000e+00, 9.6322e-02, 0.0000e+00, 0.0000e+00,\n",
       "                    1.3431e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1450e-02,\n",
       "                    0.0000e+00, 0.0000e+00, 1.1475e-01, 8.0339e-02, 1.3943e-01, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 1.0020e-01, 0.0000e+00, 0.0000e+00, 1.0318e-01,\n",
       "                    8.7323e-02, 1.4123e-01, 9.0554e-02, 0.0000e+00, 0.0000e+00, 8.6902e-02,\n",
       "                    0.0000e+00, 7.9776e-02, 8.8763e-02, 0.0000e+00, 0.0000e+00, 2.2812e-41,\n",
       "                    1.1091e-01, 0.0000e+00, 1.1708e-01, 9.6450e-02], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-22.598875045776367, max_val=41.36894989013672)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.378020763397217, max_val=6.093669891357422)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([7.9152e-04, 1.1655e-03, 6.0714e-04, 1.1935e-03, 1.0009e-03, 9.3519e-04,\n",
       "                  1.2603e-03, 1.3107e-03, 9.7412e-04, 9.9586e-04, 1.7495e-03, 3.2380e-04,\n",
       "                  8.3976e-04, 9.9704e-04, 8.4250e-04, 4.5255e-04, 1.0986e-03, 1.4033e-03,\n",
       "                  1.3701e-03, 8.9178e-04, 1.2005e-03, 1.0888e-03, 3.6848e-04, 1.3032e-03,\n",
       "                  1.2104e-03, 1.2570e-03, 1.3015e-03, 7.7950e-04, 1.3677e-03, 1.0471e-03,\n",
       "                  1.2720e-03, 1.2404e-03, 1.1298e-03, 8.5480e-04, 1.8697e-06, 1.0859e-03,\n",
       "                  7.1199e-06, 8.4063e-04, 8.0241e-04, 8.7446e-04, 9.4192e-05, 1.2095e-03,\n",
       "                  8.5182e-04, 1.2362e-03, 9.9472e-04, 1.5938e-03, 1.2651e-03, 1.2750e-03,\n",
       "                  5.4754e-06, 1.3211e-05, 1.7285e-03, 1.3496e-03, 1.5485e-03, 1.0118e-03,\n",
       "                  1.0530e-03, 1.3155e-03, 1.4923e-03, 1.7157e-03, 1.5808e-03, 1.2235e-03,\n",
       "                  1.6315e-04, 1.5095e-03, 1.8331e-06, 1.2787e-03], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-0.0788, -0.1387, -0.0585, -0.1052, -0.1414, -0.0517, -0.1318, -0.1277,\n",
       "                    -0.0756, -0.1485, -0.1219, -0.0492, -0.0598, -0.0982, -0.1027, -0.0353,\n",
       "                    -0.0994, -0.1776, -0.1275, -0.0719, -0.1298, -0.1424, -0.0650, -0.0753,\n",
       "                    -0.1081, -0.1093, -0.1461, -0.1170, -0.1222, -0.0883, -0.1175, -0.1227,\n",
       "                    -0.1571, -0.1007, -0.0049, -0.0900, -0.0026, -0.0528, -0.1184, -0.0933,\n",
       "                    -0.0233, -0.1295, -0.0364, -0.1237, -0.0872, -0.1034, -0.0862, -0.1020,\n",
       "                    -0.0043, -0.0092, -0.2222, -0.1072, -0.1184, -0.1049, -0.0665, -0.0993,\n",
       "                    -0.1529, -0.1221, -0.0765, -0.1132, -0.0299, -0.0789, -0.0038, -0.1612],\n",
       "                   device='cuda:0'), max_val=tensor([0.1253, 0.1480, 0.0896, 0.1626, 0.1033, 0.1303, 0.1639, 0.1801, 0.1431,\n",
       "                    0.1083, 0.2149, 0.0514, 0.1290, 0.1425, 0.1279, 0.0785, 0.1507, 0.1435,\n",
       "                    0.1763, 0.1194, 0.1625, 0.1390, 0.0678, 0.1792, 0.1595, 0.1594, 0.1708,\n",
       "                    0.1157, 0.1766, 0.1449, 0.1614, 0.1617, 0.1319, 0.1236, 0.0042, 0.1495,\n",
       "                    0.0055, 0.1220, 0.1054, 0.1246, 0.0244, 0.1658, 0.1281, 0.1672, 0.1337,\n",
       "                    0.2092, 0.1682, 0.1730, 0.0044, 0.0067, 0.2116, 0.1768, 0.1959, 0.1467,\n",
       "                    0.1603, 0.1689, 0.1821, 0.2152, 0.2241, 0.1606, 0.0387, 0.2069, 0.0050,\n",
       "                    0.1374], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.268716335296631, max_val=13.19469928741455)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.962431907653809, max_val=7.986553192138672)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlockQAT(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 3.3362e-05, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 4.1730e-05, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01, 1.0000e-01,\n",
       "                  1.0000e-01, 7.3023e-05, 1.0000e-01, 1.0000e-01], device='cuda:0'), zero_point=tensor([127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
       "                  127, 127, 127, 127, 127, 127, 127,   0, 127, 127, 127, 127, 127, 127,\n",
       "                  127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
       "                  127, 127, 127,   0, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
       "                  127, 127, 127, 127, 127,   0, 127, 127], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                    -2.0579e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00, -2.2060e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                    -3.6231e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                     0.0000e+00, -5.3229e-02,  0.0000e+00,  0.0000e+00], device='cuda:0'), max_val=tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1375e-41,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8205e-02, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4589e-02, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                    0.0000e+00, 8.1543e-02, 0.0000e+00, 0.0000e+00], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-21.622621536254883, max_val=64.424072265625)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.228343963623047, max_val=6.061995029449463)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.6893e-05, 1.8593e-05, 9.2677e-05, 1.6570e-03, 9.5301e-05, 1.3639e-05,\n",
       "                  1.4899e-04, 3.2413e-04, 8.9261e-06, 3.3362e-05, 9.9307e-04, 1.4693e-03,\n",
       "                  5.3476e-05, 6.6767e-04, 1.2116e-03, 1.8649e-05, 4.4405e-06, 3.4447e-05,\n",
       "                  1.6807e-03, 1.3043e-05, 1.5304e-03, 5.6896e-04, 5.1500e-05, 1.7261e-03,\n",
       "                  3.7815e-04, 5.4901e-05, 5.7959e-05, 1.7616e-05, 7.3934e-04, 1.1649e-03,\n",
       "                  1.3414e-03, 1.3877e-03, 1.1654e-03, 3.5039e-05, 7.4073e-06, 1.0552e-03,\n",
       "                  2.8828e-05, 1.2566e-03, 1.3561e-05, 2.5735e-05, 4.9946e-05, 2.0142e-05,\n",
       "                  6.4988e-06, 5.5619e-05, 5.3218e-05, 6.0197e-04, 7.3913e-04, 4.1106e-05,\n",
       "                  7.2533e-06, 7.6641e-06, 7.6391e-04, 1.0618e-03, 6.6691e-04, 8.0716e-04,\n",
       "                  1.3191e-03, 3.4608e-05, 2.2269e-04, 1.0524e-03, 7.4159e-04, 1.1870e-03,\n",
       "                  3.3644e-05, 1.1085e-03, 7.4071e-05, 1.9113e-05], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "                 dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "            min_val=tensor([-1.2138e-02, -1.2124e-02, -1.0250e-02, -5.7097e-02, -2.2690e-02,\n",
       "                    -1.0621e-02, -3.3169e-02, -2.2357e-02, -7.0792e-03, -1.0894e-02,\n",
       "                    -4.3957e-02, -7.1208e-02, -1.1360e-02, -6.4090e-03, -3.5888e-02,\n",
       "                    -9.9655e-03, -3.7275e-03, -1.4254e-02, -6.8426e-02, -7.0847e-03,\n",
       "                    -5.6926e-02, -7.1792e-04, -1.8519e-02, -4.3623e-02, -2.7050e-02,\n",
       "                    -1.4452e-02, -2.0720e-02, -9.2303e-04, -4.7247e-02, -4.8358e-02,\n",
       "                    -3.0707e-02, -5.7372e-02, -1.4948e-02, -1.6818e-05, -2.3647e-03,\n",
       "                    -4.2181e-02, -5.1816e-03, -4.8870e-02, -1.1356e-02, -1.2190e-02,\n",
       "                    -6.8355e-03, -1.4930e-02, -2.7318e-04, -1.8583e-02, -1.2398e-02,\n",
       "                    -4.6163e-02, -2.6374e-02, -1.1701e-03, -3.8981e-03, -4.3738e-03,\n",
       "                    -3.9923e-02, -2.2428e-02, -2.5103e-02, -2.2691e-02, -4.1108e-02,\n",
       "                    -7.4704e-03, -4.4455e-02, -2.3859e-02, -3.8101e-02, -4.1886e-02,\n",
       "                    -1.0836e-02, -2.0654e-02, -1.7573e-02, -4.6609e-03], device='cuda:0'), max_val=tensor([0.0038, 0.0143, 0.0217, 0.1704, 0.0198, 0.0011, 0.0335, 0.0504, 0.0092,\n",
       "                    0.0067, 0.1047, 0.1353, 0.0180, 0.0917, 0.1337, 0.0074, 0.0075, 0.0150,\n",
       "                    0.1723, 0.0083, 0.1505, 0.0747, 0.0076, 0.1775, 0.0516, 0.0158, 0.0109,\n",
       "                    0.0144, 0.0904, 0.1263, 0.1427, 0.1463, 0.1347, 0.0176, 0.0065, 0.1161,\n",
       "                    0.0029, 0.1292, 0.0099, 0.0144, 0.0102, 0.0068, 0.0097, 0.0156, 0.0214,\n",
       "                    0.0760, 0.0903, 0.0197, 0.0009, 0.0048, 0.0942, 0.1179, 0.0819, 0.1000,\n",
       "                    0.1408, 0.0153, 0.0332, 0.1209, 0.0907, 0.1325, 0.0119, 0.1222, 0.0120,\n",
       "                    0.0125], device='cuda:0')\n",
       "          )\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2512223720550537, max_val=3.563586473464966)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.864780902862549, max_val=8.027318954467773)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(\n",
       "    in_features=64, out_features=10, bias=True\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([0.0076, 0.0071, 0.0071, 0.0072, 0.0091, 0.0068, 0.0081, 0.0062, 0.0085,\n",
       "              0.0076], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "        min_val=tensor([-0.9748, -0.9113, -0.9140, -0.9167, -1.1644, -0.8744, -1.0367, -0.8002,\n",
       "                -1.0830, -0.9762], device='cuda:0'), max_val=tensor([0.4555, 0.5827, 0.4521, 0.4541, 0.5414, 0.4450, 0.4760, 0.5746, 0.5134,\n",
       "                0.5815], device='cuda:0')\n",
       "      )\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-34.153724670410156, max_val=22.162952423095703)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([0], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.429065704345703, max_val=2.7537312507629395)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.quantization as tq\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.backends.quantized.engine = \"fbgemm\"  # important if you used fbgemm in training\n",
    "\n",
    "# 1) Build model\n",
    "model = ResNetQAT(num_classes=10)\n",
    "\n",
    "# 2) Prepare QAT graph (must be in train mode for prepare_qat)\n",
    "model.train()\n",
    "model.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\n",
    "tq.prepare_qat(model, inplace=True)\n",
    "\n",
    "# 3) Load checkpoint BUT drop activation_post_process_* keys (they don't match your naming)\n",
    "state = torch.load(\"../../pth/resnet_qat_preconvert.pth\", map_location=\"cpu\")\n",
    "state = {k: v for k, v in state.items() if not k.startswith(\"activation_post_process_\")}\n",
    "\n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "print(\"missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "\n",
    "# 4) Calibrate observers (collect min/max) WITHOUT fake quant affecting activations yet\n",
    "model.to(device)\n",
    "model.train()\n",
    "model.apply(tq.enable_observer)\n",
    "model.apply(tq.disable_fake_quant)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x, _) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        _ = model(x)\n",
    "        if i == 50:   # ~50 batches is plenty\n",
    "            break\n",
    "\n",
    "# 5) Now run inference with fake quant enabled and observers frozen\n",
    "model.eval()\n",
    "model.apply(tq.disable_observer)\n",
    "model.apply(tq.enable_fake_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e71765-3ae9-4a23-b3b9-7cf4aa7cae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ea8db1-83f3-4806-8401-14ac8fcedd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNetQAT([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNetQAT([...]` with `torch.export.export(..., strict=False)`... \n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... \n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... \n"
     ]
    },
    {
     "ename": "ConversionError",
     "evalue": "Failed to convert the exported program to an ONNX model. \u001b[96mThis is step 3/3\u001b[0m of exporting the model to ONNX. Next steps:\n- If there is a missing ONNX function, implement it and register it to the registry.\n- If there is an internal error during ONNX conversion, debug the error and summit a PR to PyTorch.\n- Create an error report with `torch.onnx.export(..., report=True)`, and save the ExportedProgram as a pt2 file. Create an issue in the PyTorch GitHub repository against the \u001b[96m*onnx*\u001b[0m component. Attach the error report and the pt2 model.\n\n## Exception summary\n\n<class 'torch.onnx._internal.exporter._errors.DispatchError'>: No ONNX function found for <OpOverload(op='aten._fused_moving_avg_obs_fq_helper_functional', overload='default')>. Failure message: No decompositions registered for the real-valued input\n\n<class 'torch.onnx._internal.exporter._errors.ConversionError'>: Error when translating node %_fused_moving_avg_obs_fq_helper_functional : [num_users=5] = call_function[target=torch.ops.aten._fused_moving_avg_obs_fq_helper_functional.default](args = (%x, %b_quant_activation_post_process_observer_enabled, %b_quant_activation_post_process_fake_quant_enabled, %b_quant_activation_post_process_activation_post_process_min_val, %b_quant_activation_post_process_activation_post_process_max_val, %b_quant_activation_post_process_scale, %b_quant_activation_post_process_zero_point, 0.01, 0, 127, -1), kwargs = {}). See the stack trace for more information.\n\n(Refer to the full stack trace above for more information.)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDispatchError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:796\u001b[39m, in \u001b[36m_translate_fx_graph\u001b[39m\u001b[34m(fx_graph, model, graph_like, owned_graphs, lower, registry)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lower == \u001b[33m\"\u001b[39m\u001b[33mat_conversion\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[43m_handle_call_function_node_with_lowering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_name_to_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_like\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_like\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconstant_farm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstant_farm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_name_to_local_functions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_name_to_local_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# No lowering\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:581\u001b[39m, in \u001b[36m_handle_call_function_node_with_lowering\u001b[39m\u001b[34m(model, node, node_name_to_values, graph_like, constant_farm, registry, opset, node_name_to_local_functions)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m onnx_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _errors.DispatchError(\n\u001b[32m    582\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo ONNX function found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.target\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Failure message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m onnxscript.evaluator.default_as(\n\u001b[32m    586\u001b[39m     tracer := _building.OpRecorder(opset, constant_farm)\n\u001b[32m    587\u001b[39m ):\n",
      "\u001b[31mDispatchError\u001b[39m: No ONNX function found for <OpOverload(op='aten._fused_moving_avg_obs_fq_helper_functional', overload='default')>. Failure message: No decompositions registered for the real-valued input",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConversionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1465\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, kwargs, registry, dynamic_shapes, input_names, output_names, report, verify, profile, dump_exported_program, artifacts_dir, verbose)\u001b[39m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     \u001b[38;5;66;03m# Convert the exported program to an ONNX model\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     onnx_program = \u001b[43m_exported_program_to_onnx_program\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecomposed_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1468\u001b[39m     \u001b[38;5;66;03m# Record the strategy used for getting the exported program for unit test assertions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1096\u001b[39m, in \u001b[36m_exported_program_to_onnx_program\u001b[39m\u001b[34m(exported_program, registry, lower)\u001b[39m\n\u001b[32m   1094\u001b[39m         graph_like = func\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     values = \u001b[43m_translate_fx_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfx_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_like\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_like\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mowned_graphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mowned_graphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe last module processed should be the root module\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:822\u001b[39m, in \u001b[36m_translate_fx_graph\u001b[39m\u001b[34m(fx_graph, model, graph_like, owned_graphs, lower, registry)\u001b[39m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m _errors.ConversionError(\n\u001b[32m    823\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError when translating node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.format_node()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the stack trace for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    824\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node_name_to_values\n",
      "\u001b[31mConversionError\u001b[39m: Error when translating node %_fused_moving_avg_obs_fq_helper_functional : [num_users=5] = call_function[target=torch.ops.aten._fused_moving_avg_obs_fq_helper_functional.default](args = (%x, %b_quant_activation_post_process_observer_enabled, %b_quant_activation_post_process_fake_quant_enabled, %b_quant_activation_post_process_activation_post_process_min_val, %b_quant_activation_post_process_activation_post_process_max_val, %b_quant_activation_post_process_scale, %b_quant_activation_post_process_zero_point, 0.01, 0, 127, -1), kwargs = {}). See the stack trace for more information.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConversionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bs, dummy \u001b[38;5;129;01min\u001b[39;00m dummy_map.items():\n\u001b[32m     21\u001b[39m     out_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresnet_qat_qdq_b\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_op18.onnx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m18\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogits\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExported\u001b[39m\u001b[33m\"\u001b[39m, out_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/__init__.py:296\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Prepare legacy export parameters for potential fallback\u001b[39;00m\n\u001b[32m    287\u001b[39m     legacy_export_kwargs = {\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m: training,\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moperator_export_type\u001b[39m\u001b[33m\"\u001b[39m: operator_export_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mautograd_inlining\u001b[39m\u001b[33m\"\u001b[39m: autograd_inlining,\n\u001b[32m    294\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_compat.py:143\u001b[39m, in \u001b[36mexport_compat\u001b[39m\u001b[34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, legacy_export_kwargs)\u001b[39m\n\u001b[32m    141\u001b[39m             registry.register_op(torch_op, op, is_complex=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     onnx_program = \u001b[43m_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_shapes_with_export_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fallback:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_flags.py:23\u001b[39m, in \u001b[36mset_onnx_exporting_flag.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m _is_onnx_exporting = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Ensure it resets even if an exception occurs\u001b[39;00m\n\u001b[32m     26\u001b[39m     _is_onnx_exporting = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ee599/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py:1511\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, kwargs, registry, dynamic_shapes, input_names, output_names, report, verify, profile, dump_exported_program, artifacts_dir, verbose)\u001b[39m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1509\u001b[39m         report_path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _errors.ConversionError(\n\u001b[32m   1512\u001b[39m         _STEP_THREE_ERROR_MESSAGE\n\u001b[32m   1513\u001b[39m         + (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mError report has been saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1514\u001b[39m         + _summarize_exception_stack(e)\n\u001b[32m   1515\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1517\u001b[39m profile_result = _maybe_stop_profiler_and_get_result(profiler)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m onnx_program.exported_program \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mConversionError\u001b[39m: Failed to convert the exported program to an ONNX model. \u001b[96mThis is step 3/3\u001b[0m of exporting the model to ONNX. Next steps:\n- If there is a missing ONNX function, implement it and register it to the registry.\n- If there is an internal error during ONNX conversion, debug the error and summit a PR to PyTorch.\n- Create an error report with `torch.onnx.export(..., report=True)`, and save the ExportedProgram as a pt2 file. Create an issue in the PyTorch GitHub repository against the \u001b[96m*onnx*\u001b[0m component. Attach the error report and the pt2 model.\n\n## Exception summary\n\n<class 'torch.onnx._internal.exporter._errors.DispatchError'>: No ONNX function found for <OpOverload(op='aten._fused_moving_avg_obs_fq_helper_functional', overload='default')>. Failure message: No decompositions registered for the real-valued input\n\n<class 'torch.onnx._internal.exporter._errors.ConversionError'>: Error when translating node %_fused_moving_avg_obs_fq_helper_functional : [num_users=5] = call_function[target=torch.ops.aten._fused_moving_avg_obs_fq_helper_functional.default](args = (%x, %b_quant_activation_post_process_observer_enabled, %b_quant_activation_post_process_fake_quant_enabled, %b_quant_activation_post_process_activation_post_process_min_val, %b_quant_activation_post_process_activation_post_process_max_val, %b_quant_activation_post_process_scale, %b_quant_activation_post_process_zero_point, 0.01, 0, 127, -1), kwargs = {}). See the stack trace for more information.\n\n(Refer to the full stack trace above for more information.)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.ao.quantization as tq\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1) Put model on GPU for calibration/inference of QAT (fake-quant runs fine on GPU)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2) IMPORTANT: freeze observers + enable fake quant BEFORE export\n",
    "model.apply(tq.disable_observer)\n",
    "model.apply(tq.enable_fake_quant)\n",
    "\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32, device=device),\n",
    "    64:  torch.randn(64,  3, 32, 32, device=device),\n",
    "    128: torch.randn(128, 3, 32, 32, device=device),\n",
    "}\n",
    "\n",
    "for bs, dummy in dummy_map.items():\n",
    "    out_path = f\"resnet_qat_qdq_b{bs}_op18.onnx\"\n",
    "    torch.onnx.export(\n",
    "        model, dummy, out_path,\n",
    "        opset_version=18,\n",
    "        do_constant_folding=False,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes=None,\n",
    "    )\n",
    "    print(\"Exported\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17143253-186e-4c27-ad4a-c67f1e4d6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 78K Dec 14 09:47 resnet_qat_int8_b1_op18.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 78K Dec 14 09:47 resnet_qat_int8_b64_op18.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 78K Dec 14 09:47 resnet_qat_int8_b128_op18.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh resnet_qat_int8_b1_op18.onnx\n",
    "!ls -lh resnet_qat_int8_b64_op18.onnx\n",
    "!ls -lh resnet_qat_int8_b128_op18.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85a783e-e0c7-4e28-ae74-93c7507e8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 18)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet_qat_int8_b1_op13.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "print([(op.domain, op.version) for op in m.opset_import])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ac89d5-edbc-4178-b9e1-8f408f840f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "print(trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250f0dd1-9496-4b88-add3-6ab7503cd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f3b54e-aac2-4547-af94-14fdf8d9f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader_b1   = DataLoader(test_dataset, batch_size=1,   shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b64  = DataLoader(test_dataset, batch_size=64,  shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b128 = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5192c-3830-4e49-a652-573ceaa48587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_accuracy_static(engine_path, test_loader, num_batches=None):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # engine fixed shapes\n",
    "    in_shape = tuple(engine.get_tensor_shape(inp))\n",
    "    out_shape = tuple(engine.get_tensor_shape(out))\n",
    "    fixed_bsz = in_shape[0]  # should be 1 or 64 or 128\n",
    "\n",
    "    # output dtype\n",
    "    trt_dtype = engine.get_tensor_dtype(out)\n",
    "    torch_dtype = {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "    }[trt_dtype]\n",
    "\n",
    "    stream = torch.cuda.current_stream()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(test_loader):\n",
    "        if num_batches is not None and bi >= num_batches:\n",
    "            break\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        if x.shape[0] != fixed_bsz:\n",
    "            raise RuntimeError(f\"Batch mismatch: loader={x.shape[0]} but engine expects {fixed_bsz}\")\n",
    "\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=torch_dtype)\n",
    "\n",
    "        context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "        context.set_tensor_address(out, int(yhat.data_ptr()))\n",
    "\n",
    "        ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"TRT execute failed\")\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.shape[0]\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be43fb-7d8f-445b-8bc2-27280ac2ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "# ---- QUIET logger (prevents per-batch spam) ----\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# ---- YOUR 3 STATIC ONNX FILES (fixed batch) ----\n",
    "onnx_map = {\n",
    "    1:   \"resnet_qat_fp32_b1_op13.onnx\",\n",
    "    64:  \"resnet_qat_fp32_b64_op13.onnx\",\n",
    "    128: \"resnet_qat_fp32_b128_op13.onnx\",\n",
    "}\n",
    "\n",
    "# ---- CALIBRATION LOADERS MUST MATCH BATCH SIZE ----\n",
    "calib_loader_map = {\n",
    "    1:   test_loader_b1,\n",
    "    64:  test_loader_b64,\n",
    "    128: test_loader_b128,\n",
    "}\n",
    "\n",
    "CALIB_BATCHES = 200          # 200 is fine; 500 if you want extra\n",
    "WORKSPACE     = 1 << 28      # 256MB (raise to 1<<29 if build fails)\n",
    "\n",
    "# ---------------- Calibrator ----------------\n",
    "class EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calib_loader, max_batches=200, cache_file=\"calib.cache\"):\n",
    "        super().__init__()\n",
    "        self.cache_file = cache_file\n",
    "        self.data_iter = iter(calib_loader)\n",
    "        self.max_batches = max_batches\n",
    "        self.batch_count = 0\n",
    "\n",
    "        x0, _ = next(iter(calib_loader))\n",
    "        self.batch_size = x0.shape[0]\n",
    "        self.device_input = torch.empty_like(x0, device=\"cuda\")\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_batch(self, names):\n",
    "        if self.batch_count >= self.max_batches:\n",
    "            return None\n",
    "        try:\n",
    "            x, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        self.batch_count += 1\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "        self.device_input.resize_(x.shape).copy_(x)\n",
    "        return [int(self.device_input.data_ptr())]\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        try:\n",
    "            with open(self.cache_file, \"rb\") as f:\n",
    "                return f.read()\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "# ---------------- Builder ----------------\n",
    "def build_int8_engine_static(onnx_path, engine_path, calib_loader, max_calib_batches=200):\n",
    "    # sanity check: if ONNX already has Q/DQ, you generally should NOT calibrate\n",
    "    m = onnx.load(onnx_path)\n",
    "    ops = set(n.op_type for n in m.graph.node)\n",
    "    has_qdq = (\"QuantizeLinear\" in ops) or (\"DequantizeLinear\" in ops)\n",
    "    if has_qdq:\n",
    "        print(f\"[WARN] {onnx_path} contains Quantize/Dequantize ops. \"\n",
    "              f\"PTQ calibration may be wrong for this file.\")\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed for {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, WORKSPACE)\n",
    "\n",
    "        # INT8 PTQ\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        cache_file = engine_path.replace(\".engine\", \".cache\")\n",
    "        config.int8_calibrator = EntropyCalibrator(\n",
    "            calib_loader,\n",
    "            max_batches=max_calib_batches,\n",
    "            cache_file=cache_file\n",
    "        )\n",
    "\n",
    "        # static ONNX => NO optimization profile needed\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"INT8 engine build failed for {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(f\"Saved: {engine_path} | cache: {cache_file} | calib_batches={max_calib_batches}\")\n",
    "\n",
    "# ---------------- Build all 3 ----------------\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    build_int8_engine_static(\n",
    "        onnx_path=onnx_path,\n",
    "        engine_path=f\"resnet_qat_int8_b{bs}.engine\",\n",
    "        calib_loader=calib_loader_map[bs],\n",
    "        max_calib_batches=CALIB_BATCHES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e99fb4-c4f8-421f-ac0d-86fd5d08cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh resnet_qat_int8_b1.engine\n",
    "!ls -lh resnet_qat_int8_b64.engine\n",
    "!ls -lh resnet_qat_int8_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef2046-109c-45e9-8d6f-aa5cd7eb4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1   = trt_accuracy_static(\"resnet_qat_int8_b1.engine\",   test_loader_b1)\n",
    "acc64  = trt_accuracy_static(\"resnet_qat_int8_b64.engine\",  test_loader_b64)\n",
    "acc128 = trt_accuracy_static(\"resnet_qat_int8_b128.engine\", test_loader_b128)\n",
    "\n",
    "print(f\"INT8 TRT Acc b1:   {acc1:.2f}%\")\n",
    "print(f\"INT8 TRT Acc b64:  {acc64:.2f}%\")\n",
    "print(f\"INT8 TRT Acc b128: {acc128:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffe9cf-4ea9-4d56-9285-6c1ef58cee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def torch_acc(model_qat_prepared, loader, device=\"cuda\"):\n",
    "    model_qat_prepared.eval().to(device)\n",
    "    correct = total = 0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100*correct/total\n",
    "\n",
    "print(\"Torch acc:\", torch_acc(model_qat_prepared, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd04b1e-a34d-4db9-bea1-ae83cd7205b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_loader\u001b[49m.dataset.transform)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_loader.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd5c0d-f755-4c20-a1e7-569de0092dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet_qat_fp32_b1_op13.onnx\")  # <-- change to your qat onnx filename\n",
    "ops = sorted(set(n.op_type for n in m.graph.node))\n",
    "print(\"QuantizeLinear:\", \"QuantizeLinear\" in ops)\n",
    "print(\"DequantizeLinear:\", \"DequantizeLinear\" in ops)\n",
    "print(\"Num nodes:\", len(m.graph.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90f80d-25c3-44c9-a142-0a0328c95b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet_qat_fp32_b1_op13.onnx\")\n",
    "print(\"Inputs:\")\n",
    "for i in m.graph.input:\n",
    "    print(i.name)\n",
    "print(\"Outputs:\")\n",
    "for o in m.graph.output:\n",
    "    print(o.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd2d04-e175-494f-9ed1-b092e7014296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "with open(\"resnet_qat_int8_b1.engine\",\"rb\") as f, trt.Runtime(TRT_LOGGER) as rt:\n",
    "    engine = rt.deserialize_cuda_engine(f.read())\n",
    "\n",
    "print(\"Engine name:\", engine.name)\n",
    "print(\"Has refittable:\", engine.refittable)\n",
    "print(\"Num layers:\", engine.num_layers)\n",
    "print(\"Has dynamic shapes:\", engine.num_optimization_profiles > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868aa200-74a4-408f-bf31-641e344bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet_qat_fp32_b1_op13.onnx\")   # <-- whichever file you're using\n",
    "ops = sorted(set(n.op_type for n in m.graph.node))\n",
    "print(\"Has QuantizeLinear?\", \"QuantizeLinear\" in ops)\n",
    "print(\"Has DequantizeLinear?\", \"DequantizeLinear\" in ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c8c5f-143f-47ff-9513-03cc067b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"example keys:\", list(state.keys())[:20])\n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "print(\"missing sample:\", missing[:20])\n",
    "print(\"unexpected sample:\", unexpected[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abfde5-9900-46d3-a016-452e82a45c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "state = torch.load(\"../../pth/resnet_qat_preconvert.pth\", map_location=\"cpu\")\n",
    "print(\"num keys:\", len(state))\n",
    "print(\"first 30 keys:\")\n",
    "for k in list(state.keys())[:30]:\n",
    "    print(\" \", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e224c-ae3d-4e74-9dcd-31ffd6990108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization as tq\n",
    "from models.resnet32_model import ResNetQAT\n",
    "\n",
    "model = ResNetQAT(num_classes=10)\n",
    "model.train()\n",
    "model.qconfig = tq.get_default_qat_qconfig(\"fbgemm\")\n",
    "model_qat_prepared = tq.prepare_qat(model, inplace=False)\n",
    "\n",
    "prepared_keys = set(model_qat_prepared.state_dict().keys())\n",
    "ckpt_keys = set(state.keys())\n",
    "\n",
    "print(\"prepared keys:\", len(prepared_keys))\n",
    "print(\"ckpt keys:\", len(ckpt_keys))\n",
    "print(\"overlap:\", len(prepared_keys & ckpt_keys))\n",
    "\n",
    "print(\"\\nmissing (need in ckpt):\")\n",
    "for k in list(prepared_keys - ckpt_keys)[:30]:\n",
    "    print(\" \", k)\n",
    "\n",
    "print(\"\\nunexpected (in ckpt but not in model):\")\n",
    "for k in list(ckpt_keys - prepared_keys)[:30]:\n",
    "    print(\" \", k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
