{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83a0b14-7a38-41dc-80cf-096a9f9503ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "assert device == \"cuda\", \"Need CUDA for TensorRT.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf318930-3bf0-4de0-9854-5c6c8687c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "test_loader_b1   = DataLoader(test_dataset, batch_size=1,   shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b64  = DataLoader(test_dataset, batch_size=64,  shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b128 = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbb2e192-fdf1-4a59-bc49-6f83a36732ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[1]))\n",
    "\n",
    "from models.resnet32_model import ResNet, ResNetQAT  # <-- IMPORTANT: FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a998b044-df23-4a9d-b1b6-355c22f10ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: 0 unexpected: 0\n",
      "bad_missing (should be empty): []\n",
      "Loaded FP32 model from preconvert checkpoint ✅\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "CKPT_PATH = \"../../pth/resnet_qat_preconvert.pth\"  # <-- your checkpoint\n",
    "\n",
    "def strip_and_remap_preconvert_state(ckpt: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in ckpt.items():\n",
    "        # remove DDP prefix if present\n",
    "        if k.startswith(\"module.\"):\n",
    "            k = k[len(\"module.\"):]\n",
    "\n",
    "        # drop QAT/observer/fake-quant bookkeeping keys\n",
    "        if (\"activation_post_process\" in k) or (\"fake_quant\" in k) or (\"weight_fake_quant\" in k):\n",
    "            continue\n",
    "        if k.startswith(\"activation_post_process_\"):\n",
    "            continue\n",
    "\n",
    "        nk = k\n",
    "\n",
    "        # checkpoint uses conv1.bn.*, but FP32 ResNet uses bn1.*\n",
    "        nk = nk.replace(\"conv1.bn.\", \"bn1.\")\n",
    "\n",
    "        # checkpoint uses layerX.Y.conv1.bn.*, FP32 uses layerX.Y.bn1.*\n",
    "        nk = re.sub(r\"(layer\\d+\\.\\d+)\\.conv1\\.bn\\.\", r\"\\1.bn1.\", nk)\n",
    "        nk = re.sub(r\"(layer\\d+\\.\\d+)\\.conv2\\.bn\\.\", r\"\\1.bn2.\", nk)\n",
    "\n",
    "        # checkpoint uses shortcut.0.bn.*, FP32 shortcut is [conv, bn] => shortcut.1.*\n",
    "        nk = re.sub(r\"(layer\\d+\\.\\d+)\\.shortcut\\.0\\.bn\\.\", r\"\\1.shortcut.1.\", nk)\n",
    "\n",
    "        out[nk] = v\n",
    "    return out\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "state_fp32 = strip_and_remap_preconvert_state(ckpt)\n",
    "\n",
    "model = ResNetQAT(num_classes=10)\n",
    "missing, unexpected = model.load_state_dict(state_fp32, strict=False)\n",
    "\n",
    "# HARD CHECK: if any real weights are missing, stop.\n",
    "bad_missing = [k for k in missing if k.endswith(\".weight\") or k.endswith(\".bias\")]\n",
    "print(\"missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "print(\"bad_missing (should be empty):\", bad_missing[:30])\n",
    "\n",
    "assert len(bad_missing) == 0, \"You did NOT load trained weights correctly (still missing real params).\"\n",
    "\n",
    "model.eval().to(device)\n",
    "print(\"Loaded FP32 model from preconvert checkpoint ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a405ef-b9ed-4c31-811f-adc9967aae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (full): 88.64\n",
      "Torch acc (first 50): 88.703125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_acc(model, loader, device=\"cuda\", max_batches=None):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if max_batches is not None and bi >= max_batches:\n",
    "            break\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "print(\"Torch acc (full):\", torch_acc(model, test_loader, device=device))\n",
    "print(\"Torch acc (first 50):\", torch_acc(model, test_loader_b128, device=device, max_batches=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c861324f-ec23-4e3c-8746-15723a3d574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3519138/1693481859.py:15: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: resnet_fp32_b1_op13.onnx\n",
      "Exported: resnet_fp32_b64_op13.onnx\n",
      "Exported: resnet_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval().to(device)\n",
    "\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32, device=device),\n",
    "    64:  torch.randn(64,  3, 32, 32, device=device),\n",
    "    128: torch.randn(128, 3, 32, 32, device=device),\n",
    "}\n",
    "\n",
    "onnx_map = {}\n",
    "with torch.no_grad():  # not required, but safe\n",
    "    for bs, dummy in dummy_map.items():\n",
    "        out_path = f\"resnet_fp32_b{bs}_op13.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model, dummy, out_path,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"logits\"],\n",
    "            dynamic_axes=None,\n",
    "            dynamo=False\n",
    "        )\n",
    "        onnx_map[bs] = out_path\n",
    "        print(\"Exported:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7a1cccf-4add-485f-a181-01738e8aa2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-13:34:07] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:34:07] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:34:07] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:34:07] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:34:07] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:34:07] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:34:07] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:34:07] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:34:07] [TRT] [I] ----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5288505/ipykernel_3519138/1619425057.py:77: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  config.int8_calibrator = EntropyCalibrator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-13:34:07] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 3224, GPU 3128 (MiB)\n",
      "[12/14/2025-13:34:07] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:34:07] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:34:07] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:34:08] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:34:08] [TRT] [I] Total Host Persistent Memory: 148544 bytes\n",
      "[12/14/2025-13:34:08] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:34:08] [TRT] [I] Max Scratch Memory: 4608 bytes\n",
      "[12/14/2025-13:34:08] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 102 steps to complete.\n",
      "[12/14/2025-13:34:08] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.601302ms to assign 4 blocks to 102 nodes requiring 201216 bytes.\n",
      "[12/14/2025-13:34:08] [TRT] [I] Total Activation Memory: 201216 bytes\n",
      "[12/14/2025-13:34:08] [TRT] [I] Total Weights Memory: 3252776 bytes\n",
      "[12/14/2025-13:34:08] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:34:08] [TRT] [I] Engine generation completed in 0.972928 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 4 (MiB)\n",
      "[12/14/2025-13:34:08] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 0 in 0.00717305 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 1 in 0.0068032 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 2 in 0.00691905 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 3 in 0.00680823 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 4 in 0.00682748 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 5 in 0.0067557 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 6 in 0.00682156 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 7 in 0.0067671 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 8 in 0.00676951 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 9 in 0.00676948 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 10 in 0.0068003 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 11 in 0.006772 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 12 in 0.00674254 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 13 in 0.00672531 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 14 in 0.00668307 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 15 in 0.0067474 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 16 in 0.00670032 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 17 in 0.00677258 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 18 in 0.00677468 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 19 in 0.00677018 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 20 in 0.00672732 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 21 in 0.00679059 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 22 in 0.00680675 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 23 in 0.0067019 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 24 in 0.00680255 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 25 in 0.00677862 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 26 in 0.00676965 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 27 in 0.00676074 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 28 in 0.0067394 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 29 in 0.00678624 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 30 in 0.0068104 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 31 in 0.00678604 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 32 in 0.00682788 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 33 in 0.00676676 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 34 in 0.00675823 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 35 in 0.0067269 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 36 in 0.0067379 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 37 in 0.0067548 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 38 in 0.00677032 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 39 in 0.00674933 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 40 in 0.00676116 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 41 in 0.0064759 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 42 in 0.00637368 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 43 in 0.00639068 seconds.\n",
      "[12/14/2025-13:34:08] [TRT] [I]   Calibrated batch 44 in 0.00641089 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 45 in 0.00639314 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 46 in 0.00640779 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 47 in 0.00636314 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 48 in 0.00635508 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 49 in 0.00640322 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 50 in 0.00639159 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 51 in 0.00638351 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 52 in 0.00638328 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 53 in 0.00633096 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 54 in 0.00641128 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 55 in 0.00639813 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 56 in 0.00640152 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 57 in 0.006326 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 58 in 0.00640531 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 59 in 0.00630717 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 60 in 0.00639544 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 61 in 0.00636378 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 62 in 0.00637281 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 63 in 0.00638372 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 64 in 0.00637809 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 65 in 0.00634131 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 66 in 0.00634589 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 67 in 0.00639122 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 68 in 0.00632537 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 69 in 0.00637201 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 70 in 0.00642951 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 71 in 0.00635813 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 72 in 0.0062199 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 73 in 0.00618909 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 74 in 0.00623429 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 75 in 0.00618502 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 76 in 0.00621648 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 77 in 0.00618592 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 78 in 0.00621263 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 79 in 0.00624376 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 80 in 0.00622837 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 81 in 0.0062258 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 82 in 0.00618905 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 83 in 0.00622509 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 84 in 0.00624995 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 85 in 0.00622899 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 86 in 0.00622608 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 87 in 0.00621821 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 88 in 0.00620269 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 89 in 0.0062256 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 90 in 0.00624786 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 91 in 0.00620812 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 92 in 0.00623016 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 93 in 0.0062037 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 94 in 0.00624043 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 95 in 0.00617847 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 96 in 0.00618819 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 97 in 0.00626401 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 98 in 0.00621058 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 99 in 0.00620924 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 100 in 0.00619294 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 101 in 0.00619924 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 102 in 0.00617485 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 103 in 0.00618577 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 104 in 0.00620208 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 105 in 0.00622628 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 106 in 0.00619626 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 107 in 0.0061571 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 108 in 0.00618091 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 109 in 0.00615251 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 110 in 0.00620561 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 111 in 0.00610673 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 112 in 0.00613821 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 113 in 0.00618555 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 114 in 0.00616992 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 115 in 0.00613776 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 116 in 0.00615412 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 117 in 0.0061853 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 118 in 0.0061778 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 119 in 0.0061738 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 120 in 0.00615492 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 121 in 0.00614275 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 122 in 0.00614665 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 123 in 0.00616199 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 124 in 0.00617761 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 125 in 0.00611278 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 126 in 0.00612604 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 127 in 0.00614578 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 128 in 0.00615444 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 129 in 0.00615843 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 130 in 0.00614648 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 131 in 0.00618421 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 132 in 0.00614619 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 133 in 0.00618302 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 134 in 0.00616693 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 135 in 0.00618528 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 136 in 0.00612877 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 137 in 0.00618043 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 138 in 0.00618062 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 139 in 0.00616864 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 140 in 0.00620087 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 141 in 0.00613169 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 142 in 0.00619556 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 143 in 0.00612875 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 144 in 0.00617199 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 145 in 0.00615281 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 146 in 0.00614596 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 147 in 0.00615634 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 148 in 0.00615141 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 149 in 0.00616826 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 150 in 0.00620488 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 151 in 0.00623416 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 152 in 0.0061677 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 153 in 0.0061475 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 154 in 0.00620951 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 155 in 0.00611354 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 156 in 0.00617992 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 157 in 0.00612804 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 158 in 0.0061315 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 159 in 0.00614038 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 160 in 0.00616139 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 161 in 0.00619273 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 162 in 0.00612987 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 163 in 0.00614872 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 164 in 0.00615703 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 165 in 0.00618133 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 166 in 0.00616397 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 167 in 0.00618895 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 168 in 0.00612712 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 169 in 0.00618287 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 170 in 0.00616961 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 171 in 0.00618022 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 172 in 0.00616678 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 173 in 0.00619244 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 174 in 0.00617317 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 175 in 0.00614638 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 176 in 0.00618502 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 177 in 0.00615383 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 178 in 0.00620029 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 179 in 0.00615403 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 180 in 0.00617689 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 181 in 0.00619231 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 182 in 0.00613173 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 183 in 0.00616191 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 184 in 0.00615577 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 185 in 0.00614465 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 186 in 0.00617402 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 187 in 0.00616435 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 188 in 0.00616407 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 189 in 0.00619941 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 190 in 0.00618663 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 191 in 0.00614092 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 192 in 0.0061785 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 193 in 0.00617309 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 194 in 0.00617388 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 195 in 0.00617586 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 196 in 0.00614987 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 197 in 0.00618084 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 198 in 0.00610767 seconds.\n",
      "[12/14/2025-13:34:09] [TRT] [I]   Calibrated batch 199 in 0.00620223 seconds.\n",
      "[12/14/2025-13:34:15] [TRT] [I]   Post Processing Calibration data in 5.82296 seconds.\n",
      "[12/14/2025-13:34:15] [TRT] [I] Calibration completed in 8.11927 seconds.\n",
      "[12/14/2025-13:34:15] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:34:15] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:34:35] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:34:36] [TRT] [I] Total Host Persistent Memory: 172416 bytes\n",
      "[12/14/2025-13:34:36] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:34:36] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:34:36] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 37 steps to complete.\n",
      "[12/14/2025-13:34:36] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.126458ms to assign 3 blocks to 37 nodes requiring 98304 bytes.\n",
      "[12/14/2025-13:34:36] [TRT] [I] Total Activation Memory: 98304 bytes\n",
      "[12/14/2025-13:34:36] [TRT] [I] Total Weights Memory: 606212 bytes\n",
      "[12/14/2025-13:34:36] [TRT] [I] Engine generation completed in 20.7082 seconds.\n",
      "[12/14/2025-13:34:36] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 41 MiB\n",
      "Saved: resnet_int8_b1.engine\n",
      "[12/14/2025-13:34:36] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:34:36] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:34:36] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:34:36] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:34:36] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:34:36] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:34:36] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:34:36] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:34:36] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:34:37] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 3224, GPU 3128 (MiB)\n",
      "[12/14/2025-13:34:37] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:34:37] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:34:37] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:34:37] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:34:38] [TRT] [I] Total Host Persistent Memory: 113280 bytes\n",
      "[12/14/2025-13:34:38] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:34:38] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:34:38] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 83 steps to complete.\n",
      "[12/14/2025-13:34:38] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.335742ms to assign 3 blocks to 83 nodes requiring 12582912 bytes.\n",
      "[12/14/2025-13:34:38] [TRT] [I] Total Activation Memory: 12582912 bytes\n",
      "[12/14/2025-13:34:38] [TRT] [I] Total Weights Memory: 3416616 bytes\n",
      "[12/14/2025-13:34:38] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:34:38] [TRT] [I] Engine generation completed in 0.943341 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +12, now: CPU 0, GPU 16 (MiB)\n",
      "[12/14/2025-13:34:38] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 0 in 0.0121099 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 1 in 0.0120304 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 2 in 0.0117093 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 3 in 0.0115111 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 4 in 0.0114674 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 5 in 0.0114786 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 6 in 0.0115086 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 7 in 0.0114388 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 8 in 0.0115425 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 9 in 0.0117405 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 10 in 0.0115541 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 11 in 0.011537 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 12 in 0.0115773 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 13 in 0.0115993 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 14 in 0.0115694 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 15 in 0.0116286 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 16 in 0.0115473 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 17 in 0.0114992 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 18 in 0.0114929 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 19 in 0.0114995 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 20 in 0.0115629 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 21 in 0.0115491 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 22 in 0.0115836 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 23 in 0.0115496 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 24 in 0.0115765 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 25 in 0.0106714 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 26 in 0.0106526 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 27 in 0.0106661 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 28 in 0.0105684 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 29 in 0.0106113 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 30 in 0.0105663 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 31 in 0.0105726 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 32 in 0.0106441 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 33 in 0.0106711 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 34 in 0.0106047 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 35 in 0.0105922 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 36 in 0.0106086 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 37 in 0.0106442 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 38 in 0.0106499 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 39 in 0.0105803 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 40 in 0.0106002 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 41 in 0.0106551 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 42 in 0.010611 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 43 in 0.0106272 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 44 in 0.0106289 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 45 in 0.0106319 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 46 in 0.0106006 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 47 in 0.010677 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 48 in 0.0105395 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 49 in 0.0105933 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 50 in 0.010661 seconds.\n",
      "[12/14/2025-13:34:38] [TRT] [I]   Calibrated batch 51 in 0.0106515 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 52 in 0.0106144 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 53 in 0.0105891 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 54 in 0.0105761 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 55 in 0.0105763 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 56 in 0.0105861 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 57 in 0.0106144 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 58 in 0.0105842 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 59 in 0.0106329 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 60 in 0.0106413 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 61 in 0.0105801 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 62 in 0.0106228 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 63 in 0.0105901 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 64 in 0.0105692 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 65 in 0.010616 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 66 in 0.0106388 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 67 in 0.0105482 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 68 in 0.0106618 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 69 in 0.0105959 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 70 in 0.01066 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 71 in 0.0106114 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 72 in 0.0105881 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 73 in 0.0105367 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 74 in 0.0105741 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 75 in 0.0105881 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 76 in 0.0106016 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 77 in 0.0106232 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 78 in 0.0106689 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 79 in 0.0106089 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 80 in 0.0105682 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 81 in 0.0106168 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 82 in 0.0105648 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 83 in 0.0106091 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 84 in 0.0106627 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 85 in 0.0106338 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 86 in 0.0106362 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 87 in 0.0106172 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 88 in 0.0106688 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 89 in 0.0106312 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 90 in 0.0106046 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 91 in 0.010548 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 92 in 0.010578 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 93 in 0.0105882 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 94 in 0.0106499 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 95 in 0.0105745 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 96 in 0.0106833 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 97 in 0.0106431 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 98 in 0.0105992 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 99 in 0.0106144 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 100 in 0.0105705 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 101 in 0.0106032 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 102 in 0.0106049 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 103 in 0.0106654 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 104 in 0.0105825 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 105 in 0.0106337 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 106 in 0.010605 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 107 in 0.0106152 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 108 in 0.0106422 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 109 in 0.0106147 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 110 in 0.0105792 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 111 in 0.0106224 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 112 in 0.0106179 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 113 in 0.0105666 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 114 in 0.0106533 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 115 in 0.010629 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 116 in 0.0106509 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 117 in 0.0106512 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 118 in 0.0105772 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 119 in 0.0105121 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 120 in 0.0105878 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 121 in 0.0105234 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 122 in 0.0105044 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 123 in 0.0105244 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 124 in 0.0105716 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 125 in 0.0105186 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 126 in 0.010698 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 127 in 0.010629 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 128 in 0.0107462 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 129 in 0.0104889 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 130 in 0.0105578 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 131 in 0.0105038 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 132 in 0.0105467 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 133 in 0.0104974 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 134 in 0.0106085 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 135 in 0.0104975 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 136 in 0.0107625 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 137 in 0.0106221 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 138 in 0.0107903 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 139 in 0.0105154 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 140 in 0.0105533 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 141 in 0.0105315 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 142 in 0.0104966 seconds.\n",
      "[12/14/2025-13:34:39] [TRT] [I]   Calibrated batch 143 in 0.0105525 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 144 in 0.0105332 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 145 in 0.0105496 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 146 in 0.0105637 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 147 in 0.0105615 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 148 in 0.0107044 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 149 in 0.0106209 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 150 in 0.0105825 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 151 in 0.010554 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 152 in 0.0106271 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 153 in 0.0107406 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 154 in 0.01049 seconds.\n",
      "[12/14/2025-13:34:40] [TRT] [I]   Calibrated batch 155 in 0.0104721 seconds.\n",
      "[12/14/2025-13:34:45] [TRT] [I]   Post Processing Calibration data in 5.77208 seconds.\n",
      "[12/14/2025-13:34:45] [TRT] [I] Calibration completed in 8.53604 seconds.\n",
      "[12/14/2025-13:34:45] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:34:45] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:35:04] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:35:05] [TRT] [I] Total Host Persistent Memory: 177152 bytes\n",
      "[12/14/2025-13:35:05] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:35:05] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:35:05] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 38 steps to complete.\n",
      "[12/14/2025-13:35:05] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.135806ms to assign 3 blocks to 38 nodes requiring 4194304 bytes.\n",
      "[12/14/2025-13:35:05] [TRT] [I] Total Activation Memory: 4194304 bytes\n",
      "[12/14/2025-13:35:05] [TRT] [I] Total Weights Memory: 537092 bytes\n",
      "[12/14/2025-13:35:05] [TRT] [I] Engine generation completed in 19.374 seconds.\n",
      "[12/14/2025-13:35:05] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 41 MiB\n",
      "Saved: resnet_int8_b64.engine\n",
      "[12/14/2025-13:35:05] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:35:05] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-13:35:05] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-13:35:05] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-13:35:05] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-13:35:05] [TRT] [I] Domain:           \n",
      "[12/14/2025-13:35:05] [TRT] [I] Model version:    0\n",
      "[12/14/2025-13:35:05] [TRT] [I] Doc string:       \n",
      "[12/14/2025-13:35:05] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-13:35:06] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 3224, GPU 3128 (MiB)\n",
      "[12/14/2025-13:35:06] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Total Host Persistent Memory: 113280 bytes\n",
      "[12/14/2025-13:35:06] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:35:06] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:35:06] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 83 steps to complete.\n",
      "[12/14/2025-13:35:06] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.360389ms to assign 3 blocks to 83 nodes requiring 25165824 bytes.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Total Activation Memory: 25165824 bytes\n",
      "[12/14/2025-13:35:06] [TRT] [I] Total Weights Memory: 3416616 bytes\n",
      "[12/14/2025-13:35:06] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-13:35:06] [TRT] [I] Engine generation completed in 0.925424 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +24, now: CPU 0, GPU 28 (MiB)\n",
      "[12/14/2025-13:35:07] [TRT] [I] Starting Calibration.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 0 in 0.016591 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 1 in 0.0162586 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 2 in 0.015997 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 3 in 0.0160564 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 4 in 0.016034 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 5 in 0.0161274 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 6 in 0.0161255 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 7 in 0.0160831 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 8 in 0.0161225 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 9 in 0.0160518 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 10 in 0.0160604 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 11 in 0.0164628 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 12 in 0.0158277 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 13 in 0.0152538 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 14 in 0.0151796 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 15 in 0.0152241 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 16 in 0.0152511 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 17 in 0.0151949 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 18 in 0.015299 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 19 in 0.0152338 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 20 in 0.0152547 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 21 in 0.0152219 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 22 in 0.0152319 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 23 in 0.0152423 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 24 in 0.0156187 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 25 in 0.0152192 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 26 in 0.0152324 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 27 in 0.0151925 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 28 in 0.0151804 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 29 in 0.0151729 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 30 in 0.0151498 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 31 in 0.0153542 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 32 in 0.0153243 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 33 in 0.0152349 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 34 in 0.0152838 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 35 in 0.0152876 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 36 in 0.0153921 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 37 in 0.0152434 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 38 in 0.0152427 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 39 in 0.0151463 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 40 in 0.0151816 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 41 in 0.0151775 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 42 in 0.015329 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 43 in 0.0153636 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 44 in 0.0151755 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 45 in 0.0152198 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 46 in 0.0151601 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 47 in 0.0151312 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 48 in 0.0152058 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 49 in 0.0154988 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 50 in 0.0152453 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 51 in 0.0151833 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 52 in 0.0151699 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 53 in 0.0152103 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 54 in 0.0151706 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 55 in 0.0153727 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 56 in 0.0153158 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 57 in 0.0152654 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 58 in 0.0152914 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 59 in 0.0152768 seconds.\n",
      "[12/14/2025-13:35:07] [TRT] [I]   Calibrated batch 60 in 0.0152703 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 61 in 0.0155929 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 62 in 0.015261 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 63 in 0.0153281 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 64 in 0.0152314 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 65 in 0.015106 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 66 in 0.0152168 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 67 in 0.0151685 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 68 in 0.0151977 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 69 in 0.0151311 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 70 in 0.0153477 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 71 in 0.0151025 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 72 in 0.0151709 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 73 in 0.0151957 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 74 in 0.0150783 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 75 in 0.0150453 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 76 in 0.0150592 seconds.\n",
      "[12/14/2025-13:35:08] [TRT] [I]   Calibrated batch 77 in 0.015092 seconds.\n",
      "[12/14/2025-13:35:14] [TRT] [I]   Post Processing Calibration data in 5.75952 seconds.\n",
      "[12/14/2025-13:35:14] [TRT] [I] Calibration completed in 8.01688 seconds.\n",
      "[12/14/2025-13:35:14] [TRT] [I] Writing Calibration Cache for calibrator: TRT-101401-EntropyCalibration2\n",
      "[12/14/2025-13:35:14] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-13:35:32] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-13:35:33] [TRT] [I] Total Host Persistent Memory: 184064 bytes\n",
      "[12/14/2025-13:35:33] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-13:35:33] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/14/2025-13:35:33] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 38 steps to complete.\n",
      "[12/14/2025-13:35:33] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.133993ms to assign 3 blocks to 38 nodes requiring 8388608 bytes.\n",
      "[12/14/2025-13:35:33] [TRT] [I] Total Activation Memory: 8388608 bytes\n",
      "[12/14/2025-13:35:33] [TRT] [I] Total Weights Memory: 537092 bytes\n",
      "[12/14/2025-13:35:33] [TRT] [I] Engine generation completed in 19.3782 seconds.\n",
      "[12/14/2025-13:35:33] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 41 MiB\n",
      "Saved: resnet_int8_b128.engine\n",
      "INT8 engines built: {1: 'resnet_int8_b1.engine', 64: 'resnet_int8_b64.engine', 128: 'resnet_int8_b128.engine'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# ----------------------------\n",
    "# INT8 Entropy Calibrator\n",
    "# ----------------------------\n",
    "class EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calib_loader, max_batches=200, cache_file=\"calib.cache\"):\n",
    "        super().__init__()\n",
    "        self.data_iter = iter(calib_loader)\n",
    "        self.max_batches = max_batches\n",
    "        self.batch_count = 0\n",
    "        self.cache_file = cache_file\n",
    "\n",
    "        # initial shape (just to allocate something)\n",
    "        x0, _ = next(iter(calib_loader))\n",
    "        self.batch_size = x0.shape[0]\n",
    "        self.device_input = torch.empty_like(x0, device=\"cuda\")\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_batch(self, names):\n",
    "        if self.batch_count >= self.max_batches:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            x, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        self.batch_count += 1\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        # ✅ IMPORTANT: ensure buffer matches incoming shape\n",
    "        if self.device_input.numel() != x.numel():\n",
    "            self.device_input = torch.empty_like(x, device=\"cuda\")\n",
    "        else:\n",
    "            self.device_input = self.device_input.view_as(x)\n",
    "\n",
    "        self.device_input.copy_(x)\n",
    "        return [int(self.device_input.data_ptr())]\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        return None  # ✅ force fresh calibration\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "# ----------------------------\n",
    "# Build static INT8 engine\n",
    "# ----------------------------\n",
    "def build_int8_engine_static(onnx_path, engine_path, calib_loader, max_calib_batches=200):\n",
    "    # ✅ IMPORTANT: delete old cache so TRT can't reuse stale scales\n",
    "    cache_path = engine_path.replace(\".engine\", \".cache\")\n",
    "    if os.path.exists(cache_path):\n",
    "        os.remove(cache_path)\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed: {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        config.int8_calibrator = EntropyCalibrator(\n",
    "            calib_loader,\n",
    "            max_batches=max_calib_batches,\n",
    "            cache_file=cache_path\n",
    "        )\n",
    "\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"INT8 engine build failed: {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Build engines for each batch size\n",
    "# ----------------------------\n",
    "calib_loader_map = {\n",
    "    1:   test_loader_b1,\n",
    "    64:  test_loader_b64,\n",
    "    128: test_loader_b128,\n",
    "}\n",
    "\n",
    "engine_map = {}\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"resnet_int8_b{bs}.engine\"\n",
    "    build_int8_engine_static(\n",
    "        onnx_path=onnx_path,\n",
    "        engine_path=engine_path,\n",
    "        calib_loader=calib_loader_map[bs],\n",
    "        max_calib_batches=200\n",
    "    )\n",
    "    engine_map[bs] = engine_path\n",
    "\n",
    "print(\"INT8 engines built:\", engine_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c18192-c88b-4817-b3be-f83ed04b4bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_int8_b128.engine\n",
      "  IN : input (128, 3, 32, 32) DataType.FLOAT\n",
      "  OUT: logits (128, 10) DataType.FLOAT\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "def inspect_engine(engine_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as rt:\n",
    "        eng = rt.deserialize_cuda_engine(f.read())\n",
    "    names = [eng.get_tensor_name(i) for i in range(eng.num_io_tensors)]\n",
    "    inp = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if eng.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    print(engine_path)\n",
    "    print(\"  IN :\", inp, eng.get_tensor_shape(inp), eng.get_tensor_dtype(inp))\n",
    "    print(\"  OUT:\", out, eng.get_tensor_shape(out), eng.get_tensor_dtype(out))\n",
    "\n",
    "inspect_engine(\"resnet_int8_b128.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94c530db-5ed2-43f9-820a-8d75f4f55177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resnet_int8_b1.engine\n",
      "  batch: 1\n",
      "  acc: 90.00% (first 50 batches)\n",
      "  latency ms: mean=0.376, p50=0.376, p90=0.378, p99=0.384\n",
      "  throughput: 2658.1 img/s\n",
      "\n",
      "resnet_int8_b64.engine\n",
      "  batch: 64\n",
      "  acc: 88.66% (first 50 batches)\n",
      "  latency ms: mean=0.517, p50=0.516, p90=0.519, p99=0.532\n",
      "  throughput: 123880.1 img/s\n",
      "\n",
      "resnet_int8_b128.engine\n",
      "  batch: 128\n",
      "  acc: 88.67% (first 50 batches)\n",
      "  latency ms: mean=0.609, p50=0.608, p90=0.610, p99=0.616\n",
      "  throughput: 210303.2 img/s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER_EVAL = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def load_engine(engine_path):\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER_EVAL) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    if engine is None:\n",
    "        raise RuntimeError(f\"Failed to load engine: {engine_path}\")\n",
    "    return engine, engine.create_execution_context()\n",
    "\n",
    "def get_io_names(engine):\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "    return inp, out\n",
    "\n",
    "def trt_dtype_to_torch(dt):\n",
    "    return {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "        trt.DataType.BOOL:  torch.bool,\n",
    "    }[dt]\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_eval(engine_path, loader, warmup=50, iters=200, acc_batches=50):\n",
    "    engine, context = load_engine(engine_path)\n",
    "    inp_name, out_name = get_io_names(engine)\n",
    "\n",
    "    in_shape  = tuple(engine.get_tensor_shape(inp_name))\n",
    "    out_shape = tuple(engine.get_tensor_shape(out_name))\n",
    "    bsz = in_shape[0]\n",
    "\n",
    "    out_torch_dtype = trt_dtype_to_torch(engine.get_tensor_dtype(out_name))\n",
    "\n",
    "    # non-default stream (avoids TRT warning + better perf)\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # --------------- Accuracy (first acc_batches) ---------------\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(loader):\n",
    "        if bi >= acc_batches:\n",
    "            break\n",
    "        if x_cpu.shape[0] != bsz:\n",
    "            raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        stream.synchronize()\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += bsz\n",
    "\n",
    "    acc = 100.0 * correct / max(1, total)\n",
    "\n",
    "    # --------------- Latency / Throughput microbench ---------------\n",
    "    # Use one batch from loader\n",
    "    x_cpu, _ = next(iter(loader))\n",
    "    if x_cpu.shape[0] != bsz:\n",
    "        raise RuntimeError(f\"Batch mismatch: loader={x_cpu.shape[0]} vs engine={bsz}\")\n",
    "    x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "    yhat = torch.empty(out_shape, device=\"cuda\", dtype=out_torch_dtype)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed runs (use CUDA events for accurate GPU timing)\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    times_ms = []\n",
    "    for _ in range(iters):\n",
    "        starter.record(stream)\n",
    "        with torch.cuda.stream(stream):\n",
    "            context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "            context.set_tensor_address(out_name, int(yhat.data_ptr()))\n",
    "            ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "            if not ok:\n",
    "                raise RuntimeError(\"TRT execute failed\")\n",
    "        ender.record(stream)\n",
    "        stream.synchronize()\n",
    "        times_ms.append(starter.elapsed_time(ender))\n",
    "\n",
    "    times_ms = np.array(times_ms, dtype=np.float64)\n",
    "    p50 = float(np.percentile(times_ms, 50))\n",
    "    p90 = float(np.percentile(times_ms, 90))\n",
    "    p99 = float(np.percentile(times_ms, 99))\n",
    "    mean = float(times_ms.mean())\n",
    "\n",
    "    # throughput (images/sec)\n",
    "    ips = (1000.0 / mean) * bsz\n",
    "\n",
    "    return {\n",
    "        \"engine\": engine_path,\n",
    "        \"batch\": bsz,\n",
    "        \"acc_%\": acc,\n",
    "        \"lat_mean_ms\": mean,\n",
    "        \"lat_p50_ms\": p50,\n",
    "        \"lat_p90_ms\": p90,\n",
    "        \"lat_p99_ms\": p99,\n",
    "        \"throughput_img_s\": ips,\n",
    "    }\n",
    "\n",
    "# ---- Run for b1/b64/b128 ----\n",
    "results = []\n",
    "results.append(trt_eval(engine_map[1],   test_loader_b1,   warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[64],  test_loader_b64,  warmup=50, iters=200, acc_batches=50))\n",
    "results.append(trt_eval(engine_map[128], test_loader_b128, warmup=50, iters=200, acc_batches=50))\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n{r['engine']}\")\n",
    "    print(f\"  batch: {r['batch']}\")\n",
    "    print(f\"  acc: {r['acc_%']:.2f}% (first 50 batches)\")\n",
    "    print(f\"  latency ms: mean={r['lat_mean_ms']:.3f}, p50={r['lat_p50_ms']:.3f}, p90={r['lat_p90_ms']:.3f}, p99={r['lat_p99_ms']:.3f}\")\n",
    "    print(f\"  throughput: {r['throughput_img_s']:.1f} img/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb50c10-6590-42f1-8579-d031c3412d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc (model used for export): 88.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch acc (model used for export):\", torch_acc(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35712b3c-8c6a-4641-bbdf-70a51fea4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 981K Dec 14 13:34 resnet_int8_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 833K Dec 14 13:35 resnet_int8_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 808K Dec 14 13:35 resnet_int8_b128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh resnet_int8_b1.engine\n",
    "!ls -lh resnet_int8_b64.engine\n",
    "!ls -lh resnet_int8_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5abc0f-77ea-42a1-a397-b91c85c726cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
