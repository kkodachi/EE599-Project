{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fb18d4-66d7-421d-bf00-63460b5c60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128 CUDA: True\n",
      "TensorRT: 10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"TensorRT:\", trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20c95b9-71ae-476f-9fe5-3997105ecf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[1]))\n",
    "\n",
    "from models.alexnet_model import AlexNetCIFAR10\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd93386-e7a2-4028-8377-27899c33347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNetCIFAR10(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNetCIFAR10(num_classes=10)\n",
    "model.load_state_dict(\n",
    "    torch.load(\"../../pth/alexnet_30.pth\", map_location=\"cpu\")\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ea8db1-83f3-4806-8401-14ac8fcedd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5287623/ipykernel_2164780/3752016516.py:12: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported alexnet_30_fp32_b1_op13.onnx\n",
      "Exported alexnet_30_fp32_b64_op13.onnx\n",
      "Exported alexnet_30_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32),\n",
    "    64:  torch.randn(64,  3, 32, 32),\n",
    "    128: torch.randn(128, 3, 32, 32),\n",
    "}\n",
    "\n",
    "for bs, dummy in dummy_map.items():\n",
    "    out_path = f\"alexnet_30_fp32_b{bs}_op13.onnx\"\n",
    "    torch.onnx.export(\n",
    "        model, dummy, out_path,\n",
    "        opset_version=13,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes=None,   # <-- IMPORTANT: static\n",
    "        dynamo=False\n",
    "    )\n",
    "    print(\"Exported\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17143253-186e-4c27-ad4a-c67f1e4d6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 4.0M Dec 14 02:05 alexnet_30_fp32_b1_op13.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 4.0M Dec 14 02:05 alexnet_30_fp32_b64_op13.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 4.0M Dec 14 02:05 alexnet_30_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh alexnet_30_fp32_b1_op13.onnx\n",
    "!ls -lh alexnet_30_fp32_b64_op13.onnx\n",
    "!ls -lh alexnet_30_fp32_b128_op13.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85a783e-e0c7-4e28-ae74-93c7507e8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 13)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"alexnet_30_fp32_b1_op13.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "print([(op.domain, op.version) for op in m.opset_import])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ac89d5-edbc-4178-b9e1-8f408f840f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "print(trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0c6a83-4e52-4242-aea3-229a1256bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-02:05:43] [TRT] [I] [MemUsageChange] Init CUDA: CPU -23, GPU +0, now: CPU 285, GPU 4152 (MiB)\n",
      "[12/14/2025-02:05:43] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:43] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:05:43] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:05:43] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:05:43] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:05:43] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:05:43] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:05:43] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:05:43] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:43] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +278, GPU +8, now: CPU 674, GPU 4160 (MiB)\n",
      "[12/14/2025-02:05:43] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:05:46] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:05:48] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:05:48] [TRT] [I] Total Host Persistent Memory: 45232 bytes\n",
      "[12/14/2025-02:05:48] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:05:48] [TRT] [I] Max Scratch Memory: 1024 bytes\n",
      "[12/14/2025-02:05:48] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 11 steps to complete.\n",
      "[12/14/2025-02:05:48] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.128933ms to assign 2 blocks to 11 nodes requiring 196608 bytes.\n",
      "[12/14/2025-02:05:48] [TRT] [I] Total Activation Memory: 196608 bytes\n",
      "[12/14/2025-02:05:48] [TRT] [I] Total Weights Memory: 4191872 bytes\n",
      "[12/14/2025-02:05:48] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:05:48] [TRT] [I] Engine generation completed in 4.23277 seconds.\n",
      "[12/14/2025-02:05:48] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 8 MiB\n",
      "Saved: alexnet_30_fp32_b1.engine\n",
      "[12/14/2025-02:05:48] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:48] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:05:48] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:05:48] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:05:48] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:05:48] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:05:48] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:05:48] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:05:48] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:48] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +2, now: CPU 2733, GPU 4406 (MiB)\n",
      "[12/14/2025-02:05:48] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:05:51] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:05:52] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:05:52] [TRT] [I] Total Host Persistent Memory: 45488 bytes\n",
      "[12/14/2025-02:05:52] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:05:52] [TRT] [I] Max Scratch Memory: 65536 bytes\n",
      "[12/14/2025-02:05:52] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 12 steps to complete.\n",
      "[12/14/2025-02:05:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.146245ms to assign 3 blocks to 12 nodes requiring 12583424 bytes.\n",
      "[12/14/2025-02:05:52] [TRT] [I] Total Activation Memory: 12582912 bytes\n",
      "[12/14/2025-02:05:52] [TRT] [I] Total Weights Memory: 4192128 bytes\n",
      "[12/14/2025-02:05:52] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:05:52] [TRT] [I] Engine generation completed in 4.04335 seconds.\n",
      "[12/14/2025-02:05:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 16 MiB\n",
      "Saved: alexnet_30_fp32_b64.engine\n",
      "[12/14/2025-02:05:52] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:52] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:05:52] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:05:52] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:05:52] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:05:52] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:05:52] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:05:52] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:05:52] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:53] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +2, now: CPU 2760, GPU 4408 (MiB)\n",
      "[12/14/2025-02:05:53] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:05:56] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:05:57] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:05:57] [TRT] [I] Total Host Persistent Memory: 45488 bytes\n",
      "[12/14/2025-02:05:57] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:05:57] [TRT] [I] Max Scratch Memory: 131072 bytes\n",
      "[12/14/2025-02:05:57] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 12 steps to complete.\n",
      "[12/14/2025-02:05:57] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.140003ms to assign 3 blocks to 12 nodes requiring 25166336 bytes.\n",
      "[12/14/2025-02:05:57] [TRT] [I] Total Activation Memory: 25165824 bytes\n",
      "[12/14/2025-02:05:57] [TRT] [I] Total Weights Memory: 4192128 bytes\n",
      "[12/14/2025-02:05:57] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:05:57] [TRT] [I] Engine generation completed in 4.17211 seconds.\n",
      "[12/14/2025-02:05:57] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 32 MiB\n",
      "Saved: alexnet_30_fp32_b128.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# IMPORTANT: these ONNX files must be exported with FIXED batch sizes (static)\n",
    "onnx_map = {\n",
    "    1:   \"alexnet_30_fp32_b1_op13.onnx\",\n",
    "    64:  \"alexnet_30_fp32_b64_op13.onnx\",\n",
    "    128: \"alexnet_30_fp32_b128_op13.onnx\",\n",
    "}\n",
    "\n",
    "def build_static_engine(onnx_path, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed for {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # NO optimization profile => static engine (uses whatever fixed shape is in ONNX)\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"Engine build failed for {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"alexnet_30_fp32_b{bs}.engine\"\n",
    "    build_static_engine(onnx_path, engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37bac398-e290-467b-bf6c-a49cc60b1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 4.2M Dec 14 02:05 alexnet_30_fp32_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 4.2M Dec 14 02:05 alexnet_30_fp32_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 4.3M Dec 14 02:05 alexnet_30_fp32_b128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh alexnet_30_fp32_b1.engine\n",
    "!ls -lh alexnet_30_fp32_b64.engine\n",
    "!ls -lh alexnet_30_fp32_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa592380-cf3a-43a7-bfdf-19ee4c109118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting benchmark (3 static engines)...\n",
      "alexnet_30_fp32_b1.engine | batch=1\n",
      "  latency:     0.092 ms/batch\n",
      "  per-image:   0.091725 ms/image\n",
      "  throughput:  10902.2 images/sec\n",
      "alexnet_30_fp32_b64.engine | batch=64\n",
      "  latency:     0.205 ms/batch\n",
      "  per-image:   0.003209 ms/image\n",
      "  throughput:  311635.2 images/sec\n",
      "alexnet_30_fp32_b128.engine | batch=128\n",
      "  latency:     0.329 ms/batch\n",
      "  per-image:   0.002572 ms/image\n",
      "  throughput:  388853.3 images/sec\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "def benchmark_engine_static(engine_path, batch_size, iters=1000):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # ✅ STATIC engine: DO NOT set_input_shape()\n",
    "    # context.set_input_shape(inp, (batch_size, 3, 32, 32))\n",
    "\n",
    "    x = torch.randn(batch_size, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out, int(y.data_ptr()))\n",
    "\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    end.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = start.elapsed_time(end)\n",
    "\n",
    "    batch_latency_ms = elapsed_ms / iters\n",
    "    throughput = (iters * batch_size) / (elapsed_ms / 1000.0)\n",
    "    ms_per_img = batch_latency_ms / batch_size\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch_size}\")\n",
    "    print(f\"  latency:     {batch_latency_ms:.3f} ms/batch\")\n",
    "    print(f\"  per-image:   {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:  {throughput:.1f} images/sec\")\n",
    "\n",
    "\n",
    "print(\"Starting benchmark (3 static engines)...\")\n",
    "benchmark_engine_static(\"alexnet_30_fp32_b1.engine\",   batch_size=1,   iters=1000)\n",
    "benchmark_engine_static(\"alexnet_30_fp32_b64.engine\",  batch_size=64,  iters=1000)\n",
    "benchmark_engine_static(\"alexnet_30_fp32_b128.engine\", batch_size=128, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dfa043-1872-4920-873f-04560db1663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-02:05:58] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:58] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:05:58] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:05:58] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:05:58] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:05:58] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:05:58] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:05:58] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:05:58] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:05:59] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 2747, GPU 4452 (MiB)\n",
      "[12/14/2025-02:05:59] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:06:04] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:06:06] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:06:07] [TRT] [I] Total Host Persistent Memory: 43696 bytes\n",
      "[12/14/2025-02:06:07] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:06:07] [TRT] [I] Max Scratch Memory: 1024 bytes\n",
      "[12/14/2025-02:06:07] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 11 steps to complete.\n",
      "[12/14/2025-02:06:07] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.130225ms to assign 2 blocks to 11 nodes requiring 98304 bytes.\n",
      "[12/14/2025-02:06:07] [TRT] [I] Total Activation Memory: 98304 bytes\n",
      "[12/14/2025-02:06:07] [TRT] [I] Total Weights Memory: 2098304 bytes\n",
      "[12/14/2025-02:06:07] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:06:07] [TRT] [I] Engine generation completed in 8.48327 seconds.\n",
      "[12/14/2025-02:06:07] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 32 MiB\n",
      "Saved: alexnet_30_fp16_b1.engine\n",
      "[12/14/2025-02:06:07] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:06:07] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:06:07] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:06:07] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:06:07] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:06:07] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:06:07] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:06:07] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:06:07] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:06:08] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 2787, GPU 4456 (MiB)\n",
      "[12/14/2025-02:06:08] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:06:13] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:06:15] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:06:15] [TRT] [I] Total Host Persistent Memory: 44400 bytes\n",
      "[12/14/2025-02:06:15] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:06:15] [TRT] [I] Max Scratch Memory: 34304 bytes\n",
      "[12/14/2025-02:06:15] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 11 steps to complete.\n",
      "[12/14/2025-02:06:15] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.150132ms to assign 2 blocks to 11 nodes requiring 6291456 bytes.\n",
      "[12/14/2025-02:06:15] [TRT] [I] Total Activation Memory: 6291456 bytes\n",
      "[12/14/2025-02:06:15] [TRT] [I] Total Weights Memory: 2098560 bytes\n",
      "[12/14/2025-02:06:15] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:06:15] [TRT] [I] Engine generation completed in 7.45888 seconds.\n",
      "[12/14/2025-02:06:15] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 32 MiB\n",
      "Saved: alexnet_30_fp16_b64.engine\n",
      "[12/14/2025-02:06:15] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:06:15] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/14/2025-02:06:15] [TRT] [I] Opset version:    13\n",
      "[12/14/2025-02:06:15] [TRT] [I] Producer name:    pytorch\n",
      "[12/14/2025-02:06:15] [TRT] [I] Producer version: 2.9.1\n",
      "[12/14/2025-02:06:15] [TRT] [I] Domain:           \n",
      "[12/14/2025-02:06:15] [TRT] [I] Model version:    0\n",
      "[12/14/2025-02:06:15] [TRT] [I] Doc string:       \n",
      "[12/14/2025-02:06:15] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/14/2025-02:06:16] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -277, GPU +0, now: CPU 2792, GPU 4458 (MiB)\n",
      "[12/14/2025-02:06:16] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/14/2025-02:06:21] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/14/2025-02:06:23] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/14/2025-02:06:23] [TRT] [I] Total Host Persistent Memory: 45104 bytes\n",
      "[12/14/2025-02:06:23] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/14/2025-02:06:23] [TRT] [I] Max Scratch Memory: 68096 bytes\n",
      "[12/14/2025-02:06:23] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 11 steps to complete.\n",
      "[12/14/2025-02:06:23] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.149551ms to assign 2 blocks to 11 nodes requiring 12582912 bytes.\n",
      "[12/14/2025-02:06:23] [TRT] [I] Total Activation Memory: 12582912 bytes\n",
      "[12/14/2025-02:06:23] [TRT] [I] Total Weights Memory: 2098560 bytes\n",
      "[12/14/2025-02:06:23] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/14/2025-02:06:23] [TRT] [I] Engine generation completed in 7.51573 seconds.\n",
      "[12/14/2025-02:06:23] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 32 MiB\n",
      "Saved: alexnet_30_fp16_b128.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# IMPORTANT: these ONNX files must be exported with FIXED batch sizes (static)\n",
    "onnx_map = {\n",
    "    1:   \"alexnet_30_fp32_b1_op13.onnx\",\n",
    "    64:  \"alexnet_30_fp32_b64_op13.onnx\",\n",
    "    128: \"alexnet_30_fp32_b128_op13.onnx\",\n",
    "}\n",
    "\n",
    "def build_static_fp16_engine(onnx_path, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed for {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # ✅ FP16 enabled\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "        # ✅ NO optimization profile => static engine (fixed shape from ONNX)\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"FP16 engine build failed for {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"alexnet_30_fp16_b{bs}.engine\"\n",
    "    build_static_fp16_engine(onnx_path, engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff36bb1-0473-480e-96e4-239d24e4e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 2.2M Dec 14 02:06 alexnet_30_fp16_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.2M Dec 14 02:06 alexnet_30_fp16_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.2M Dec 14 02:06 alexnet_30_fp16_b128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh alexnet_30_fp16_b1.engine\n",
    "!ls -lh alexnet_30_fp16_b64.engine\n",
    "!ls -lh alexnet_30_fp16_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb914e1-f19a-42c2-b8e4-04ae245d5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_30_fp16_b1.engine | batch=1\n",
      "  batch latency: 0.070 ms/batch\n",
      "  per-image:     0.070056 ms/image\n",
      "  throughput:    14274.3 images/sec\n",
      "alexnet_30_fp16_b64.engine | batch=64\n",
      "  batch latency: 0.127 ms/batch\n",
      "  per-image:     0.001991 ms/image\n",
      "  throughput:    502197.6 images/sec\n",
      "alexnet_30_fp16_b128.engine | batch=128\n",
      "  batch latency: 0.177 ms/batch\n",
      "  per-image:     0.001379 ms/image\n",
      "  throughput:    725066.4 images/sec\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "def run_engine_static(engine_path, batch, iters=1000, warmup=50):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # ❌ NO set_input_shape() for static engines\n",
    "\n",
    "    x = torch.randn(batch, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out_name)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out_name, int(y.data_ptr()))\n",
    "\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    end.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = start.elapsed_time(end)\n",
    "    batch_latency_ms = elapsed_ms / iters\n",
    "    ms_per_img = batch_latency_ms / batch\n",
    "    img_per_sec = (iters * batch) / (elapsed_ms / 1000.0)\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch}\")\n",
    "    print(f\"  batch latency: {batch_latency_ms:.3f} ms/batch\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:    {img_per_sec:.1f} images/sec\")\n",
    "\n",
    "run_engine_static(\"alexnet_30_fp16_b1.engine\",   1)\n",
    "run_engine_static(\"alexnet_30_fp16_b64.engine\",  64)\n",
    "run_engine_static(\"alexnet_30_fp16_b128.engine\", 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250f0dd1-9496-4b88-add3-6ab7503cd722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f3b54e-aac2-4547-af94-14fdf8d9f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader_b1   = DataLoader(test_dataset, batch_size=1,   shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b64  = DataLoader(test_dataset, batch_size=64,  shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "test_loader_b128 = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb0ea02-1c28-416f-917b-48b6789cd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_accuracy_static(engine_path, test_loader, num_batches=None):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # engine fixed shapes\n",
    "    in_shape = tuple(engine.get_tensor_shape(inp))\n",
    "    out_shape = tuple(engine.get_tensor_shape(out))\n",
    "    fixed_bsz = in_shape[0]  # should be 1 or 64 or 128\n",
    "\n",
    "    # output dtype\n",
    "    trt_dtype = engine.get_tensor_dtype(out)\n",
    "    torch_dtype = {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "    }[trt_dtype]\n",
    "\n",
    "    stream = torch.cuda.current_stream()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(test_loader):\n",
    "        if num_batches is not None and bi >= num_batches:\n",
    "            break\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        if x.shape[0] != fixed_bsz:\n",
    "            raise RuntimeError(f\"Batch mismatch: loader={x.shape[0]} but engine expects {fixed_bsz}\")\n",
    "\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=torch_dtype)\n",
    "\n",
    "        context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "        context.set_tensor_address(out, int(yhat.data_ptr()))\n",
    "\n",
    "        ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"TRT execute failed\")\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.shape[0]\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e04cc8-22e8-41d7-9345-d5bd98464ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-02:06:38] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:06:44] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:06:45] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "FP32 TRT Acc b1:   88.49%\n",
      "FP32 TRT Acc b64:  88.48%\n",
      "FP32 TRT Acc b128: 88.48%\n"
     ]
    }
   ],
   "source": [
    "acc1   = trt_accuracy_static(\"alexnet_30_fp32_b1.engine\",   test_loader_b1)\n",
    "acc64  = trt_accuracy_static(\"alexnet_30_fp32_b64.engine\",  test_loader_b64)\n",
    "acc128 = trt_accuracy_static(\"alexnet_30_fp32_b128.engine\", test_loader_b128)\n",
    "\n",
    "print(f\"FP32 TRT Acc b1:   {acc1:.2f}%\")\n",
    "print(f\"FP32 TRT Acc b64:  {acc64:.2f}%\")\n",
    "print(f\"FP32 TRT Acc b128: {acc128:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90f820f0-364f-4320-93e4-b90ed0965239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-02:06:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:06:53] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:06:54] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "FP16 TRT Acc b1:   88.49%\n",
      "FP16 TRT Acc b64:  88.47%\n",
      "FP16 TRT Acc b128: 88.47%\n"
     ]
    }
   ],
   "source": [
    "acc1   = trt_accuracy_static(\"alexnet_30_fp16_b1.engine\",   test_loader_b1)\n",
    "acc64  = trt_accuracy_static(\"alexnet_30_fp16_b64.engine\",  test_loader_b64)\n",
    "acc128 = trt_accuracy_static(\"alexnet_30_fp16_b128.engine\", test_loader_b128)\n",
    "\n",
    "print(f\"FP16 TRT Acc b1:   {acc1:.2f}%\")\n",
    "print(f\"FP16 TRT Acc b64:  {acc64:.2f}%\")\n",
    "print(f\"FP16 TRT Acc b128: {acc128:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5be43fb-7d8f-445b-8bc2-27280ac2ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5287623/ipykernel_2164780/2590553118.py:69: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  config.int8_calibrator = EntropyCalibrator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: alexnet_30_int8_b1.engine (calib_batches=200)\n",
      "Saved: alexnet_30_int8_b64.engine (calib_batches=200)\n",
      "Saved: alexnet_30_int8_b128.engine (calib_batches=200)\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "# ✅ reduce spam\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# ✅ use your 3 fixed-shape ONNX files\n",
    "onnx_map = {\n",
    "    1:   \"alexnet_30_fp32_b1_op13.onnx\",\n",
    "    64:  \"alexnet_30_fp32_b64_op13.onnx\",\n",
    "    128: \"alexnet_30_fp32_b128_op13.onnx\",\n",
    "}\n",
    "\n",
    "class EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calib_loader, max_batches=200, cache_file=\"calib.cache\"):\n",
    "        super().__init__()\n",
    "        self.cache_file = cache_file\n",
    "        self.data_iter = iter(calib_loader)\n",
    "        self.max_batches = max_batches\n",
    "        self.batch_count = 0\n",
    "\n",
    "        x0, _ = next(iter(calib_loader))\n",
    "        self.batch_size = x0.shape[0]\n",
    "        self.device_input = torch.empty_like(x0, device=\"cuda\")\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_batch(self, names):\n",
    "        if self.batch_count >= self.max_batches:\n",
    "            return None\n",
    "        try:\n",
    "            x, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        self.batch_count += 1\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "        self.device_input.resize_(x.shape).copy_(x)\n",
    "        return [int(self.device_input.data_ptr())]\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        try:\n",
    "            with open(self.cache_file, \"rb\") as f:\n",
    "                return f.read()\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "def build_int8_engine_static(onnx_path, engine_path, calib_loader, max_calib_batches=200):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed for {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # INT8 PTQ\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        config.int8_calibrator = EntropyCalibrator(\n",
    "            calib_loader,\n",
    "            max_batches=max_calib_batches,\n",
    "            cache_file=engine_path.replace(\".engine\", \".cache\")\n",
    "        )\n",
    "\n",
    "        # ✅ static ONNX => NO optimization profile needed\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"INT8 Engine build failed for {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(f\"Saved: {engine_path} (calib_batches={max_calib_batches})\")\n",
    "\n",
    "# ✅ make sure these match the ONNX batch size:\n",
    "calib_loader_map = {\n",
    "    1:   test_loader_b1,\n",
    "    64:  test_loader_b64,\n",
    "    128: test_loader_b128,\n",
    "}\n",
    "\n",
    "CALIB_BATCHES = 200\n",
    "\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    build_int8_engine_static(\n",
    "        onnx_path=onnx_path,\n",
    "        engine_path=f\"alexnet_30_int8_b{bs}.engine\",\n",
    "        calib_loader=calib_loader_map[bs],\n",
    "        max_calib_batches=CALIB_BATCHES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e99fb4-c4f8-421f-ac0d-86fd5d08cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 1.5M Dec 14 02:07 alexnet_30_int8_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.2M Dec 14 02:07 alexnet_30_int8_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.2M Dec 14 02:07 alexnet_30_int8_b128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh alexnet_30_int8_b1.engine\n",
    "!ls -lh alexnet_30_int8_b64.engine\n",
    "!ls -lh alexnet_30_int8_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ef2046-109c-45e9-8d6f-aa5cd7eb4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/14/2025-02:07:40] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:07:46] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[12/14/2025-02:07:47] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "INT8 TRT Acc b1:   88.46%\n",
      "INT8 TRT Acc b64:  88.34%\n",
      "INT8 TRT Acc b128: 88.30%\n"
     ]
    }
   ],
   "source": [
    "acc1   = trt_accuracy_static(\"alexnet_30_int8_b1.engine\",   test_loader_b1)\n",
    "acc64  = trt_accuracy_static(\"alexnet_30_int8_b64.engine\",  test_loader_b64)\n",
    "acc128 = trt_accuracy_static(\"alexnet_30_int8_b128.engine\", test_loader_b128)\n",
    "\n",
    "print(f\"INT8 TRT Acc b1:   {acc1:.2f}%\")\n",
    "print(f\"INT8 TRT Acc b64:  {acc64:.2f}%\")\n",
    "print(f\"INT8 TRT Acc b128: {acc128:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ffe9cf-4ea9-4d56-9285-6c1ef58cee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch acc: 88.49\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def torch_acc(model, loader, device=\"cuda\"):\n",
    "    model.eval().to(device)\n",
    "    correct = total = 0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100*correct/total\n",
    "\n",
    "print(\"Torch acc:\", torch_acc(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd04b1e-a34d-4db9-bea1-ae83cd7205b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(test_loader.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd5c0d-f755-4c20-a1e7-569de0092dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
