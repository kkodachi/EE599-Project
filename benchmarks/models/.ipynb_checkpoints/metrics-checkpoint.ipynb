{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb324e4",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this notebook we test any remaining metrics we need need after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341102e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### ResNet\n",
    "\n",
    "1. Total Parameters: 466906\n",
    "2. MACs: 34879808\n",
    "3. Energy FP32: 0.160 mJ\n",
    "4. Energy FP16: 0.038 mJ\n",
    "5. Energy INT8: 0.007 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×\n",
    "\n",
    "### SqueezeNet\n",
    "\n",
    "1. Total Parameters: 734986\n",
    "2. MACs: 26637312\n",
    "3. Energy FP32: 0.123 mJ\n",
    "4. Energy FP16: 0.029 mJ\n",
    "5. Energy INT8: 0.005 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "1. Total Parameters: 1048330\n",
    "2. MACs: 33598720\n",
    "3. Energy FP32: 0.155 mJ\n",
    "4. Energy FP16: 0.037 mJ\n",
    "5. Energy INT8: 0.007 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15837eb",
   "metadata": {},
   "source": [
    "## Energy vs Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bde76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import helper\n",
    "from squeezenet_model import SqueezeNetCIFAR10, SqueezeNetCIFAR10_QAT\n",
    "from alexnet_model import AlexNetCIFAR10, AlexNetCIFAR10_QAT\n",
    "from resnet32_model import ResNet, ResNetQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae0e9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"squeezenet\"\n",
    "# mname = \"alexnet\"\n",
    "# mname = \"resnet\"\n",
    "\n",
    "if mname == \"squeezenet\":\n",
    "    get_model = SqueezeNetCIFAR10\n",
    "    get_model_qat = SqueezeNetCIFAR10_QAT\n",
    "elif mname == \"alexnet\":\n",
    "    get_model = AlexNetCIFAR10\n",
    "    get_model_qat = AlexNetCIFAR10_QAT\n",
    "elif mname == \"resnet\":\n",
    "    get_model = ResNet\n",
    "    get_model_qat = ResNetQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d01ba601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_energy(macs, precision=\"fp32\"):\n",
    "    energy_per_mac = {\n",
    "        \"fp32\": 4.6e-12,\n",
    "        \"fp16\": 1.1e-12,\n",
    "        \"int8\": 0.2e-12\n",
    "    }\n",
    "    return macs * energy_per_mac[precision]  # Joules\n",
    "\n",
    "def compute_sparsity(model):\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "            w = m.weight.detach()\n",
    "            total += w.numel()\n",
    "            zeros += (w == 0).sum().item()\n",
    "    return zeros / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beafb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet Metrics\n",
      "Model loaded from ../pth/squeezenet_fp32.pth\n",
      "Total Parameters: 734986\n",
      "MACs: 26637312\n",
      "Energy FP32: 0.123 mJ\n",
      "Energy FP16: 0.029 mJ\n",
      "Energy INT8: 0.005 mJ\n",
      "Energy reduction FP32: 4.2×\n",
      "Energy reduction INT8: 23.0×\n",
      "Model loaded from ../pth/squeezenet_10.pth\n",
      "Sparsity: 10.0%\n",
      "Energy: 0.005\n",
      "Model loaded from ../pth/squeezenet_30.pth\n",
      "Sparsity: 30.0%\n",
      "Energy: 0.004\n",
      "Model loaded from ../pth/squeezenet_50.pth\n",
      "Sparsity: 50.0%\n",
      "Energy: 0.003\n",
      "Model loaded from ../pth/squeezenet_70.pth\n",
      "Sparsity: 70.0%\n",
      "Energy: 0.002\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "def get_metrics(mname=\"squeezenet\"):\n",
    "    print(f\"{mname} Metrics\")\n",
    "\n",
    "    model = get_model()\n",
    "    model.load_model(f\"../pth/{mname}_fp32.pth\", device='cpu')\n",
    "    x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "    # total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "    # total MACs\n",
    "    flops = FlopCountAnalysis(model, x)\n",
    "    macs = flops.total() // 2  # FLOPs = 2 × MACs\n",
    "    print(f\"MACs: {macs}\")\n",
    "\n",
    "    # energy vs precision\n",
    "    energy_fp32 = estimate_energy(macs, \"fp32\")\n",
    "    energy_fp16 = estimate_energy(macs, \"fp16\")\n",
    "    energy_int8 = estimate_energy(macs, \"int8\")\n",
    "    print(f\"Energy FP32: {energy_fp32*1e3:.3f} mJ\")\n",
    "    print(f\"Energy FP16: {energy_fp16*1e3:.3f} mJ\")\n",
    "    print(f\"Energy INT8: {energy_int8*1e3:.3f} mJ\")\n",
    "    print(f\"Energy reduction FP32: {energy_fp32 / energy_fp16:.1f}×\")\n",
    "    print(f\"Energy reduction INT8: {energy_fp32 / energy_int8:.1f}×\")\n",
    "\n",
    "    #\n",
    "    fnames = [f\"{mname}_10\", f\"{mname}_30\", f\"{mname}_50\", f\"{mname}_70\"]\n",
    "\n",
    "    for fn in fnames:\n",
    "        model_pruned = get_model()\n",
    "        model_pruned.load_model(f\"../pth/{fn}.pth\", device='cpu')\n",
    "        sparsity = compute_sparsity(model_pruned)\n",
    "        eff_macs = macs * (1 - sparsity)\n",
    "        energy = estimate_energy(eff_macs,\"fp32\")\n",
    "        print(f\"Sparsity: {sparsity*100:.1f}%\")\n",
    "        print(f\"Energy: {energy*1e3:.3f}\")\n",
    "\n",
    "get_metrics(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc971505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../pth/squeezenet_fp32.pth\n",
      "MACs: 26637312\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "model = get_model()\n",
    "model.load_model(f\"../pth/{mname}_fp32.pth\", device='cpu')\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "flops = FlopCountAnalysis(model, x)\n",
    "macs = flops.total() // 2  # FLOPs = 2 × MACs\n",
    "\n",
    "print(f\"MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02643b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy FP32: 0.123 mJ\n",
      "Energy FP16: 0.029 mJ\n",
      "Energy INT8: 0.005 mJ\n",
      "Energy reduction FP32: 4.2×\n",
      "Energy reduction INT8: 23.0×\n"
     ]
    }
   ],
   "source": [
    "def estimate_energy(macs, precision=\"fp32\"):\n",
    "    energy_per_mac = {\n",
    "        \"fp32\": 4.6e-12,\n",
    "        \"fp16\": 1.1e-12,\n",
    "        \"int8\": 0.2e-12\n",
    "    }\n",
    "    return macs * energy_per_mac[precision]  # Joules\n",
    "\n",
    "energy_fp32 = estimate_energy(macs, \"fp32\")\n",
    "energy_fp16 = estimate_energy(macs, \"fp16\")\n",
    "energy_int8 = estimate_energy(macs, \"int8\")\n",
    "\n",
    "print(f\"Energy FP32: {energy_fp32*1e3:.3f} mJ\")\n",
    "print(f\"Energy FP16: {energy_fp16*1e3:.3f} mJ\")\n",
    "print(f\"Energy INT8: {energy_int8*1e3:.3f} mJ\")\n",
    "print(f\"Energy reduction FP32: {energy_fp32 / energy_fp16:.1f}×\")\n",
    "print(f\"Energy reduction INT8: {energy_fp32 / energy_int8:.1f}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ded26",
   "metadata": {},
   "source": [
    "## Energy vs Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"ResNet\"\n",
    "resnet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 0,\n",
    "    \"energy\": 0.123,\n",
    "    \"batch = 1 throughput\": 3256.7,\n",
    "    \"batch = 64 throughput\": 125515.1,\n",
    "    \"batch = 128 throughput\": 176338,\n",
    "    \"batch = 1 latency\": .307,\n",
    "    \"batch = 64 latency\": .510,\n",
    "    \"batch = 128 latency\": .726,\n",
    "    \"batch = 1 engine size\": 2.0M,\n",
    "    \"batch = 64 engine size\": 2.1M,\n",
    "    \"batch = 128 engine size\": 2.1M,\n",
    "    \"batch = 1 accuracy\": 89.74,\n",
    "    \"batch = 64 accuracy\": 89.74,\n",
    "    \"batch = 128 accuracy\": 89.74\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.029\n",
    "        \"batch = 1 throughput\": 4069.9,\n",
    "        \"batch = 64 throughput\": 195238.1,\n",
    "        \"batch = 128 throughput\": 293951,\n",
    "        \"batch = 1 latency\": .246,\n",
    "        \"batch = 64 latency\": .328,\n",
    "        \"batch = 128 latency\": .435,\n",
    "        \"batch = 1 engine size\": 1.2M,\n",
    "        \"batch = 64 engine size\": 1.2M,\n",
    "        \"batch = 128 engine size\": 1.2M,\n",
    "        \"batch = 1 accuracy\": 89.75,\n",
    "        \"batch = 64 accuracy\": 89.74,\n",
    "        \"batch = 128 accuracy\": 89.74\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.005,\n",
    "        \"batch = 1 throughput\": 5264.5,\n",
    "        \"batch = 64 throughput\": 209156.0,\n",
    "        \"batch = 128 throughput\": 306946.6,\n",
    "        \"batch = 1 latency\": .190,\n",
    "        \"batch = 64 latency\": .306,\n",
    "        \"batch = 128 latency\": .417,\n",
    "        \"batch = 1 engine size\": .971M,\n",
    "        \"batch = 64 engine size\": .821M,\n",
    "        \"batch = 128 engine size\": .795M,\n",
    "        \"batch = 1 accuracy\": 89.75,\n",
    "        \"batch = 64 accuracy\": 89.74,\n",
    "        \"batch = 128 accuracy\": 89.74\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0,\n",
    "        \"batch = 1 throughput\": 3229.6,\n",
    "        \"batch = 64 throughput\": 125688.3,\n",
    "        \"batch = 128 throughput\": 176323.8,\n",
    "        \"batch = 1 latency\": .310,\n",
    "        \"batch = 64 latency\": .509,\n",
    "        \"batch = 128 latency\": .726,\n",
    "        \"batch = 1 engine size\": 2.0M,\n",
    "        \"batch = 64 engine size\": 2.1M,\n",
    "        \"batch = 128 engine size\": 2.1M,\n",
    "        \"batch = 1 accuracy\": 90.38,\n",
    "        \"batch = 64 accuracy\": 90.37,\n",
    "        \"batch = 128 accuracy\": 90.38\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0,\n",
    "        \"batch = 1 throughput\": 3197.4,\n",
    "        \"batch = 64 throughput\": 124203.4,\n",
    "        \"batch = 128 throughput\": 174183.0,\n",
    "        \"batch = 1 latency\": .313,\n",
    "        \"batch = 64 latency\": .515,\n",
    "        \"batch = 128 latency\": .735,\n",
    "        \"batch = 1 engine size\": 2.0M,\n",
    "        \"batch = 64 engine size\": 2.1M,\n",
    "        \"batch = 128 engine size\": 2.1M,\n",
    "        \"batch = 1 accuracy\": 89.16,\n",
    "        \"batch = 64 accuracy\": 89.18,\n",
    "        \"batch = 128 accuracy\": 89.18\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0,\n",
    "        \"batch = 1 throughput\": 3346.9,\n",
    "        \"batch = 64 throughput\": 127108.7,\n",
    "        \"batch = 128 throughput\": 176151.6,\n",
    "        \"batch = 1 latency\": .299,\n",
    "        \"batch = 64 latency\": .504,\n",
    "        \"batch = 128 latency\": .727,\n",
    "        \"batch = 1 engine size\": 2.0M,\n",
    "        \"batch = 64 engine size\": 2.1M,\n",
    "        \"batch = 128 engine size\": 2.1M,\n",
    "        \"batch = 1 accuracy\": 90.86,\n",
    "        \"batch = 64 accuracy\": 90.86,\n",
    "        \"batch = 128 accuracy\": 90.87\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0,\n",
    "        \"batch = 1 throughput\": 3284.5,\n",
    "        \"batch = 64 throughput\": 127111.6,\n",
    "        \"batch = 128 throughput\": 175969.6,\n",
    "        \"batch = 1 latency\": .304,\n",
    "        \"batch = 64 latency\": .503,\n",
    "        \"batch = 128 latency\": .727,\n",
    "        \"batch = 1 engine size\": 2.0M,\n",
    "        \"batch = 64 engine size\": 2.1M,\n",
    "        \"batch = 128 engine size\": 2.1M,\n",
    "        \"batch = 1 accuracy\": 91.3,\n",
    "        \"batch = 64 accuracy\": 91.31,\n",
    "        \"batch = 128 accuracy\": 91.31\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned and Quantized\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0,\n",
    "        \"batch = 1 throughput\": 2658.1,\n",
    "        \"batch = 64 throughput\": 123880.1,\n",
    "        \"batch = 128 throughput\": 210303.2,\n",
    "        \"batch = 1 latency\": .376,\n",
    "        \"batch = 64 latency\": .517,\n",
    "        \"batch = 128 latency\": .609,\n",
    "        \"batch = 1 engine size\": .981M,\n",
    "        \"batch = 64 engine size\": .833M,\n",
    "        \"batch = 128 engine size\": .808M,\n",
    "        \"batch = 1 accuracy\": 90.00,\n",
    "        \"batch = 64 accuracy\": 88.66,\n",
    "        \"batch = 128 accuracy\": 88.67\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9de985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"SqueezeNet\"\n",
    "squeezenet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 89.20,\n",
    "    \"energy\": 0.123,\n",
    "    \"batch = 1 throughput\": 4349.5,\n",
    "    \"batch = 64 throughput\": 140871.4,\n",
    "    \"batch = 128 throughput\": 173614.3,\n",
    "    \"batch = 1 latency\": .230,\n",
    "    \"batch = 64 latency\": .454,\n",
    "    \"batch = 128 latency\": .737,\n",
    "    \"batch = 1 engine size\": 3.1M,\n",
    "    \"batch = 64 engine size\": 3.4M,\n",
    "    \"batch = 128 engine size\": 3.3M,\n",
    "    \"batch = 1 accuracy\": 89.21,\n",
    "    \"batch = 64 accuracy\": 89.19,\n",
    "    \"batch = 128 accuracy\": 89.19 \n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.029,\n",
    "        \"batch = 1 throughput\": 5050.5,\n",
    "        \"batch = 64 throughput\": 210439.8,\n",
    "        \"batch = 128 throughput\": 312212.0,\n",
    "        \"batch = 1 latency\": .198,\n",
    "        \"batch = 64 latency\": .304,\n",
    "        \"batch = 128 latency\": .410,\n",
    "        \"batch = 1 engine size\": 1.8M,\n",
    "        \"batch = 64 engine size\": 1.9M,\n",
    "        \"batch = 128 engine size\": 1.9M,\n",
    "        \"batch = 1 accuracy\": 89.23,\n",
    "        \"batch = 64 accuracy\": 89.20,\n",
    "        \"batch = 128 accuracy\": 89.21\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.005,\n",
    "        \"batch = 1 throughput\": 3968.1,\n",
    "        \"batch = 64 throughput\": 228469.1,\n",
    "        \"batch = 128 throughput\": 356741.3,\n",
    "        \"batch = 1 latency\": .252,\n",
    "        \"batch = 64 latency\": .280,\n",
    "        \"batch = 128 latency\": .359,\n",
    "        \"batch = 1 engine size\": 1.2M,\n",
    "        \"batch = 64 engine size\": 1.4M,\n",
    "        \"batch = 128 engine size\": 1.3M,\n",
    "        \"batch = 1 accuracy\": 89.13,\n",
    "        \"batch = 64 accuracy\": 89.22,\n",
    "        \"batch = 128 accuracy\": 89.18\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 88.18,\n",
    "        \"energy\": 0.110,\n",
    "        \"batch = 1 throughput\": 4249.6,\n",
    "        \"batch = 64 throughput\": 138965.2,\n",
    "        \"batch = 128 throughput\": 172100.4,\n",
    "        \"batch = 1 latency\": .235,\n",
    "        \"batch = 64 latency\": .461,\n",
    "        \"batch = 128 latency\": .744,\n",
    "        \"batch = 1 engine size\": 3.1M,\n",
    "        \"batch = 64 engine size\": 3.4M,\n",
    "        \"batch = 128 engine size\": 3.3M,\n",
    "        \"batch = 1 accuracy\": 88.2,\n",
    "        \"batch = 64 accuracy\": 88.2,\n",
    "        \"batch = 128 accuracy\": 88.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 89.20,\n",
    "        \"energy\": 0.086,\n",
    "        \"batch = 1 throughput\": 4321.8,\n",
    "        \"batch = 64 throughput\": 139816.6,\n",
    "        \"batch = 128 throughput\": 171848.2,\n",
    "        \"batch = 1 latency\": .231,\n",
    "        \"batch = 64 latency\": .458,\n",
    "        \"batch = 128 latency\": .745,\n",
    "        \"batch = 1 engine size\": 3.1M,\n",
    "        \"batch = 64 engine size\": 3.4M,\n",
    "        \"batch = 128 engine size\": 3.4M,\n",
    "        \"batch = 1 accuracy\": 88.97,\n",
    "        \"batch = 64 accuracy\": 88.98,\n",
    "        \"batch = 128 accuracy\": 88.98\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 88.97,\n",
    "        \"energy\": 0.061,\n",
    "        \"batch = 1 throughput\": 4235.8,\n",
    "        \"batch = 64 throughput\": 139790.1,\n",
    "        \"batch = 128 throughput\": 171286.6,\n",
    "        \"batch = 1 latency\": .236,\n",
    "        \"batch = 64 latency\": .458,\n",
    "        \"batch = 128 latency\": .747,\n",
    "        \"batch = 1 engine size\": 3.1M,\n",
    "        \"batch = 64 engine size\": 3.4M,\n",
    "        \"batch = 128 engine size\": 3.4M,\n",
    "        \"batch = 1 accuracy\": 89.18,\n",
    "        \"batch = 64 accuracy\": 89.19,\n",
    "        \"batch = 128 accuracy\": 89.19\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 89.66,\n",
    "        \"energy\": 0.037,\n",
    "        \"batch = 1 throughput\": 4421.9,\n",
    "        \"batch = 64 throughput\": 139949.1,\n",
    "        \"batch = 128 throughput\": 172244.6,\n",
    "        \"batch = 1 latency\": .226,\n",
    "        \"batch = 64 latency\": .457,\n",
    "        \"batch = 128 latency\": .743,\n",
    "        \"batch = 1 engine size\": 3.1M,\n",
    "        \"batch = 64 engine size\": 3.4M,\n",
    "        \"batch = 128 engine size\": 3.4M,\n",
    "        \"batch = 1 accuracy\": 89.71,\n",
    "        \"batch = 64 accuracy\": 89.72,\n",
    "        \"batch = 128 accuracy\": 89.71\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned and Quantized\",\n",
    "        \"accuracy\": 88.71,\n",
    "        \"energy\": 0.002,\n",
    "        \"batch = 1 throughput\": 2711.8,\n",
    "        \"batch = 64 throughput\": 130063.4,\n",
    "        \"batch = 128 throughput\": 220532.5,\n",
    "        \"batch = 1 latency\": .369,\n",
    "        \"batch = 64 latency\": .492,\n",
    "        \"batch = 128 latency\": .580,\n",
    "        \"batch = 1 engine size\": 1.2M,\n",
    "        \"batch = 64 engine size\": 1.4M,\n",
    "        \"batch = 128 engine size\": 1.3M,\n",
    "        \"batch = 1 accuracy\": 96.00,\n",
    "        \"batch = 64 accuracy\": 88.59,\n",
    "        \"batch = 128 accuracy\": 88.42\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ead89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"AlexNet\"\n",
    "\n",
    "alexnet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 0,\n",
    "    \"energy\": 0.155,\n",
    "    \"batch = 1 throughput\": 10807.8,\n",
    "    \"batch = 64 throughput\": 311812.4,\n",
    "    \"batch = 128 throughput\": 389893.9,\n",
    "    \"batch = 1 latency\": .093,\n",
    "    \"batch = 64 latency\": .205,\n",
    "    \"batch = 128 latency\": .328,\n",
    "    \"batch = 1 engine size\": 4.2M,\n",
    "    \"batch = 64 engine size\": 4.2M,\n",
    "    \"batch = 128 engine size\": 4.3M,\n",
    "    \"batch = 1 accuracy\": 88.13,\n",
    "    \"batch = 64 accuracy\": 88.13,\n",
    "    \"batch = 128 accuracy\": 88.13\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.037,\n",
    "        \"batch = 1 throughput\": 14351.5,\n",
    "        \"batch = 64 throughput\": 505405.8,\n",
    "        \"batch = 128 throughput\": 732974.5,\n",
    "        \"batch = 1 latency\": .070,\n",
    "        \"batch = 64 latency\": .127,\n",
    "        \"batch = 128 latency\": .175,\n",
    "        \"batch = 1 engine size\": 2.2M,\n",
    "        \"batch = 64 engine size\": 2.2M,\n",
    "        \"batch = 128 engine size\": 2.2M,\n",
    "        \"batch = 1 accuracy\": 88.13,\n",
    "        \"batch = 64 accuracy\": 88.14,\n",
    "        \"batch = 128 accuracy\": 88.14\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.007,\n",
    "        \"batch = 1 throughput\": 9867.3,\n",
    "        \"batch = 64 throughput\": 573905.2,\n",
    "        \"batch = 128 throughput\": 1062157.5,\n",
    "        \"batch = 1 latency\": .101,\n",
    "        \"batch = 64 latency\": .112,\n",
    "        \"batch = 128 latency\": .121,\n",
    "        \"batch = 1 engine size\": 1.5M,\n",
    "        \"batch = 64 engine size\": 1.2M,\n",
    "        \"batch = 128 engine size\": 1.2M,\n",
    "        \"batch = 1 accuracy\": 88.17,\n",
    "        \"batch = 64 accuracy\": 88.13,\n",
    "        \"batch = 128 accuracy\": 88.16\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 87.43,\n",
    "        \"energy\": 0.139,\n",
    "        \"batch = 1 throughput\": 10943.1,\n",
    "        \"batch = 64 throughput\": 315314.2,\n",
    "        \"batch = 128 throughput\": 389125.6,\n",
    "        \"batch = 1 latency\": .091,\n",
    "        \"batch = 64 latency\": .203,\n",
    "        \"batch = 128 latency\": .329,\n",
    "        \"batch = 1 engine size\": 4.2M,\n",
    "        \"batch = 64 engine size\": 4.2M,\n",
    "        \"batch = 128 engine size\": 4.2M,\n",
    "        \"batch = 1 accuracy\": 88.58,\n",
    "        \"batch = 64 accuracy\": 88.57,\n",
    "        \"batch = 128 accuracy\": 88.57\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 88.55,\n",
    "        \"energy\": 0.108,\n",
    "        \"batch = 1 throughput\": 10902.2,\n",
    "        \"batch = 64 throughput\": 311635.2,\n",
    "        \"batch = 128 throughput\": 388853.3,\n",
    "        \"batch = 1 latency\": .092,\n",
    "        \"batch = 64 latency\": .205,\n",
    "        \"batch = 128 latency\": .329,\n",
    "        \"batch = 1 engine size\": 4.2M,\n",
    "        \"batch = 64 engine size\": 4.2M,\n",
    "        \"batch = 128 engine size\": 4.3M,\n",
    "        \"batch = 1 accuracy\": 88.49,\n",
    "        \"batch = 64 accuracy\": 88.48,\n",
    "        \"batch = 128 accuracy\": 88.48\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 88.44,\n",
    "        \"energy\": 0.077,\n",
    "        \"batch = 1 throughput\": 10961.5,\n",
    "        \"batch = 64 throughput\": 314282.0,\n",
    "        \"batch = 128 throughput\": 390365.2,\n",
    "        \"batch = 1 latency\": .091,\n",
    "        \"batch = 64 latency\": .204,\n",
    "        \"batch = 128 latency\": .328,\n",
    "        \"batch = 1 engine size\": 4.1M,\n",
    "        \"batch = 64 engine size\": 4.2M,\n",
    "        \"batch = 128 engine size\": 4.2M,\n",
    "        \"batch = 1 accuracy\": 87.98,\n",
    "        \"batch = 64 accuracy\": 87.97,\n",
    "        \"batch = 128 accuracy\": 87.97\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 88.94,\n",
    "        \"energy\": 0.046,\n",
    "        \"batch = 1 throughput\": 11098.6,\n",
    "        \"batch = 64 throughput\": 313402.6,\n",
    "        \"batch = 128 throughput\": 390450.5,\n",
    "        \"batch = 1 latency\": .090,\n",
    "        \"batch = 64 latency\": .204,\n",
    "        \"batch = 128 latency\": .328,\n",
    "        \"batch = 1 engine size\": 4.2M,\n",
    "        \"batch = 64 engine size\": 4.2M,\n",
    "        \"batch = 128 engine size\": 4.2M,\n",
    "        \"batch = 1 accuracy\": 88.27,\n",
    "        \"batch = 64 accuracy\": 88.27,\n",
    "        \"batch = 128 accuracy\": 88.27\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned 70% and Quantized\",\n",
    "        \"accuracy\": 76.95,\n",
    "        \"energy\": 0.002,\n",
    "        \"batch = 1 throughput\": 7384.2,\n",
    "        \"batch = 64 throughput\": 324801.9,\n",
    "        \"batch = 128 throughput\": 527815.9,\n",
    "        \"batch = 1 latency\": .135,\n",
    "        \"batch = 64 latency\": .197,\n",
    "        \"batch = 128 latency\": .243,\n",
    "        \"batch = 1 engine size\": 1.5M,\n",
    "        \"batch = 64 engine size\": 1.2M,\n",
    "        \"batch = 128 engine size\": 1.2M,\n",
    "        \"batch = 1 accuracy\": 96.00,\n",
    "        \"batch = 64 accuracy\": 88.66,\n",
    "        \"batch = 128 accuracy\": 86.84\n",
    "    },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
