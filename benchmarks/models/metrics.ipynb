{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb324e4",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this notebook we test any remaining metrics we need need after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341102e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### ResNet\n",
    "\n",
    "1. Total Parameters: 466906\n",
    "2. MACs: 34879808\n",
    "3. Energy FP32: 0.160 mJ\n",
    "4. Energy FP16: 0.038 mJ\n",
    "5. Energy INT8: 0.007 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×\n",
    "\n",
    "### SqueezeNet\n",
    "\n",
    "1. Total Parameters: 734986\n",
    "2. MACs: 26637312\n",
    "3. Energy FP32: 0.123 mJ\n",
    "4. Energy FP16: 0.029 mJ\n",
    "5. Energy INT8: 0.005 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "1. Total Parameters: 1048330\n",
    "2. MACs: 33598720\n",
    "3. Energy FP32: 0.155 mJ\n",
    "4. Energy FP16: 0.037 mJ\n",
    "5. Energy INT8: 0.007 mJ\n",
    "6. Energy reduction FP32: 4.2×\n",
    "7. Energy reduction INT8: 23.0×"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15837eb",
   "metadata": {},
   "source": [
    "## Energy vs Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bde76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import helper\n",
    "from squeezenet_model import SqueezeNetCIFAR10, SqueezeNetCIFAR10_QAT\n",
    "from alexnet_model import AlexNetCIFAR10, AlexNetCIFAR10_QAT\n",
    "from resnet32_model import ResNet, ResNetQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae0e9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mname = \"squeezenet\"\n",
    "mname = \"alexnet\"\n",
    "# mname = \"resnet\"\n",
    "\n",
    "if mname == \"squeezenet\":\n",
    "    get_model = SqueezeNetCIFAR10\n",
    "    get_model_qat = SqueezeNetCIFAR10_QAT\n",
    "elif mname == \"alexnet\":\n",
    "    get_model = AlexNetCIFAR10\n",
    "    get_model_qat = AlexNetCIFAR10_QAT\n",
    "elif mname == \"resnet\":\n",
    "    get_model = ResNet\n",
    "    get_model_qat = ResNetQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d01ba601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_energy(macs, precision=\"fp32\"):\n",
    "    energy_per_mac = {\n",
    "        \"fp32\": 4.6e-12,\n",
    "        \"fp16\": 1.1e-12,\n",
    "        \"int8\": 0.2e-12\n",
    "    }\n",
    "    return macs * energy_per_mac[precision]  # Joules\n",
    "\n",
    "def compute_sparsity(model):\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "            w = m.weight.detach()\n",
    "            total += w.numel()\n",
    "            zeros += (w == 0).sum().item()\n",
    "    return zeros / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8beafb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet Metrics\n",
      "Model loaded from ../pth/alexnet_fp32.pth\n",
      "Total Parameters: 1048330\n",
      "MACs: 33598720\n",
      "Energy FP32: 0.155 mJ\n",
      "Energy FP16: 0.037 mJ\n",
      "Energy INT8: 0.007 mJ\n",
      "Energy reduction FP32: 4.2×\n",
      "Energy reduction INT8: 23.0×\n",
      "Model loaded from ../pth/alexnet_10.pth\n",
      "Sparsity: 10.0%\n",
      "Energy: 0.139\n",
      "Model loaded from ../pth/alexnet_30.pth\n",
      "Sparsity: 30.0%\n",
      "Energy: 0.108\n",
      "Model loaded from ../pth/alexnet_50.pth\n",
      "Sparsity: 50.0%\n",
      "Energy: 0.077\n",
      "Model loaded from ../pth/alexnet_70.pth\n",
      "Sparsity: 70.0%\n",
      "Energy: 0.046\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "def get_metrics(mname=\"squeezenet\"):\n",
    "    print(f\"{mname} Metrics\")\n",
    "\n",
    "    model = get_model()\n",
    "    model.load_model(f\"../pth/{mname}_fp32.pth\", device='cpu')\n",
    "    x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "    # total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "    # total MACs\n",
    "    flops = FlopCountAnalysis(model, x)\n",
    "    macs = flops.total() // 2  # FLOPs = 2 × MACs\n",
    "    print(f\"MACs: {macs}\")\n",
    "\n",
    "    # energy vs precision\n",
    "    energy_fp32 = estimate_energy(macs, \"fp32\")\n",
    "    energy_fp16 = estimate_energy(macs, \"fp16\")\n",
    "    energy_int8 = estimate_energy(macs, \"int8\")\n",
    "    print(f\"Energy FP32: {energy_fp32*1e3:.3f} mJ\")\n",
    "    print(f\"Energy FP16: {energy_fp16*1e3:.3f} mJ\")\n",
    "    print(f\"Energy INT8: {energy_int8*1e3:.3f} mJ\")\n",
    "    print(f\"Energy reduction FP32: {energy_fp32 / energy_fp16:.1f}×\")\n",
    "    print(f\"Energy reduction INT8: {energy_fp32 / energy_int8:.1f}×\")\n",
    "\n",
    "    #\n",
    "    fnames = [f\"{mname}_10\", f\"{mname}_30\", f\"{mname}_50\", f\"{mname}_70\"]\n",
    "\n",
    "    for fn in fnames:\n",
    "        model_pruned = get_model()\n",
    "        model_pruned.load_model(f\"../pth/{fn}.pth\", device='cpu')\n",
    "        sparsity = compute_sparsity(model_pruned)\n",
    "        eff_macs = macs * (1 - sparsity)\n",
    "        energy = estimate_energy(eff_macs,\"fp32\")\n",
    "        print(f\"Sparsity: {sparsity*100:.1f}%\")\n",
    "        print(f\"Energy: {energy*1e3:.3f}\")\n",
    "\n",
    "get_metrics(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc971505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../pth/squeezenet_fp32.pth\n",
      "MACs: 26637312\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "model = get_model()\n",
    "model.load_model(f\"../pth/{mname}_fp32.pth\", device='cpu')\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "flops = FlopCountAnalysis(model, x)\n",
    "macs = flops.total() // 2  # FLOPs = 2 × MACs\n",
    "\n",
    "print(f\"MACs: {macs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02643b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy FP32: 0.123 mJ\n",
      "Energy FP16: 0.029 mJ\n",
      "Energy INT8: 0.005 mJ\n",
      "Energy reduction FP32: 4.2×\n",
      "Energy reduction INT8: 23.0×\n"
     ]
    }
   ],
   "source": [
    "def estimate_energy(macs, precision=\"fp32\"):\n",
    "    energy_per_mac = {\n",
    "        \"fp32\": 4.6e-12,\n",
    "        \"fp16\": 1.1e-12,\n",
    "        \"int8\": 0.2e-12\n",
    "    }\n",
    "    return macs * energy_per_mac[precision]  # Joules\n",
    "\n",
    "energy_fp32 = estimate_energy(macs, \"fp32\")\n",
    "energy_fp16 = estimate_energy(macs, \"fp16\")\n",
    "energy_int8 = estimate_energy(macs, \"int8\")\n",
    "\n",
    "print(f\"Energy FP32: {energy_fp32*1e3:.3f} mJ\")\n",
    "print(f\"Energy FP16: {energy_fp16*1e3:.3f} mJ\")\n",
    "print(f\"Energy INT8: {energy_int8*1e3:.3f} mJ\")\n",
    "print(f\"Energy reduction FP32: {energy_fp32 / energy_fp16:.1f}×\")\n",
    "print(f\"Energy reduction INT8: {energy_fp32 / energy_int8:.1f}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ded26",
   "metadata": {},
   "source": [
    "## Energy vs Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"ResNet\"\n",
    "resnet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 0,\n",
    "    \"energy\": 0.123,\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.029\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.005\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned and Quantized\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9de985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"SqueezeNet\"\n",
    "squeezenet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 0,\n",
    "    \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned and Quantized\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ead89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtitle = \"AlexNet\"\n",
    "\n",
    "alexnet_results = [{\n",
    "    \"name\": f\"{mtitle} FP32\",\n",
    "    \"accuracy\": 0,\n",
    "    \"energy\": 0.155\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP16\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.037\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} INT8\",\n",
    "        \"accuracy\": 0,\n",
    "        \"energy\": 0.007\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 10%\",\n",
    "        \"accuracy\": 87.43,\n",
    "        \"energy\": 0.139\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 30%\",\n",
    "        \"accuracy\": 88.55,\n",
    "        \"energy\": 0.108\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 50%\",\n",
    "        \"accuracy\": 88.44,\n",
    "        \"energy\": 0.077\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} FP32 Pruned 70%\",\n",
    "        \"accuracy\": 88.94,\n",
    "        \"energy\": 0.046\n",
    "    },\n",
    "    {\n",
    "        \"name\": f\"{mtitle} Pruned 70% and Quantized\",\n",
    "        \"accuracy\": 76.95,\n",
    "        \"energy\": 0.002\n",
    "    },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
